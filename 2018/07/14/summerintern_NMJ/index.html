<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="google5b248f7b86cbcee5.html" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="deep learning,project,summer intern,neural science,Jeff Lichtman," />





  <link rel="alternate" href="/atom.xml" title="WonderLand" type="application/atom+xml" />






<meta name="description" content="It is my main task during my summer intern in Lichtman lab.The codes related are here: NMJ codes">
<meta name="keywords" content="deep learning,project,summer intern,neural science,Jeff Lichtman">
<meta property="og:type" content="article">
<meta property="og:title" content="NMJ Project">
<meta property="og:url" content="https://www.cmwonderland.com/2018/07/14/summerintern_NMJ/index.html">
<meta property="og:site_name" content="WonderLand">
<meta property="og:description" content="It is my main task during my summer intern in Lichtman lab.The codes related are here: NMJ codes">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://i2.tiimg.com/640680/674ef868297b66d0.gif">
<meta property="og:image" content="http://i1.fuimg.com/640680/45e727fc31a9b0dc.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/8b18f43f830a2eb7.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/2a5303ed7c054769.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/96c7c89bc409d6ba.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/070eef826c0612ae.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/2b1b68b735d93e29.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/c9d99655bdaf9cac.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/06d9ead45f4caa9a.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/68a5d5858d2eca5f.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/14e81611ee917fa6.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/20dac5fc8da5ae1f.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/6ba0407959138c82.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/83ebcf388707f0a6.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/f618886ef775eb3c.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/080f9880226ba6e5.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/493a642ca564813f.png">
<meta property="og:image" content="http://i2.tiimg.com/640680/96c7c89bc409d6ba.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/743789aaa8f0fe9f.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/8c9abba357fcb56c.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/ad6c8f42a22e89f1.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/db41e29e1b9c045a.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/c8462edb973660e0.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/81ada9efd84b2bb8.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/87378f2e7ea1db4c.png">
<meta property="og:image" content="http://i4.fuimg.com/640680/4d964d4ee16a7e7a.png">
<meta property="og:updated_time" content="2018-08-12T23:52:52.427Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NMJ Project">
<meta name="twitter:description" content="It is my main task during my summer intern in Lichtman lab.The codes related are here: NMJ codes">
<meta name="twitter:image" content="http://i2.tiimg.com/640680/674ef868297b66d0.gif">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.cmwonderland.com/2018/07/14/summerintern_NMJ/"/>





  <title>NMJ Project | WonderLand</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6656499bfc0e07b4e20ee4975eb85f31";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/james20141606"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_white_ffffff.png" alt="Fork me on GitHub"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WonderLand</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Somnium & Somniator</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.cmwonderland.com/2018/07/14/summerintern_NMJ/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="James Chen">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WonderLand">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">NMJ Project</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-07-14T20:35:19-04:00">
                2018-07-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/summer-intern/" itemprop="url" rel="index">
                    <span itemprop="name">summer intern</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/07/14/summerintern_NMJ/" class="leancloud_visitors" data-flag-title="NMJ Project">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  4,148
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  26
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>It is my main task during my summer intern in Lichtman lab.<br>The codes related are here: <a href="https://github.com/james20141606/Summer_Intern/tree/master/NMJ" target="_blank" rel="noopener">NMJ codes</a></p>
<a id="more"></a>
<hr>
<h1 id="First-two-weeks"><a href="#First-two-weeks" class="headerlink" title="First two weeks"></a>First two weeks</h1><p>Since the new data is still to be processed, I spent several days doing dense segmentation work both for study and future training. </p>
<p>I have done 25 sections dense segmentation in W12-W14 for 4 days(7.5-7.8), it includes dense segmentation of Axons, Schwann cell, and Schwann cell nucleus. </p>
<p>I have written codes to use python to visualize animation of the 25 segments <img src="http://i2.tiimg.com/640680/674ef868297b66d0.gif" alt="Markdown">. Since the computational  work use more python codes know, I also shared my animating code with others.<br><a href="https://github.com/james20141606/Summer_Intern/blob/master/NMJ/jupyter/plot_segment.ipynb" target="_blank" rel="noopener">plot segment script</a></p>
<p>Core codes to plot animation in python</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">defdef  transform_rgbtransfor (img):</span><br><span class="line">    num = np.unique(img.reshape(<span class="number">-1</span>,<span class="number">3</span>),axis=<span class="number">0</span>).shape[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#print (num)</span></span><br><span class="line">    <span class="comment">#rgbarr = np.ndarray([num*3])</span></span><br><span class="line">    <span class="comment">#for i in range(num*3):</span></span><br><span class="line">      <span class="comment">#  rgbarr[i] = np.random.uniform(0,1)</span></span><br><span class="line">    <span class="comment">#rgbarr = rgbarr.reshape(-1,3)</span></span><br><span class="line">    image = np.zeros([img.shape[<span class="number">0</span>]*img.shape[<span class="number">1</span>],<span class="number">3</span>])</span><br><span class="line">    sumimg = np.sum(img.reshape(<span class="number">-1</span>,<span class="number">3</span>),axis=<span class="number">1</span>)</span><br><span class="line">    uniqueind = np.unique(img.reshape(<span class="number">-1</span>,<span class="number">3</span>),axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">0</span>,num<span class="number">-1</span>):</span><br><span class="line">        image[sumimg==<span class="number">3</span>*(uniqueind[i][<span class="number">0</span>]+<span class="number">1</span>)] = colorsgallery[i]</span><br><span class="line">    <span class="comment">#print (sumimg.shape)</span></span><br><span class="line">    image[sumimg==<span class="number">0</span>] = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> image.reshape(img.shape[<span class="number">0</span>],img.shape[<span class="number">1</span>],<span class="number">3</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> rc</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">animations</span><span class="params">(opt=<span class="string">'show'</span>,type=<span class="string">'gif'</span>)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    opt: show/save</span></span><br><span class="line"><span class="string">    type:gif/mp4</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    imagelist = [transform_rgb(imagedata[i][<span class="number">100</span>:<span class="number">900</span>,<span class="number">100</span>:<span class="number">900</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">26</span>)]</span><br><span class="line">    fig,ax=plt.subplots(<span class="number">1</span>,figsize=(<span class="number">16</span>,<span class="number">12</span>)) </span><br><span class="line">    im =ax.imshow(imagelist[<span class="number">0</span>])</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">updatefig</span><span class="params">(j)</span>:</span></span><br><span class="line">        im.set_array(imagelist[j])</span><br><span class="line">        <span class="keyword">return</span> [im]</span><br><span class="line">    anim = animation.FuncAnimation(fig, updatefig, frames=range(<span class="number">26</span>), </span><br><span class="line">                                  interval=<span class="number">100</span>, blit=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">if</span> opt==<span class="string">'show'</span>:</span><br><span class="line">        <span class="keyword">return</span> anim</span><br><span class="line">    <span class="keyword">elif</span> opt==<span class="string">'save'</span>:</span><br><span class="line">        <span class="keyword">if</span> type==<span class="string">'mp4'</span>:</span><br><span class="line">            Writer = animation.writers[<span class="string">'ffmpeg'</span>]</span><br><span class="line">            writer1 = Writer(fps=<span class="number">10</span>)</span><br><span class="line">            anim.save(<span class="string">'animation.'</span>+type, writer=writer1,dpi=<span class="number">1000</span>)</span><br><span class="line">        <span class="keyword">elif</span> type==<span class="string">'gif'</span>:</span><br><span class="line">            <span class="comment">#Writer = animation.writers['imagemagick']</span></span><br><span class="line">            anim.save(<span class="string">'animation.'</span>+type, writer=<span class="string">'imagemagick'</span>, fps=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>I also read several articles Marco and Yaron recommened, including previous NMJ work, some segmentation and Connectome processing pipeline papers.</p>
<h2 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h2><p>We also discuss a lot about the future plan of the project. Since it is more challenging than other tasks, it seems we are a little slow in progress. We have worked with Marco to find a way to label the ROI and use a script to extract coordinates of the bounding box. We have labeled one mask, later we will test Adi’s align results and generate more.</p>
<ul>
<li>Manually create ROI region for bundles and NMJ for alignment</li>
<li>Do segmentation and \textbf{statistical analysis} work on some NMJs(concerning our limited staying time, it seems there isn’t enough time to wait for all NMJs’ alignment and segmentation results to analyze)</li>
</ul>
<hr>
<h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="mask-and-seeding"><a href="#mask-and-seeding" class="headerlink" title="mask and seeding"></a>mask and seeding</h2><p>This week we have worked out a plan on alignment and seeding.</p>
<p>We use a mind map to record tree’s nodes to visualize our progress. The mask was sent to Adi for aligning. The alignment results seem very good.</p>
<p>I have seeded three masks Adi sent back, <strong>for about 900 sections mainly in bundle area.</strong></p>
<p>I also wrote python script <a href="https://github.com/james20141606/Summer_Intern/blob/master/NMJ/jupyter/plot_segment.ipynb" target="_blank" rel="noopener">Summer_Intern/plot_segment.ipynb at master · james20141606/Summer_Intern · GitHub</a> for further analysis. Since I am proficient in using python for visualization, statistical analysis and machine learning, I wrote some python scripts to read seeding result, visualize them and plot them in 3D and animation. It will be better to have more statistical analysis when I collect more seeding data.<br><img src="http://i1.fuimg.com/640680/45e727fc31a9b0dc.png" alt="Markdown"></p>
<h2 id="discussion-on-mask"><a href="#discussion-on-mask" class="headerlink" title="discussion on mask"></a>discussion on mask</h2><p>When we put masks on ROI, we found many branches even in bundle area, two branches from one stem may encounter and form a closed loop. We are worried if it will be a problem when we merge all masks together. After discussing with Adi and Daniel, we understand that the spatial structure’s change isn’t a big problem.</p>
<hr>
<p>Week 4</p>
<h2 id="My-thought-about-how-the-whole-project"><a href="#My-thought-about-how-the-whole-project" class="headerlink" title="My thought about how the whole project"></a>My thought about how the whole project</h2><p>This week I continue to seed on Mask3, and then I do a lot of exploration on how to do the NMJ project automatically.</p>
<p>I have understood how big and challenging this project is, it requires so many manually labeling work than we can’t finish all the masking and seeding and segmentation and reconstruction work in two months. We know that it took KK and Marco several months to finish part of the bundle parts. But the remaining parts are more complex to seed, segment and it contains maybe 200 masks with approximately 50,000 sections. It is hard to estimate how long it will take to finish the whole project</p>
<p>However, as I am getting more familiar with this project, I am trying to build a more automatically pipeline for seeding, predicting membrane and segmentation. If it works, the project may move faster when we are here and after we leave:)</p>
<h3 id="Seeding-on-Mask3"><a href="#Seeding-on-Mask3" class="headerlink" title="Seeding on Mask3"></a>Seeding on Mask3</h3><p>I felt that seeding on mask3 is much more complex than previous bundle seeding, the axon travels very fast and I should look up and down to look for one axon, it takes much more time to trace the branch than the main bundle.</p>
<h2 id="Automatic-pipeline"><a href="#Automatic-pipeline" class="headerlink" title="Automatic pipeline"></a>Automatic pipeline</h2><p><strong>We would like to build up a more automatic pipeline before we leave and test the whole pipeline on several masks to see if they can be merged and reconstructed.</strong></p>
<p>We would like to build up the whole pipeline, prepare all the codes and model for prediction and processing and write down the protocol.</p>
<p>The complete pipeline should contain:<br><strong>Generating Masks —&gt; Seeding —&gt; Predict Membrane —&gt; Expand Seeds —&gt; Merge different Masks</strong></p>
<p>Previously we do seeding manually and then predict membrane, but the remaining masks have so many sections, I would like to do the seeding work more automatically too.</p>
<h3 id="Predict-Membrane"><a href="#Predict-Membrane" class="headerlink" title="Predict Membrane"></a>Predict Membrane</h3><p>The automatically prediction parts must include membrane prediction, because it is “easier” to predict since the raw image already have the membrane.</p>
<h3 id="Automatically-seeding"><a href="#Automatically-seeding" class="headerlink" title="Automatically seeding"></a>Automatically seeding</h3><p>The traditional way is to manually put seeds on each axon, but we have approximately 50,000 sections if all masks are generated, it is so time-consuming to manually put seeds. I will <strong>generate seeds by distance transformation from membrane</strong></p>
<p>Then the seeds must be indexed to track each seed is from which axon, so we will manually put seeds  per 100 sections, then do <strong>Hungarian matching.</strong></p>
<h3 id="segmentation"><a href="#segmentation" class="headerlink" title="segmentation"></a>segmentation</h3><p>Expand the seed to generate segments</p>
<h3 id="Merge-masks"><a href="#Merge-masks" class="headerlink" title="Merge masks"></a>Merge masks</h3><p>We are thinking about linear interpolation to merge anchor sections for loop problems. We will discuss it more with Daniel and Yaron after the segmentation</p>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p>The related codes are here:<br><a href="https://github.com/james20141606/membrane_prediction" target="_blank" rel="noopener">GitHub - james20141606/membrane_prediction: Use 3D U-net to predict membrane predition</a></p>
<h3 id="Predict-Membrane-1"><a href="#Predict-Membrane-1" class="headerlink" title="Predict Membrane"></a>Predict Membrane</h3><p>I will use a 3D U-net model to use contours extracted from dense segmentation sections. Use 50 sections for training, then predict more, proofread predicted sections to generate more training samples. <strong>The iterative training and predicting method will make the model more precise.</strong></p>
<p>The model’s weight is adaptive to the pixels ratio, I can do fine tune on the model iteratively. So the model will be more precise and requires fewer proofreading. Last week I do many augmentation works, it is also useful to generate more training images since I only have 50 sections for training now.</p>
<p><strong>How to fine tune:</strong><br>If we want better result, we can manually label several sections on each mask and retrain the model on each mask.</p>
<p>For membrane prediction, since we do not consider affinity, we can also consider 2D U-net, it contains much less parameters and easier to train.</p>
<h3 id="Automatically-seeding-1"><a href="#Automatically-seeding-1" class="headerlink" title="Automatically seeding"></a>Automatically seeding</h3><ul>
<li><strong>Distance transformation</strong> to generate seeds from membrane</li>
<li><strong>Hungarian matching</strong> to label each seeds for different axons. Manually label one section’ s seed and do Hungarian matching for the next 100 sections.</li>
</ul>
<h3 id="Watershed"><a href="#Watershed" class="headerlink" title="Watershed"></a>Watershed</h3><p>Use watershed to expand seeds and generate segments</p>
<h3 id="Useful-resources"><a href="#Useful-resources" class="headerlink" title="Useful resources"></a>Useful resources</h3><p><a href="https://github.com/tdedecko/hungarian-algorithm/blob/master/hungarian.py#L6" target="_blank" rel="noopener">hungarian-algorithm/hungarian.py at master · tdedecko/hungarian-algorithm · GitHub</a><br><a href="https://github.com/hrldcpr/hungarian" target="_blank" rel="noopener">GitHub - hrldcpr/hungarian: Hungarian / Munkres’ algorithm for the linear assignment problem, in Python</a></p>
<p><a href="https://github.com/microns-ariadne/pipeline_engine/tree/cf100202997d3c848a21de441e15deb9f975042d/ariadne_microns_pipeline/tasks" target="_blank" rel="noopener">pipeline_engine/ariadne_microns_pipeline/tasks at cf100202997d3c848a21de441e15deb9f975042d · microns-ariadne/pipeline_engine · GitHub</a></p>
<p>Other possible algorithm:</p>
<ul>
<li>seeding<br>Use EM data to predict seeds, train seeding prediction network, using affinity because the axon travels fast. Sebastian’s group has some work. But I think it is imprecise compared to membrane prediction—distance transformation algorithm</li>
</ul>
<blockquote>
<p>Convolutional Networks Can Learn to Generate Affinity<br>Graphs for Image Segmentation<br>Maximin affinity learning of image segmentation</p>
</blockquote>
<p><a href="https://github.com/jiwoon-ahn/psa" target="_blank" rel="noopener">GitHub - jiwoon-ahn/psa: Learning Pixel-level Semantic Affinity with Image-level Supervision for Weakly Supervised Semantic Segmentation, CVPR 2018</a></p>
<h2 id="Work-on-membrane-prediction"><a href="#Work-on-membrane-prediction" class="headerlink" title="Work on membrane prediction"></a>Work on membrane prediction</h2><h3 id="Prepare-ground-truth-training-set"><a href="#Prepare-ground-truth-training-set" class="headerlink" title="Prepare ground truth training set"></a>Prepare ground truth training set</h3><p>I have started on membrane prediction pipeline after discussion with zudi, yaron and others. I would like to use previously label siyan and I have done in first two weeks to save time. We have done dense segmentation on 51 sections, I wrote a python script</p>
<p>Codes: <a href="https://github.com/james20141606/Summer_Intern/blob/master/NMJ/jupyter/extract_membrane_gt.ipynb" target="_blank" rel="noopener">Summer_Intern/extract_membrane_gt.ipynb at master · james20141606/Summer_Intern · GitHub</a></p>
<p> to extract the needed EM image and contours of the membrane in the following steps:</p>
<ul>
<li>export segmentation and EM ROI from VAST</li>
<li>read in python, converting id array to RGB array for visualization</li>
</ul>
<p><img src="http://i2.tiimg.com/640680/8b18f43f830a2eb7.png" alt="Markdown"></p>
<ul>
<li>find bounding box of each segmentation and EM image</li>
</ul>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def find_bounding(data):</span><br><span class="line">    xmin = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">0</span>])[<span class="number">0</span>]</span><br><span class="line">    xmax = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">0</span>])[-<span class="number">1</span>]</span><br><span class="line">    ymin = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">    ymax = <span class="built_in">np</span>.<span class="built_in">sort</span>(<span class="built_in">np</span>.where(data[:,:,<span class="number">0</span>]!=<span class="number">0</span>)[<span class="number">1</span>])[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">return</span> xmin, xmax, ymin, ymax</span><br><span class="line"><span class="built_in">row</span> = <span class="number">26</span></span><br><span class="line">fig,ax=plt.subplots(<span class="built_in">row</span>,<span class="number">2</span>,figsize=(<span class="number">16</span>,<span class="number">6</span>*<span class="built_in">row</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">row</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        xmin, xmax, ymin, ymax = find_bounding(segdata[i*<span class="number">2</span>+j])</span><br><span class="line">        ax[i,j].imshow(transform_rgb(segdata[i*<span class="number">2</span>+j][(xmin-<span class="number">10</span>): (xmax+<span class="number">10</span>), (ymin-<span class="number">10</span>): (ymax+<span class="number">10</span>)]))</span><br></pre></td></tr></table></figure>
<ul>
<li>remove Schwann cell to concentrate on axons</li>
</ul>
<p>First it has some problems</p>
<p><img src="http://i2.tiimg.com/640680/2a5303ed7c054769.png" alt="Markdown"></p>
<p>Then I separately plot and find the black wrong region is 25 and 38</p>
<p>After correction:</p>
<p><img src="http://i2.tiimg.com/640680/96c7c89bc409d6ba.png" alt="Markdown"></p>
<ul>
<li>convert the segment array to binary mask</li>
</ul>
<p><img src="http://i2.tiimg.com/640680/070eef826c0612ae.png" alt="Markdown"></p>
<ul>
<li>Make sure each mask and EM data are in same bounding box</li>
</ul>
<p><img src="http://i2.tiimg.com/640680/2b1b68b735d93e29.png" alt="Markdown"></p>
<ul>
<li>Generate contours as training set label<br>opencv’s findcontour function is not suitable for same grayscale image, so I use erode and dilation<figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">open = cv2.erode(grayimg, None, iterations = 4)</span><br><span class="line">open1 = cv2.dilate(open, None, iterations = 3)</span><br><span class="line">imshow(open1-open)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="http://i2.tiimg.com/640680/c9d99655bdaf9cac.png" alt="Markdown"></p>
<ul>
<li>Padding for same image size<br>Do reflection padding on each image to generate images with same size.</li>
</ul>
<p><img src="http://i2.tiimg.com/640680/06d9ead45f4caa9a.png" alt="Markdown"></p>
<p>The margin is the reflection of the original image<br>Store in HDF5</p>
<ul>
<li>Save image and label as HDF5<br>EM data as training set’s image and contour as label</li>
</ul>
<p>Save as uint8   (51, 530, 835)</p>
<h3 id="Train-membrane-prediction-model"><a href="#Train-membrane-prediction-model" class="headerlink" title="Train membrane prediction model"></a>Train membrane prediction model</h3><p>Input image and label are the 51 bundle sections.</p>
<p><strong>Train model args:</strong><br>Run on two machines: one with one gpu and another with 4 gpus</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0729mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">40000</span> --volume-save <span class="number">2000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">12</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0729mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">40000</span> --volume-save <span class="number">2000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">6</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#-lt <span class="number">4</span> focal and dice loss</span><br></pre></td></tr></table></figure>
<p>References:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span> python3 -u bin/synapse_pytorch/train<span class="selector-class">.py</span> -t data/cremi/ -dn images/im_A_v2_200.h5@images/im_B_v2_200.h5@images/im_C_v2_200<span class="selector-class">.h5</span> -ln gt-syn/syn_A_v2_200.h5@gt-syn/syn_B_v2_200.h5@gt-syn/syn_C_v2_200<span class="selector-class">.h5</span> -o outputs/cremi0719mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">20000</span> -mi <span class="number">24</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">2</span> -c <span class="number">6</span> -<span class="selector-tag">b</span> <span class="number">2</span> -l mix</span><br><span class="line"><span class="selector-id">#b</span>:<span class="number">6</span>  try to keep gpu and batch size same</span><br></pre></td></tr></table></figure>
<p>The hp003 memory is small, also train on hpc</p>
<h4 id="Check-loss"><a href="#Check-loss" class="headerlink" title="Check loss"></a>Check loss</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard <span class="attribute">--logdir</span>=outputs/nmj0729mixloss</span><br></pre></td></tr></table></figure>
<p>Monitor loss and test on new EM image. If is good, train it longer with more GPUs</p>
<p>Train loss( DICE + Focal loss)</p>
<p><img src="http://i2.tiimg.com/640680/68a5d5858d2eca5f.png" alt="Markdown"></p>
<p>Focal loss</p>
<p><img src="http://i2.tiimg.com/640680/14e81611ee917fa6.png" alt="Markdown"></p>
<p>Dice loss</p>
<p><img src="http://i2.tiimg.com/640680/20dac5fc8da5ae1f.png" alt="Markdown"></p>
<p>It seems that the combined loss and both focal and dice loss decrease well.</p>
<h4 id="real-time-monitoring-predicted-result"><a href="#real-time-monitoring-predicted-result" class="headerlink" title="real time monitoring predicted result"></a>real time monitoring predicted result</h4><p>Use TensorboardX to monitor predicted results:</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment">#draw image every 20 batches</span></span><br><span class="line">            writer.add_image(<span class="string">'EM image '</span>+str(i),</span><br><span class="line">                             torchvision.utils.make_grid(<span class="keyword">volume</span><span class="bash">), i)</span></span><br><span class="line"><span class="bash">            writer.add_image(<span class="string">'GT image '</span>+str(i), torchvision.utils.make_grid(label), i)</span></span><br><span class="line"><span class="bash">            writer.add_image(<span class="string">'predict image '</span>+str(i), torchvision.utils.make_grid(output), i)</span></span><br></pre></td></tr></table></figure>
<p>This will allow me to see the improvement of model’s performance more clearly.</p>
<p>EM in 3680th batches</p>
<p><img src="http://i2.tiimg.com/640680/6ba0407959138c82.png" alt="Markdown"></p>
<p>Ground truth in 3680th batches</p>
<p><img src="http://i2.tiimg.com/640680/83ebcf388707f0a6.png" alt="Markdown"></p>
<p>Predicted in 3680th batches</p>
<p><img src="http://i2.tiimg.com/640680/f618886ef775eb3c.png" alt="Markdown"></p>
<p>Then I will predict new EM image which is preprocessed by the previous steps. Then do proofreading on the predicted membrane. Then do distance transformation to generate seeds.</p>
<hr>
<h1 id="Week-5-amp-6"><a href="#Week-5-amp-6" class="headerlink" title="Week 5 &amp; 6"></a>Week 5 &amp; 6</h1><h1 id="predict-on-EM"><a href="#predict-on-EM" class="headerlink" title="predict on EM"></a>predict on EM</h1><ul>
<li>prepare predict data</li>
<li>export mask1 em</li>
<li>Mip level 3, it is really important to keep the resolution same( realize it after several failures)</li>
<li>set to window</li>
<li>bad slices record, replace by the previous layer</li>
</ul>
<p><strong>Record export coordinates</strong></p>
<pre><code>- 0-80: 10809-20685  5448-11102
- 81-144 9200-19076   4649-10303
- 145-182 8193-18069  4104-9758
- 183-219  7337-17213  3792-9446
- 220-265 6496-16372  3584-9238
- 266-292   55509-15385    3241-8895
- 293-300 4590-14466   2914-8568
</code></pre><p><strong>Test commands</strong><br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em.h5 -o outputs/mask1output -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0729mixloss/volume_40000.pth -c <span class="number">12</span> -b <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>see results:<br><a href="http://127.0.0.1:8889/notebooks/projects/membrane/jupyter/visualize_prediction_result.ipynb" target="_blank" rel="noopener">http://127.0.0.1:8889/notebooks/projects/membrane/jupyter/visualize_prediction_result.ipynb</a></li>
</ul>
<p>Not good, check very bad slices and deflicker<br>Try to train for a longer time</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0731retrain -lr <span class="number">0.0005</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -c <span class="number">8</span> -b <span class="number">3</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0729mixloss -lr <span class="number">0.001</span> --volume-total <span class="number">40000</span> --volume-save <span class="number">2000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">6</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#-lt <span class="number">4</span> focal and dice loss</span><br></pre></td></tr></table></figure>
<p>It seems the results of membrane prediction isn’t very good. Needs many post process work. For example, one way is to use a deep learning model like U-net to predict affinity and close the membrane.</p>
<p><img src="http://i4.fuimg.com/640680/080f9880226ba6e5.png" alt="Markdown"></p>
<h4 id="preprocess"><a href="#preprocess" class="headerlink" title="preprocess"></a>preprocess</h4><p><strong>Deflickering work</strong><br>I use deflickering codes to smooth the contrast.</p>
<ul>
<li>[ ] <a href="https://github.com/donglaiw/EM-preprocess/blob/master/script/T_deflicker.py" target="_blank" rel="noopener">EM-preprocess/T_deflicker.py at master · donglaiw/EM-preprocess · GitHub</a><br>20 sec to process a volume with data size 100x1024x1024 using online version of deflickering</li>
</ul>
<p><img src="http://i4.fuimg.com/640680/493a642ca564813f.png" alt="Markdown"></p>
<h4 id="try-to-predict-directly-on-masks-Not-the-membrane"><a href="#try-to-predict-directly-on-masks-Not-the-membrane" class="headerlink" title="try to predict directly on masks. Not the membrane"></a>try to predict directly on masks. Not the membrane</h4><p>It may have some advantages: do not need to be precise, we can perform distance transformation on the predicted masks to get the seed. And it will be better to track and automatically assign labels using masks instead of seeds.</p>
<p><img src="http://i2.tiimg.com/640680/96c7c89bc409d6ba.png" alt="Markdown"></p>
<p>Comparison of mask and membrane:<br><img src="http://i4.fuimg.com/640680/743789aaa8f0fe9f.png" alt="Markdown"></p>
<h3 id="7-31-retrain-on-deflicker-data"><a href="#7-31-retrain-on-deflicker-data" class="headerlink" title="7.31 retrain on deflicker data"></a>7.31 retrain on deflicker data</h3><p>volume_168000.pth<br>data/mask1/deflicker_em.h5</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span> python3 -u bin/test.py -t data/mask1/ -dn deflicker_em.h5 -o outputs/mask1output8<span class="number">.01</span>deflicker -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -m outputs/nmj0801retrain/volume_156000.pth -c <span class="number">3</span> -b <span class="number">3</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0731debug -lr <span class="number">0.0005</span> --volume-total <span class="number">4000</span> --volume-save <span class="number">1000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">3</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn deflicker_em.h5 -o outputs/mask1outputdebug -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0731retrain/volume_4002.pth -c <span class="number">6</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>Model structure has problems<br>Retrain on previous model</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0801retrain -lr <span class="number">0.0001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -c <span class="number">8</span> -b <span class="number">3</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0731retrain/volume_200001.pth</span><br></pre></td></tr></table></figure>
<p>Train on segment data</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51_ -o outputs/nmj0801segment -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">3</span> -c <span class="number">8</span> -b <span class="number">3</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>It is weird that after some training, the test results have nothing</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">5</span> python3 -u bin/train.py -t data/train_set/ -dn em_51 -ln mask_51 -o outputs/nmj0801after -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">8</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>Add image augmentation, adjust intensity augmentation. Decrease contrast and brightness ratio, it will severely influence converge.</p>
<h4 id="NMJ-manually-labeling-work"><a href="#NMJ-manually-labeling-work" class="headerlink" title="NMJ manually labeling work"></a>NMJ manually labeling work</h4><p>First I start randomly from a terminal or axon. Then Jeff recommended it is better to start from axons. I use the latter method to manually label <strong>two NMJs</strong> for using one week.</p>
<p>At first it seems very hard to track and label NMJs. The boundary is unclear and I have little experience on labeling NMJs, it is a lot harder to label NMJs than labeling on the main bundle.</p>
<p>I will try to label maybe more <strong>5 NMJs</strong> to collect enough data to test the linear hypothesis: <strong>the correlation of axon caliber and terminal area.</strong> If we can prove that, we can save a lot of time: we can just dense segment on axons and calculate the corresponding terminal area. And we only need tracing on the terminals.</p>
<p>I will try to reslice the labeled NMJs to calculate the axon caliber. It seems VTK is a good tool to do reslice on any arbitrary orientation reslice.</p>
<h4 id="Add-more-data-for-automatic-pipeline"><a href="#Add-more-data-for-automatic-pipeline" class="headerlink" title="Add more data for automatic pipeline"></a>Add more data for automatic pipeline</h4><ul>
<li>[ ] 代码 <a href="http://140.247.107.75:8889/notebooks/projects/membrane/jupyter/extract_membrane_from_marco.ipynb" target="_blank" rel="noopener">Jupyter Notebook</a><br>I processed marco’s data for training. It is really precious, we easily increase our data from 51 images to 1440 images. It is really helpful if we have more.</li>
</ul>
<figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> h5py.<span class="keyword">File</span>(<span class="string">'data/train_set/marco_1435_mask'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.create_dataset(<span class="string">'main'</span>,data= paddedmask,dtype =uint8)</span><br><span class="line"><span class="keyword">with</span> h5py.<span class="keyword">File</span>(<span class="string">'data/train_set/marco_1435_membrane'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.create_dataset(<span class="string">'main'</span>,data= paddedmaskmem,dtype =uint8)</span><br></pre></td></tr></table></figure>
<p><img src="http://i4.fuimg.com/640680/8c9abba357fcb56c.png" alt="Markdown"></p>
<p><img src="http://i4.fuimg.com/640680/ad6c8f42a22e89f1.png" alt="Markdown"></p>
<p><img src="http://i4.fuimg.com/640680/db41e29e1b9c045a.png" alt="Markdown"></p>
<h3 id="updated-pipeline"><a href="#updated-pipeline" class="headerlink" title="updated pipeline"></a>updated pipeline</h3><ul>
<li>segmentation first, doesn’t need to be very precise. </li>
<li>Then do distance transform and find the seed. It is easy to find connected component and then do distance transform to get seeds.</li>
<li><p>Test distance transform and hungarian matching on marco’s data.</p>
</li>
<li><p>[ ]  代码<a href="http://140.247.107.75:8889/notebooks/projects/membrane/jupyter/extract_membrane_from_marco.ipynb" target="_blank" rel="noopener">Jupyter Notebook</a></p>
</li>
</ul>
<p>8.3  training</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0804segmentmarcodata -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0805segmentmarcodataretrain -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0805segmentmarcodataretrain/volume_4000.pth</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em.h5 -o outputs/mask1output8<span class="number">.04</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0804segmentmarcodata/volume_108000.pth -c <span class="number">2</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4 id="resolution-matters"><a href="#resolution-matters" class="headerlink" title="resolution matters!"></a>resolution matters!</h4><p>It seems that the resolution influence the prediction. We should keep the training and test data in the same resolution!</p>
<p>Record test data’s export coordinates:</p>
<pre><code>- 0-80: 10809-20685  5448-11102
- 81-144 9200-19076   4649-10303
- 145-182 8193-18069  4104-9758
- 183-219  7337-17213  3792-9446
- 220-265 6496-16372  3584-9238
- 266-292   55509-15385    3241-8895
- 293-300 4590-14466   2914-8568
</code></pre><p>Try <strong>mip4</strong> result</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em_mip4.h5 -o outputs/mask1output8<span class="number">.05</span>mip4 -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0804segmentmarcodata/volume_108000.pth -c <span class="number">2</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p><img src="http://i4.fuimg.com/640680/c8462edb973660e0.png" alt="Markdown"></p>
<p>Result still not good: some axons are not predicted.<br>Maybe the noise has a big influence. And the proposed region isn’t enough.  Maybe DICE loss function influence the False positive region.</p>
<p>Try only BCE</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0805segmentmarcodataBCE -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">1</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/test.py -t data/mask1/ -dn mask1_em_mip4.h5 -o outputs/mask1output8<span class="number">.07</span>mip4 -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -m outputs/nmj0805segmentmarcodataBCE/volume_160000.pth -c <span class="number">2</span> -b <span class="number">1</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#<span class="number">8.7</span> retrain</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0807segmentmarcodataretrain -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">1</span> -c <span class="number">4</span> -b <span class="number">1</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0805segmentmarcodataBCE/volume_160000.pth</span><br></pre></td></tr></table></figure>
<p>Results still not good<br><img src="http://i4.fuimg.com/640680/81ada9efd84b2bb8.png" alt="Markdown"></p>
<h4 id="8-11-new-try"><a href="#8-11-new-try" class="headerlink" title="8.11 new try"></a>8.11 new try</h4><p>Previous computing resource isn’t enough. Only have one gpu on the machine. I use RC cluster to do the computing. It has many gpus to use. Setting some environment and softwares to computing.</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">srun <span class="params">--pty</span> -p cox -t 7-00<span class="function">:00</span> <span class="params">--mem</span> 100000 -n 8 <span class="params">--gres=gpu</span><span class="function">:4</span> <span class="string">/bin/bash</span></span><br><span class="line">srun <span class="params">--pty</span> -p cox -t 7-00<span class="function">:00</span> <span class="params">--mem</span> 200000 -n 2 <span class="params">--gres=gpu</span><span class="function">:1</span> <span class="string">/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#control D exit</span></span><br><span class="line"><span class="comment">#squeue/sacct check job</span></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> add all other SBATCH directives here...</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -p cox</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH --gres=gpu:4</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH --constraint=titanx</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -n 8 <span class="comment"># Number of cores</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -N 1 <span class="comment"># Ensure that all cores are on one machine</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH --mem=100000</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -t 5-00:00:00</span></span><br><span class="line"><span class="meta">#</span><span class="bash">SBATCH -o logs/train_%j.log</span></span><br><span class="line"></span><br><span class="line">module load cuda</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=0,1,2,3 python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj08011segmentmarcodataretrain -lr 0.001 --volume-total 400000 --volume-save 4000 -mi 4,256,256 -g 4 -c 8 -b 4 -lt 4 -ac 2 -ft True -pm outputs/nmj0811membranemarcodata/volume_12000.pth</span><br><span class="line"><span class="meta">#</span><span class="bash"> end of program</span></span><br><span class="line">exit 0;</span><br></pre></td></tr></table></figure>
<p>Working dir on rc<br>/n/coxfs01/xupeng/projects/membrane<br>Scp -r hp003 to rc<br>Install anaconda2 and 3<br>Install pytorch(0.4.0)  keras and tensorflow<br>tensorboardX 1.2 torchvision0.2</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> keras</span><br><span class="line">pip <span class="keyword">install</span> tensorflow-gpu</span><br><span class="line">conda <span class="keyword">install</span> pytorch torchvision -c pytorch</span><br></pre></td></tr></table></figure>
<p>train with 4 gpus<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj0811membranemarcodata -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">12</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -c <span class="number">8</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span></span><br><span class="line"></span><br><span class="line">#retrain</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python3 -u bin/train.py -t data/train_set/marco/ -dn marco_1435_em -ln marco_1435_mask -o outputs/nmj08012segmentmarcodataretrain -lr <span class="number">0.001</span> --volume-total <span class="number">400000</span> --volume-save <span class="number">4000</span> -mi <span class="number">4</span>,<span class="number">256</span>,<span class="number">256</span> -g <span class="number">4</span> -c <span class="number">8</span> -b <span class="number">4</span> -lt <span class="number">4</span> -ac <span class="number">2</span> -ft True -pm outputs/nmj0811membranemarcodata/volume_12000.pth</span><br></pre></td></tr></table></figure></p>
<p><strong>Thoughts about the not perfect results:</strong></p>
<ul>
<li>Maybe 3D U-net model is too large to train, intensity has influence. </li>
<li>The pattern difference is large, we may use the similar one with larger weights. </li>
<li>We may need some more design to predict many separate regions and consider the continuity. Consider higher resolution.</li>
</ul>
<h4 id="2D-D-Linknet"><a href="#2D-D-Linknet" class="headerlink" title="2D D-Linknet"></a>2D D-Linknet</h4><p>I started to build a new deep learning model. I use 2D U-net instead of 3D to train is easier. It is different with U-net, but also effective in predicting segments.</p>
<p><img src="http://i4.fuimg.com/640680/87378f2e7ea1db4c.png" alt="Markdown"></p>
<p>D-LinkNet uses Linknet with pretrained encoder as its backbone and has additional dilated convolution layers in the center part. Linknet is an efficient semantic segmentation<br>neural network which takes the advantages of skip connections, residual blocks and encoder-decoder architecture. The original Linknet uses ResNet18 as its encoder, which is a pretty light but outperforming network. Linknet has shown high precision on several benchmarks, and it runs pretty fast.</p>
<p>I also use dilation CNN, Dilated convolution is a useful kernel to adjust receptive<br>fields of feature points without decreasing the resolution of feature maps. It was widely used recently.</p>
<p>I set the image input shape as 1024*1024, so I reprocess Marco data, export Mip level 0. Change the export ROI for better ROI and more precise resolution. Change the channels for resnet.</p>
<p><img src="http://i4.fuimg.com/640680/4d964d4ee16a7e7a.png" alt="Markdown"></p>
<p>I will keep on modifying the model and build up the whole training pipeline including several efficient data augmentation methods. And then do test on the mask data.</p>

      
    </div>
    
    
    

    

    <div>
    
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-----The ---- end ----<i class="fa fa-paw"></i>--- Thanks --- for --- Reading----</div>
    
</div>

    
    </div>

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/deep-learning/" rel="tag"><i class="fa fa-tag"></i> deep learning</a>
          
            <a href="/tags/project/" rel="tag"><i class="fa fa-tag"></i> project</a>
          
            <a href="/tags/summer-intern/" rel="tag"><i class="fa fa-tag"></i> summer intern</a>
          
            <a href="/tags/neural-science/" rel="tag"><i class="fa fa-tag"></i> neural science</a>
          
            <a href="/tags/Jeff-Lichtman/" rel="tag"><i class="fa fa-tag"></i> Jeff Lichtman</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/20/wittgenstein_bio/" rel="next" title="Wittgenstein’s love and philosophy">
                <i class="fa fa-chevron-left"></i> Wittgenstein’s love and philosophy
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/14/summerintern_Synapse_Prediction/" rel="prev" title="Synapse Prediction">
                Synapse Prediction <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="James Chen" />
            
              <p class="site-author-name" itemprop="name">James Chen</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">58</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">44</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/james20141606" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:xp-chen14@mails.tsinghua.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#First-two-weeks"><span class="nav-number">1.</span> <span class="nav-text">First two weeks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Future-work"><span class="nav-number">1.1.</span> <span class="nav-text">Future work</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-3"><span class="nav-number">2.</span> <span class="nav-text">Week 3</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#mask-and-seeding"><span class="nav-number">2.1.</span> <span class="nav-text">mask and seeding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#discussion-on-mask"><span class="nav-number">2.2.</span> <span class="nav-text">discussion on mask</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#My-thought-about-how-the-whole-project"><span class="nav-number">2.3.</span> <span class="nav-text">My thought about how the whole project</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Seeding-on-Mask3"><span class="nav-number">2.3.1.</span> <span class="nav-text">Seeding on Mask3</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Automatic-pipeline"><span class="nav-number">2.4.</span> <span class="nav-text">Automatic pipeline</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Predict-Membrane"><span class="nav-number">2.4.1.</span> <span class="nav-text">Predict Membrane</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Automatically-seeding"><span class="nav-number">2.4.2.</span> <span class="nav-text">Automatically seeding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#segmentation"><span class="nav-number">2.4.3.</span> <span class="nav-text">segmentation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Merge-masks"><span class="nav-number">2.4.4.</span> <span class="nav-text">Merge masks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Algorithm"><span class="nav-number">2.5.</span> <span class="nav-text">Algorithm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Predict-Membrane-1"><span class="nav-number">2.5.1.</span> <span class="nav-text">Predict Membrane</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Automatically-seeding-1"><span class="nav-number">2.5.2.</span> <span class="nav-text">Automatically seeding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Watershed"><span class="nav-number">2.5.3.</span> <span class="nav-text">Watershed</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Useful-resources"><span class="nav-number">2.5.4.</span> <span class="nav-text">Useful resources</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Work-on-membrane-prediction"><span class="nav-number">2.6.</span> <span class="nav-text">Work on membrane prediction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Prepare-ground-truth-training-set"><span class="nav-number">2.6.1.</span> <span class="nav-text">Prepare ground truth training set</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Train-membrane-prediction-model"><span class="nav-number">2.6.2.</span> <span class="nav-text">Train membrane prediction model</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Check-loss"><span class="nav-number">2.6.2.1.</span> <span class="nav-text">Check loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#real-time-monitoring-predicted-result"><span class="nav-number">2.6.2.2.</span> <span class="nav-text">real time monitoring predicted result</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Week-5-amp-6"><span class="nav-number">3.</span> <span class="nav-text">Week 5 &amp; 6</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#predict-on-EM"><span class="nav-number">4.</span> <span class="nav-text">predict on EM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#preprocess"><span class="nav-number">4.0.0.1.</span> <span class="nav-text">preprocess</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#try-to-predict-directly-on-masks-Not-the-membrane"><span class="nav-number">4.0.0.2.</span> <span class="nav-text">try to predict directly on masks. Not the membrane</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-31-retrain-on-deflicker-data"><span class="nav-number">4.0.1.</span> <span class="nav-text">7.31 retrain on deflicker data</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#NMJ-manually-labeling-work"><span class="nav-number">4.0.1.1.</span> <span class="nav-text">NMJ manually labeling work</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Add-more-data-for-automatic-pipeline"><span class="nav-number">4.0.1.2.</span> <span class="nav-text">Add more data for automatic pipeline</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#updated-pipeline"><span class="nav-number">4.0.2.</span> <span class="nav-text">updated pipeline</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#resolution-matters"><span class="nav-number">4.0.2.1.</span> <span class="nav-text">resolution matters!</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-11-new-try"><span class="nav-number">4.0.2.2.</span> <span class="nav-text">8.11 new try</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2D-D-Linknet"><span class="nav-number">4.0.2.3.</span> <span class="nav-text">2D D-Linknet</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">James Chen</span>

  
</div>



  <span class="post-meta-divider">|</span>




<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共123.8k字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  



  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("klOjl0RBA8qP5IKgIXkOszBr-gzGzoHsz", "rCaN5wX4mjiRkRMzP95g7XHz");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  


  

  

  
</body>
</html>
