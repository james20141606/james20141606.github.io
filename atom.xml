<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>James Chen&#39;s Blogs</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://james20141606.github.io/"/>
  <updated>2018-04-16T06:07:35.541Z</updated>
  <id>http://james20141606.github.io/</id>
  
  <author>
    <name>James Chen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>multi0</title>
    <link href="http://james20141606.github.io/2018/04/16/multi0/"/>
    <id>http://james20141606.github.io/2018/04/16/multi0/</id>
    <published>2018-04-16T06:07:35.000Z</published>
    <updated>2018-04-16T06:07:35.541Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>line2</title>
    <link href="http://james20141606.github.io/2018/04/16/line2/"/>
    <id>http://james20141606.github.io/2018/04/16/line2/</id>
    <published>2018-04-16T06:07:29.000Z</published>
    <updated>2018-04-16T06:07:29.397Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>line1</title>
    <link href="http://james20141606.github.io/2018/04/16/line1/"/>
    <id>http://james20141606.github.io/2018/04/16/line1/</id>
    <published>2018-04-16T06:07:26.000Z</published>
    <updated>2018-04-16T06:07:26.086Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Linear Regression Assignment 4</title>
    <link href="http://james20141606.github.io/2018/04/16/line0/"/>
    <id>http://james20141606.github.io/2018/04/16/line0/</id>
    <published>2018-04-16T04:59:19.000Z</published>
    <updated>2018-04-16T06:10:54.489Z</updated>
    
    <content type="html"><![CDATA[<p>The fourth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.<br><a id="more"></a><br>You may also find the <strong>PDF Version</strong> of this assignment. Which is more recommended:</p><p><div class="row">    <embed src="&lt;a" width="100%" height="550" type="application/pdf"></div></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The fourth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;br&gt;
    
    </summary>
    
      <category term="school work" scheme="http://james20141606.github.io/categories/school-work/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="R" scheme="http://james20141606.github.io/tags/R/"/>
    
      <category term="assignment" scheme="http://james20141606.github.io/tags/assignment/"/>
    
      <category term="linear regression" scheme="http://james20141606.github.io/tags/linear-regression/"/>
    
  </entry>
  
  <entry>
    <title>春日の恋想</title>
    <link href="http://james20141606.github.io/2018/04/15/peomofmeng/"/>
    <id>http://james20141606.github.io/2018/04/15/peomofmeng/</id>
    <published>2018-04-15T05:54:30.000Z</published>
    <updated>2018-04-15T13:13:00.755Z</updated>
    
    <content type="html"><![CDATA[<p>就像pdf文档里所说的那样，这组诗作于2013年春⽇在郑州外国语学校就读期间，我十七岁，孟孟年方二八，正是豆蔻年华，如今看起来有些羞涩的文字却是那个时候的真情流露，并不觉得夸张。人们总是喜欢用青涩形容自己年轻的岁月，我却一直秉持着大胆地做自己想做的事情的原则，因此青春中做了很多美好的值得回味的，不落于俗套的美好事情。这一路来所做所想，都是自己所爱，能够在自己多年来心仪的学校继续和多年来心爱的姑娘经历生活的美好与平淡，实在是人生的幸运。<br><a id="more"></a><br>原诗曾记录整理于高中的电⼦词典中，并⼀⼀抄录于⼿折玫瑰中赠予孟孟。那个春天每天晚上一朵纸折的玫瑰，如今还能回忆起春风沉醉，空气温暖，眼眸明亮，笑容可人，这些是刻在记忆里了，以及这些文字，在2018 年1 ⽉30 ⽇整理旧寝室的物品的时候，发现还完好无损地躺在我的电子词典中，于是导出，重新用LaTeX排了版，如今也放在这里，希望可以和记忆一起永恒。</p><div class="row"><iframe src="https://drive.google.com/open?id=1lNCiSdpfv9scaQ1fHKt49UWHLv59rKjv/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;就像pdf文档里所说的那样，这组诗作于2013年春⽇在郑州外国语学校就读期间，我十七岁，孟孟年方二八，正是豆蔻年华，如今看起来有些羞涩的文字却是那个时候的真情流露，并不觉得夸张。人们总是喜欢用青涩形容自己年轻的岁月，我却一直秉持着大胆地做自己想做的事情的原则，因此青春中做了很多美好的值得回味的，不落于俗套的美好事情。这一路来所做所想，都是自己所爱，能够在自己多年来心仪的学校继续和多年来心爱的姑娘经历生活的美好与平淡，实在是人生的幸运。&lt;br&gt;
    
    </summary>
    
      <category term="life" scheme="http://james20141606.github.io/categories/life/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="girl friend" scheme="http://james20141606.github.io/tags/girl-friend/"/>
    
      <category term="poem" scheme="http://james20141606.github.io/tags/poem/"/>
    
  </entry>
  
  <entry>
    <title>Data Mining of Deng Era</title>
    <link href="http://james20141606.github.io/2018/04/15/datamining/"/>
    <id>http://james20141606.github.io/2018/04/15/datamining/</id>
    <published>2018-04-14T16:55:43.000Z</published>
    <updated>2018-04-15T08:26:50.362Z</updated>
    
    <content type="html"><![CDATA[<p>期中作业之一是写一篇邓小平时代的读后感，说实话这种书是实在没空读了，虽然粗略地翻了几章，十分吸引人，但是这两年真的越来越讨厌写文科式的论文，瞎胡诌凑字数曾经也是我作为理科生的优势，但是这一两年对这种风格的文章：东拼西凑，无病呻吟，迷茫又自负的写作非常地厌恶。因为就想玩点花样，做点简单的文本数据挖掘凑凑字数，虽然多花了很多时间，但是毕竟很有意思，有意思的事情就不算浪费时间对吧，没有意思的事情，哪怕一分钟也是对生命的浪费呢。<br><a id="more"></a><br>中文分词是个很好玩的事情，但是jieba和THULAC之类的工具已经把中文分词和词性标注之类的变得很简单，最折腾的，花了我很久时间的是这本中文材料。。。matplotlib本身不支持英文绘图，python的encoding方式也让我折腾了很久，竟然做了很久装卸各种包的工作，，，直到最后奇葩的matplotlib就是找不到字体，不管在本地还是在几个服务器上竟然都不行，于是只好测试好代码让斌斌帮忙在他的账户跑一下。下面简单记一下过程和代码，最后再把自己胡乱拼凑的论文也扔上。</p><p>代码也放到<a href="https://github.com/james20141606/somethingmore/datamining_dxp" target="_blank" rel="noopener">GitHub</a>上了,里面附有jupyter版本的代码和可以直接运行产生各种类型图片的代码。</p><h1 id="对邓小平时代的分词与词频统计"><a href="#对邓小平时代的分词与词频统计" class="headerlink" title="对邓小平时代的分词与词频统计"></a>对邓小平时代的分词与词频统计</h1><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p><strong>convert to UTF-8 format</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">file ip.txt</span><br><span class="line"><span class="comment">#use vim to change encoding format</span></span><br><span class="line">:<span class="builtin-name">set</span> <span class="attribute">fileencoding</span>=utf-8</span><br></pre></td></tr></table></figure></p><p>首先是找到txt版本的邓小平时代资源，用utf-8编码，方便后续处理。</p><h2 id="分词与词频统计"><a href="#分词与词频统计" class="headerlink" title="分词与词频统计"></a>分词与词频统计</h2><p>想做词频统计分析，就得对文本进行分词，中文和英文不同，英文单词是孤立的，而中文单词需要人工分开，这里我找了一个比较经典的分词方法，<strong>Jieba分词</strong>，对整本书进行了分词处理，把每句话都给分开，存储了各个名词，并且顺便统计了一下出现频次前10000的所有词语。因此我通过代码可以获取以下<strong>两个文件</strong>：</p><p>被分词分开的全书“词汇”，按顺序一个个存储起来，以及对各个词汇出现频次的统计文件。接下来就可以对数据进行进一步的分析。</p><p><strong>Use Jieba for Chinese words partition</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, codecs  </span><br><span class="line"><span class="keyword">import</span> jieba  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter </span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">plt.rcParams[<span class="string">'font.style'</span>] = <span class="string">u'normal'</span></span><br><span class="line">plt.rcParams[<span class="string">'font.family'</span>] = <span class="string">u'Microsoft YaHei'</span></span><br><span class="line"><span class="keyword">with</span> codecs.open(<span class="string">'output.txt'</span>, <span class="string">'r'</span>, <span class="string">'utf8'</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    txt = f.read() </span><br><span class="line">seg_list = jieba.cut(txt) </span><br><span class="line">c = Counter()  </span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> seg_list:  </span><br><span class="line">    <span class="keyword">if</span> len(x)&gt;<span class="number">1</span> <span class="keyword">and</span> x != <span class="string">'\r\n'</span>:  </span><br><span class="line">        c[x] += <span class="number">1</span></span><br><span class="line">np.savetxt(<span class="string">'count10000.txt'</span>,np.array(c.most_common(<span class="number">10000</span>)),fmt=<span class="string">'%s'</span>)</span><br><span class="line">data = np.loadtxt(<span class="string">'count10000.txt'</span>,dtype=<span class="string">'str'</span>)</span><br><span class="line"><span class="keyword">with</span> codecs.open(<span class="string">'output.txt'</span>, <span class="string">'r'</span>, <span class="string">'utf8'</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    txt = f.read() </span><br><span class="line">wordlist = np.array(txt.split(<span class="string">' '</span>))</span><br><span class="line"><span class="comment">#wordlist.shape</span></span><br><span class="line">countlist = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    countlist.append(data[i,<span class="number">0</span>]+<span class="string">': '</span>+str(data[i,<span class="number">1</span>]))</span><br><span class="line">pd.DataFrame(np.array(countlist)[:<span class="number">200</span>].reshape(<span class="number">20</span>,<span class="number">10</span>)).head()</span><br></pre></td></tr></table></figure></p><p>然后选取最靠前的200个词语制出来一张表格，从这个表格里还是可以看出一些信息量的，还是很有趣的。比如毛泽东作为中国近现代史的第一人物，是本书除了邓小平之外绕不开的第二号人物。干部一词也反复出现，在中国这是个非常重要的词语，很多东西都取决于干部之间的博弈和关系。北京作为政治中心和中国的代名词，自然也反复出现，而国家和地区层面，美国，苏联、日本和中国台湾也榜上有名，广东作为非常重要的试验地点，被提及的频率也相当的高。人物上，胡耀邦、陈云、赵紫阳、周恩来也都出现了多次。军队、学生等关键词也出现次数不少。</p><p>除此之外还有年份也引人关注，比如1975、1977、1979、1980、1989等关键节点也都帮上有名。</p><p><img src="http://i4.bvimg.com/640680/f405c02d19042f6b.png" alt="Markdown"></p><h2 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h2><p><strong>除此之外，我还对一些非常重要的关键词画了一些可视化的图，这里选取一些放上来。</strong></p><h3 id="bar-plot"><a href="#bar-plot" class="headerlink" title="bar plot"></a>bar plot</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">namelist = [<span class="string">u'邓小平'</span>,<span class="string">u'中国'</span>,<span class="string">u'毛泽东'</span>,<span class="string">u'工作'</span>,<span class="string">u'干部'</span>,<span class="string">u'问题'</span>,<span class="string">u'北京'</span>,<span class="string">u'美国'</span>,<span class="string">u'领导人'</span>,<span class="string">u'会议'</span>,<span class="string">u'经济'</span>,<span class="string">u'关系'</span>,<span class="string">u'香港'</span>,<span class="string">u'1975'</span>,<span class="string">u'领导'</span>,<span class="string">u'胡耀邦'</span>,<span class="string">u'苏联'</span>,<span class="string">u'政治'</span>,<span class="string">u'支持'</span>,</span><br><span class="line"><span class="string">u'军队'</span>,<span class="string">u'陈云'</span>,<span class="string">u'政策'</span>,<span class="string">u'赵紫阳'</span>,<span class="string">u'周恩'</span>,<span class="string">u'讲话'</span>,<span class="string">u'学生'</span>,<span class="string">u'华国锋'</span>,<span class="string">u'改革'</span>,<span class="string">u'日本'</span>]</span><br><span class="line">index_25 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">11</span>,<span class="number">12</span>,<span class="number">14</span>,<span class="number">16</span>,<span class="number">20</span>,<span class="number">21</span>,<span class="number">23</span>,<span class="number">26</span>,<span class="number">27</span>,<span class="number">28</span>,<span class="number">31</span>,<span class="number">33</span>,<span class="number">37</span>,<span class="number">39</span>,<span class="number">40</span>,<span class="number">42</span>,<span class="number">46</span>,<span class="number">47</span>,<span class="number">48</span>,<span class="number">49</span>]</span><br><span class="line">count = <span class="number">27</span></span><br><span class="line">fig,ax=plt.subplots(<span class="number">1</span>,figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">ax.bar(range(count),data[index_25,<span class="number">1</span>].astype(<span class="string">'int'</span>),color = <span class="string">'b'</span>)</span><br><span class="line"><span class="comment">#ax.bar(range(count),data[:count,1].astype('int'))</span></span><br><span class="line">ax.set_xticks(range(count))</span><br><span class="line">ax.set_xticklabels(namelist)</span><br><span class="line"><span class="comment">#plt.savefig('tst.png')</span></span><br><span class="line">ax.set_title(str(count)+<span class="string">' key words frequency in book'</span>)</span><br></pre></td></tr></table></figure><p>比如这个显示前二十个关键词的bar plot，可以发现相当有趣的现象，在一本书中的关键词分布竟然也挺像幂率分布，某两三个关键词频次非常高，然后是一堆比较重要的关键词，这个也很有趣。<br><img src="http://i4.bvimg.com/640680/9190c33461d494bd.png" alt="Markdown"></p><h3 id="fluctuation"><a href="#fluctuation" class="headerlink" title="fluctuation"></a>fluctuation</h3><p>接下来我还画了重要词汇再不同章节的变化图。这个的难点是要先获取每一章的起始和结束的位置（不是书本的页码，而是自己分割出来的“单词表”上的位置）<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">chapterind = <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">16590</span>,  <span class="number">31267</span>,  <span class="number">54053</span>,<span class="number">69769</span>,  <span class="number">90171</span>, <span class="number">104745</span>,<span class="number">121010</span>, <span class="number">138136</span>,  <span class="number">147048</span>,  <span class="number">161724</span>,<span class="number">170963</span>,  <span class="number">193593</span>, <span class="number">206502</span>, <span class="number">214129</span>,<span class="number">230193</span>, </span><br><span class="line">                <span class="number">245828</span>,  <span class="number">260400</span>,<span class="number">285768</span>, <span class="number">303284</span>, <span class="number">324922</span>, <span class="number">337101</span>, <span class="number">349241</span>, <span class="number">362426</span>, <span class="number">377184</span>])-<span class="number">1</span></span><br><span class="line">def count_frequent(chap):</span><br><span class="line">    freqlist =[]</span><br><span class="line">    <span class="keyword">if</span> chap &lt;<span class="number">23</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">27</span>):</span><br><span class="line">            freqlist.<span class="built_in">append</span>(<span class="built_in">np</span>.where(wordlist[chapterind[chap]:chapterind[chap+<span class="number">1</span>]] ==namelist[i])[<span class="number">0</span>].shape[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">27</span>):</span><br><span class="line">            freqlist.<span class="built_in">append</span>(<span class="built_in">np</span>.where(wordlist[chapterind[chap]:] ==namelist[i])[<span class="number">0</span>].shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">np</span>.<span class="built_in">array</span>(freqlist)</span><br><span class="line"></span><br><span class="line">freq_var = <span class="built_in">np</span>.ndarray([<span class="number">24</span>,<span class="number">27</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">24</span>):</span><br><span class="line">    freq_var[i] = count_frequent(i)</span><br><span class="line"></span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">transformed = scaler.fit_transform(freq_var)</span><br><span class="line"></span><br><span class="line">fig,ax=plt.subplots(<span class="number">1</span>,figsize =(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">ax.matshow(transformed.T ,cmap ='jet')</span><br><span class="line">ax.set_title('<span class="number">27</span> <span class="built_in">key</span> words fluctuation <span class="keyword">in</span> <span class="number">24</span> chapters')</span><br><span class="line">ax.set_xticks(<span class="built_in">range</span>(<span class="number">24</span>))</span><br><span class="line">ax.set_yticks(<span class="built_in">range</span>(<span class="number">27</span>))</span><br><span class="line">ax.set_yticklabels(namelist)</span><br></pre></td></tr></table></figure></p><h4 id="heatmap"><a href="#heatmap" class="headerlink" title="heatmap"></a>heatmap</h4><p>经过一番折腾就可以统计出来27个关键词在24章的词频的变化，然后先画了一个<strong>heatmap热力图</strong>，这里为了避免某些关键词，比如邓小平出现频次太多影响到其他关键词的颜色，对每行做了归一化的处理（Minmaxscale）。<br><img src="http://i4.bvimg.com/640680/231ecc794e04d4d7.png" alt="Markdown"></p><p>这个图每一行是一个关键词，每一列是一章。信息量也是蛮大的，比如毛泽东在前面几章出现频次极其的高，后面由于趋势的原因，提的渐渐少了很多，变化相当明显。再比如支持一词，在后面的章节出现很多，可以推理强调邓小平受到他人支持以及支持他人推进改革的次数不少。学生这个关键词在19-21章出现非常多，闭着眼睛也知道这几张在讲什么（政治的潮起潮落、北京之春和天安门事件）。总之用heatmap图的方法也可以粗略地对关键词，尤其是关键词在每章中的变化做一些分析，更加细致的分析可以通过索引回一开始产生的全书词汇找到前后文再仔细看。</p><h4 id="折线图"><a href="#折线图" class="headerlink" title="折线图"></a>折线图</h4><p>接下来又绘制了一个更加直观的折线图，展示不同关键词在不同章节的变化情况，但是由于混杂在一起，可能不如热力图易读。<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(1,figsize =(20,10))</span><br><span class="line">#ax.<span class="keyword">plot</span>(freq_var[:,:10])</span><br><span class="line"><span class="keyword">count</span> =10</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="keyword">zip</span>(freq_var[:,:<span class="keyword">count</span>].T,namelist[:<span class="keyword">count</span>]):</span><br><span class="line">    plt.<span class="keyword">plot</span>(x,<span class="keyword">label</span> =y)</span><br><span class="line">plt.title(str(<span class="keyword">count</span>)+' key words fluctuation <span class="keyword">in</span> 24 chapters')</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="http://i4.bvimg.com/640680/c79d691ce875618e.png" alt="Markdown"></p><h2 id="进一步分析"><a href="#进一步分析" class="headerlink" title="进一步分析"></a>进一步分析</h2><h3 id="定义关键词之间的关系"><a href="#定义关键词之间的关系" class="headerlink" title="定义关键词之间的关系"></a>定义关键词之间的关系</h3><p>之前做的是一些基本的分析，我又思考了一下，能不能怎样表示一下两个关键词之间的关系呢？因为时间仓促，我也没有查找资料，就自己定义了某种衡量方法：</p><p>想衡量两个关键词的关系，以邓小平和毛泽东为例，他们分别出现了四千多次和两千多次，分布在全书中的各个位置，我想看他们的关系，就是看他们是否会出现的比较近，或者很多时候没有什么关系。于是我考虑去计算两个关键词的“<strong>最近邻距离</strong>”。接下来就是如何定义这个最近邻距离。因为两个关键词的数量不一致，以个数少的作为基准，已经可以知道这个词语在我生成的词汇表的具体位置，因此我分别找到毛泽东出现的两千多个位置，然后搜索每个位置最近的邓小平这个词汇出现的位置，然后获得他们的距离。这样就可以衡量出两个关键词在每个位置的最近距离了。</p><p>虽然听起来这个过程十分的繁琐，需要大量的搜索，但是通过把循环和搜索问题变成矩阵的运算（反正位置都是数字），就可以非常快地计算出任意两个关键词的距离分布了，我给定义成了<strong>calculate_distance</strong>函数。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def calculate_distance(ind1,ind2):</span><br><span class="line">    <span class="attr">pos1</span> = np.where(<span class="attr">wordlist==namelist[ind1])[0]</span></span><br><span class="line">    <span class="attr">pos2</span> = np.where(<span class="attr">wordlist==namelist[ind2])[0]</span></span><br><span class="line">    num1 ,<span class="attr">num2</span> = pos1.shape[<span class="number">0</span>],pos2.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> num1&gt;num2:</span><br><span class="line">        <span class="attr">small</span> = num2</span><br><span class="line">        <span class="attr">large</span> = num1</span><br><span class="line">        <span class="attr">lararr</span> = pos1</span><br><span class="line">        <span class="attr">smarr</span> = pos2</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="attr">small</span> = num1</span><br><span class="line">        <span class="attr">large</span> = num2</span><br><span class="line">        <span class="attr">lararr</span> = pos2</span><br><span class="line">        <span class="attr">smarr</span> = pos1</span><br><span class="line">    <span class="attr">disarr</span> = np.ndarray([small,large])  <span class="comment">#each line calculate the small set's ith word's and large set's every words distance</span></span><br><span class="line">    <span class="attr">arr1=</span> np.repeat(smarr,large).reshape(-<span class="number">1</span>,large)</span><br><span class="line">    <span class="attr">arr2=</span> np.repeat(lararr,small).reshape(-<span class="number">1</span>,small).T</span><br><span class="line">    <span class="attr">mindis</span> = np.min(np.abs(arr2-arr1),<span class="attr">axis=1)</span></span><br><span class="line">    return mindis</span><br><span class="line"></span><br><span class="line">def draw_dist_count(ind1,ind2):</span><br><span class="line">    fig,<span class="attr">ax=plt.subplots(1,figsize=(20,10))</span></span><br><span class="line">    ax.bar(range(calculate_distance(<span class="number">0</span>,<span class="number">1</span>).shape[<span class="number">0</span>]),calculate_distance(<span class="number">0</span>,<span class="number">1</span>),<span class="attr">color='g')</span></span><br><span class="line">    ax.set_title('Minimum Distance of '+namelist[ind1]+<span class="string">" and "</span>+namelist[ind2])</span><br><span class="line">draw_dist_count(<span class="number">0</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h4><p>这里就拿邓小平和毛泽东两个关键词举例，我按照顺序画了出来，毛泽东出现的两千多次里，每个毛泽东与最近的一个邓小平的位置距离。值越小说明这两个关键词越靠近，要是值为1的话就说明他们挨着（不过对于名词来说一般中间至少隔着一个介词）。<strong>这样就可以看到任意两个关键词的关系随书的文字的紧张的变化情况。</strong></p><p>可以看到700到1400左右，两个词的距离明显较近，说明在这部分文字中，两人发生了更为密切的联系，而500左右的距离有的非常远，说明这部分是各讲各的故事，两个人还没有交集。</p><p><img src="http://i4.bvimg.com/640680/a421383dc7da2619.png" alt="Markdown"></p><p>同样的调用计算距离和绘图的函数，可以查看任意两个关键词的距离并按顺序绘制其值。</p><p>下面一次性展示了同一个关键词和其他好几个关键词的距离图。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(<span class="number">4</span>,<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].bar(range(calculate_distance(<span class="number">0</span>,<span class="number">1</span>+<span class="number">2</span>*i+j)<span class="selector-class">.shape</span>[<span class="number">0</span>]),calculate_distance(<span class="number">0</span>,<span class="number">1</span>+<span class="number">2</span>*i+j))</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].set_title(<span class="string">'Minimum Distance of '</span>+namelist[<span class="number">0</span>]+<span class="string">" and "</span>+namelist[<span class="number">1</span>+<span class="number">2</span>*i+j])</span><br></pre></td></tr></table></figure><p><img src="http://i4.bvimg.com/640680/4414d03a5b228e77.png" alt="Markdown"></p><h4 id="hist-plot"><a href="#hist-plot" class="headerlink" title="hist plot"></a>hist plot</h4><p>接下来还画了一下距离的<strong>分布图</strong>，就是把上面的图中的距离统计一下他们的分布。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(<span class="number">4</span>,<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].hist(calculate_distance(<span class="number">0</span>,<span class="number">1</span>+<span class="number">2</span>*i+j),bins =<span class="number">50</span>,<span class="attribute">color</span>=<span class="string">'b'</span>,alpha=<span class="number">0.4</span>)</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].set_title(<span class="string">'Minimum Distance of '</span>+namelist[<span class="number">0</span>]+<span class="string">" and "</span>+namelist[<span class="number">1</span>+<span class="number">2</span>*i+j])</span><br></pre></td></tr></table></figure><p><img src="http://i4.bvimg.com/640680/3c6048942654bc2c.png" alt="Markdown"></p><p>这种图感觉就丢失很多信息了，看不出来随着书籍的发展，两个名词的关系的变化。当然如果做得更细致，可以用某些指标刻画一下这种距离图，更好地衡量两个指标的关系，用可视化的方法当然是更直观的。</p><h4 id="boxplot"><a href="#boxplot" class="headerlink" title="boxplot"></a>boxplot</h4><p>最后是<strong>Boxplot</strong>，这是另一种直观显示距离分布的图。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dist_data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>,<span class="number">20</span>):</span><br><span class="line">    dist_data[i] = calculate_distance(<span class="number">0</span>,i)</span><br><span class="line">dataframe_dxp = pd.concat((pd.DataFrame(&#123;namelist[i]:dist_data[i]&#125;) <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>,<span class="number">20</span>)),axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">100</span>,<span class="number">20</span>))</span><br><span class="line">sns.boxplot(data =dataframe_dxp,ax=ax,boxprops=dict(alpha=<span class="number">.5</span>),color=<span class="string">'g'</span>)</span><br><span class="line">ax.set_title(<span class="string">u'Dengxiaoping and others'</span>,fontsize=<span class="number">80</span>)</span><br><span class="line">ax.set_xticks(range(<span class="number">19</span>))</span><br><span class="line">ax.set_xticklabels(namelist[<span class="number">1</span>:<span class="number">20</span>],fontsize=<span class="number">80</span>)</span><br><span class="line">fig.savefig(<span class="string">'boxplot.png'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="http://i4.bvimg.com/640680/5ef0af735a848eca.png" alt="Markdown"></p><p>可以看到邓小平和好几个关键词的距离的分布，每一个box就是一个分布的统计，当然也和分布图一样，这样一画就<strong>拉平了</strong>不同关键词之间的差异了。</p><p>其实对文本挖掘还有<strong>词性标注、情感分析</strong>等更多方法，包括归纳段落或篇章的主题等等，目前都有很多统计模型和机器学习方法可以做。不过在尝试的过程中，我还是感觉到这只是很基本的辅助方法，更重要的还在于人文历史政治学科的专家们对书籍做仔细的解读，<strong>挖掘历史细节中的关键信息是人最擅长的</strong>，比机器强大的多的地方，不过在卷帙浩繁的历史典籍中，面对成千上万的书籍时，快速挖掘书籍的要点，分析出来一些有趣的东西，也许机器能够帮上大忙。</p><h1 id="附：读后感"><a href="#附：读后感" class="headerlink" title="附：读后感"></a>附：读后感</h1><p>这部分明显能感觉到自己笔触的迟滞和笨重，真的是很久不写这种风格的论文，表达得略显凌乱，也有可能是最近总是熬夜，写的时间也正是脑子乱乱的时候，又没有一个规范约束自己，因此写的相当不守规矩。</p><p>这次读后感分成两个部分，一个是常规的读后感想，另一部分是出于兴趣所做的一些对邓小平时代一书的基本的文本挖掘。</p><p>第一部分是我在读书时的一些感悟，尤其是比较了一些香港版和大陆版的不同之后，也产生了一些感悟。</p><p>经过查询，我发现大陆版正文较港版删节约5.3万字，其中包括“邓小平时代的关键人物”一文约2.6万字。这部分其实还相当有趣，我还专门仔细找了其中提到的几个人物的一些更多的史料，发现能读到很多令人震惊的，被有意掩盖的历史。大陆版的几个大篇幅忽略的内容包括天安门事件、邓小平南巡前后对改革停滞的不满、邓小平子女的腐败传闻等敏感话题并未避而不谈。其实这几部分也不是秘密了，我想有一些想法的民众也都能从各种地方搜集来蛛丝马迹，但是从删节中还是能感觉到一条清晰的审查红线。如果删除的内容更真实、接近历史的真相的话，确实相当让人开阔眼界，比如叶剑英病重，邓小平并未去看望，毛泽东对周恩来的打压讨厌却又离不开，在其死后冷漠的态度。这就很颠覆大家的“被培养起来的观念”，还有比如印象中对陈云和邓小平在经济问题上很好地合作的观念，也被作者纠正：陈云比起邓小平的大刀阔斧，要保守稳健很多，因此产生很多分歧，比如不去广东视察。另一个肯定被删（没有核实）的就是南巡时候的珠海会议，不留情面地批评了有点向往毛泽东的观念的江泽民，甚至威胁要取代他。这种分歧的事情大陆版应该也不会保留的。至于89年的风波，就没有什么可讨论的啦。</p><p>我总感觉，一字之差可能一篇文章意义就全变了，中国人最懂笔义春秋之法，也就格外注意这点。邓小平时代确实披露了很多史料，让中国人有机会了解自己的事情（听起来有点滑稽），但是在搜索的过程中，还是难免注意到，香港版的邓小平时代在好几个网站被列为“大陆禁书”。可想而之其中的一些关键问题，可能被隐去了。为什么会被隐去呢，我想我自己有些体会，当我初中读到上上任领导人的传记中的部分内容，感到一阵阵的震惊、震撼、深思、迷茫和一种成长成熟的不愉悦感的时候，以及日后有意无意读到搜到的各种真假故事的时候，都会隐隐体会到为什么有些历史和真实被隐去了。</p><p>读历史和任务传记，尤其是夹杂在历史洪流中的人物群像时，最让人不适的阅读体验之一就是作者对任务的评价不得不因为篇幅所限而显得相当“专断”，比如“雖然趙紫陽做人和藹可親，但一些同事認為他有點兒不合群，喜歡為自己著想。文革開始時趙紫陽讓他的部下抵抗紅衛兵，可是令部下氣憤的是，趙本人很快就把自己辦公室的鑰匙交給了紅衛兵。”这样的话语，让人很难真正对赵紫阳这样一个略显神秘的人物有更多的了解和判断，读起来还是一团历史的迷雾，当然对历史做价值判断本来就是危险且未必能断得清楚的，而如果能尽可能多得了解到公正的史料，也许就能想的更清楚一点，更全面一点，更多地祛除个人的感情，比如作者就并没有站在自由派的立场上一边倒地吹捧赵紫阳，而是指出了他自私自我的一面，这样的词语可能还是可以甚至有点受到大陆的欢迎的，而相反的，喜欢报复、邪恶狡猾之类很难见到的形容毛泽东的词语当然被删除干净。我相信人是无比复杂的，也绝不是多么高尚的，无私的，一个忘我的奉献一切的无私的人就真的是像神一样的所有人应该努力追逐的样子吗，我觉得不是，要说刨去了物质欲望，无私的奉献、为祖国的奉献、也无非是精神上的享受而已，不同类型的人难以体会另外的人的享受和愉悦的点，把事情渲染地极端又美好真的是件好事吗，需要的时候就圣洁如神明，一旦出事了一个个都不干净，这样的过程一再出现的话，恐怕就得不断填补一个巨大的漏洞，或者封住所有的缺口，封住所有信息的渠道，这样好吗。</p><p>从这里想到的东西绝不是在批评当权者和领导层，而是感到作为自私的利己的人类而言也许会永远存在的现象，我们当然不会承认自己的自私，也都指责别人的自私，在这个过程中有心照不宣也有大声互斥，我想共产党有的时候让世界上的很多人抵触和担忧就在于，一定要极端地宣称某些事情，有的时候大家都心照不宣的事情，可以揭露的事情，一定要坚持极端地说出来，这样未必是好的。然而反过来想，就算允许人们议论，揭短，又有何意义呢，对国家发展、经济增长、人民福利有什么意义呢？一下子也许还有很多负面的例子，也许很多时候我们就是这样安慰自己来进行善意的谎言的过程吧。有的时候一次性揭开历史的各种真相也未必是好事，对大多数人来说会是一个失去信仰的，难以接受的过程，就看美国也不过是借着民主自由人权的外衣干了很多坏事，包括这两天的叙利亚的空袭，为了自己的自私和利益，一套冠冕堂皇的理由好像自己也愿意相信，当然中国不信，中国说自己和平崛起不愿战争的说法，外国也不信，所以我们是否真的要探讨一下，话题开放的尺度究竟在哪里，“见过世面”、书读的多一点的人总是嚷嚷着开放，讲出真相，但是真的好吗，我记得也许是毛泽东曾经说过，知识分子什么都懂，就是不懂两点，吃不饱会饿，打仗会死人，我想书读得多了，很多道理也未必想的清楚，也只有毛泽东邓小平这样的人物，也许才能做一个比较好的决断？也许一个自诩读书万卷的知识分子人类良心真正有机会去管理人民的时候，也会发现这套管理是尽量好的办法？虽然也会有很多问题：我们避免不了伟人的错误，比如邓小平的全面物价改革可能造成的问题，我们避免不了无外部监督的权力带来的严重腐败，但这都源于每个人本身的缺点，虽然中国历史数千年来都因为通行一套文字而拥有巨量的经验，但是看起来还是很难解决好这样的问题。</p><p>本书让我感触颇深的另一点在于英雄人物的复杂性，这两段话让我感触极深：<br>~“基辛格11月訪華後，毛澤東為了與美國打交道，轉而依靠鄧小平這個在對抗蘇聯時十分堅定的人。1973年12月，鄧小平遵照指示參加了政治局批周的會議。無論在法國、在上海做地下工作期間還是1950年代初在北京一起工作時，周恩來就像鄧小平的兄長。但是毛澤東有理由希望鄧小平會和自己而不是周恩來站在一起。鄧小平在1940年代的整風運動中就站在毛澤東的一邊，周恩來卻沒有。自從1931年鄧小平被批為「毛派頭子」後，他就一直緊跟毛澤東，並在1950年代得到了毛的重用。1956年以後鄧小平成了黨的總書記，他和周恩來的關係在黨內事務上有時變得很尷尬：周恩來在黨內排名上高於鄧小平，可是他要向負責黨內日常事務的鄧小平彙報工作和接受指示。[2-82]周恩來在文革期間也沒有保護鄧小平。[2-83]~<br>~鄧小平心裏很清楚，「兩位小姐」會把他在批周會議上的發言彙報給毛主席。會議臨近結束時，鄧小平對周恩來說：「你現在的位置離主席只有一步之遙，別人都是可望而不可即，而你卻是『可望而可即』，希望你自己能夠十分警惕這一點。」[2-84]這些話表面上並不惡毒，卻暗藏殺機。鄧小平實際上是在暗示，周恩來想架空毛澤東，篡奪毛的地位。「兩位小姐」把鄧小平的發言和態度彙報給毛澤東後，毛非常興奮，立刻把鄧小平叫去談話。”~</p><p>我印象很深，小时候喜欢问父亲，这个人是好人还是坏人，父亲总会告诫我，不要用好坏去区分一个人。但是不用好坏去区分总会很头疼，很费脑子，让人很难受。毛泽东这个人的复杂性，很多历史事实和资料都能让人们略知一二，邓小平时代一书让我体会的更加深切，尤其是邓小平文革后期找到机会重新拾起权力阶段的故事，顺带让我了解到周恩来与毛泽东的分歧，而按顺序读起来，总是让人感慨颇深，一会儿对某人充满同情，一会儿又更加深切地感受到人物关系的复杂，让人对这些历史巨人产生了掺杂的混合的情绪，不知道同情谁好，不知道支持谁好，更别说谁是好人谁是坏人。可见评价历史真是件十分难的事情，如果客观地叙述事实，就只是记录罢了，而历史终归要掺入主观的观念，从这点上看，我反而觉得不要删节，让有心的读者多读读更好，为什么要把人维护得如此正面而甚至虚假呢，让人更加深切地体会到人性、人生和历史的复杂，更加谨慎地获取和得到自己的观点，岂不是更好？</p><p>大陆版删除的关键人物一章，读起来相当有意思，虽然在我看来这一章里篇幅所限也并没有很细致的描述，可能是不希望人们太多的关注人物背后的交情以及过多思考人性的复杂，故而这章也被删除了，我觉得其中一些写的不错，包括读到了赵紫阳的个人性格和可能带来的局限性，比如过分自爱，性格较为保守，对于管理经济倒是非常擅长。从很多人物和邓小平的关系看来，邓小平确实在管理人，尤其是管理领袖级人物上非常有一套，虽然不及毛泽东的本事，把开国功臣们掌握得牢牢的，但是也能不需要居于最前方就可以实际掌控大局，我觉得邓小平在很多地方上是借鉴了毛泽东的，而且去除了一些掌控欲，也有可能是由于一代英雄们都已经谢幕，相对掌控起来也更加容易，让邓小平有机会居于稍微靠后的位置，就牢牢掌控着一切局势，而且我感觉他和毛泽东后期一样，在挑人上都有意选择一些并未在权力中心浸染很久的人，比如王洪文、华国锋、赵紫阳和江泽民等等，赵紫阳是他出访尼泊尔路过四川一番交谈最终调到北京，而江泽民，我记得在各处看到，大概是邓小平喜欢春节在上海度过，加上八九年的风波，江泽民处理得很好，就空降到政治局成了领导者。这种选人的风格给邓小平带来了很多主动性，也许也有未来避免在历史上少背点锅的可能也说不好。做实验的过程中，都特别强调试探，邓小平可以多一些试探的余地，更多地观察再做决定，加上自己实际的军队和政治上的掌控权和表面领导人的生疏，可以让自己牢牢地掌管真正的核心决策。我记得江泽民曾经对毛泽东的一套更加喜欢，对市场化的进程感到过快，邓小平于是南下巡防，声称反对改革开放就是反对社会主义，由此压制了另一套想法的滋生。</p><p>但是这种掌管权力的方法也未必是完全好的，想想邓小平其实在一个相当“美好”的历史时期，活到最后的就是胜利者，邓小平73年说自己还能干二十年，结果真的干到十四大退到幕后，这种后发优势熬倒了很多元老，导致在大清洗之后的权力真空期获得了很多权力，恐怕接下来的两任都在某些时间段并不舒服，有很多桎梏，到这一任才有了更加集中的权力。这里面有的时候也可以看出人性的有趣之处。干部在反对个人集权的时候又希望自己能够有更多的权力，当年反对个人集权，是反对毛泽东权力过大，随意分配权力，两位小姐、造反派头头竟然能高过周恩来，反对的是权力危害到了我，而当自己可以有权力的时候，有人会愿意不要吗，恐怕也是很少见的。所以我觉得人们在意的可能更多的是权力能不能更多地为自己所用，以及其他的权力不要危害到自己，最好在一种比较好的平衡中，但是平衡也未必会永远存在，也未必是好事。看起来邓小平用权力的集中做了很多伟大的改革，毛泽东也做出了一系列彪炳千秋的伟业和载入史册的糊涂事，如今权力也更加集中起来，如果思路明晰的话，我觉得权力集中是能够做大事的，否则光是吵吵嚷嚷争论不休就什么都做不了了。只是权力集中虽然有可能带来很多的回报，也有更大的风险，争吵不休而止步不前面临的是缓慢的毁灭，一意孤行地推进则有走向荣光和加速衰败两种更加极端的选择。</p><p>这本书讲了很多改革和开放的故事，看起来是讲述了一个政党的领导人如何自我改革，把自己变得更加兼容并包，在术的层面不断学习进步的过程，但是大胆地一说，总是能感觉到在政治和管理问题上，管理者有极其强烈的控制欲，这当然很重要，必须承认，如果不是这样，也许我们已经几次陷入严重到可以亡国的风险，这种经验教训可能也让共产党更加谨慎小心，让改革开放这个词语显得更加多面性：从西方的角度，我们的所谓改革开放，也就是做到人家常规的程度，甚至都远远不够，而共产党在这个过程中要不断地审视各种局势，更加小心翼翼。我的感觉是，共产党相比于其他政党，更喜欢和强调管教，但是又不是喜欢按照法律管理，而是希望有更大的自由裁定权，记得一位高层曾经说过，法律不要立的太细致，这样才有解释的空间。管制与压抑的原理是什么？这恐怕是很多人心中的无法言说的疑问，不管会乱，有很多例子，所以我们就愿意并满足于上交更多的权利？比如自由获取信息、翻阅墙壁、表达言论的权利。某些做法使人很容易往不好的一面联想，虽然这也许并非管理者与人民的本意，但是实在是与神圣纯洁的宣传所矛盾。</p><p>最近对快手、抖音、内涵段子等的查封，以及其“段友”、“抖友”发展出来的有一定结构的组织，让管理者更加紧绷，很多人说这些地方都是垃圾，价值观歪曲，封的好，但是也有人心中充满了疑问，以及经典的“他们向…发难，而我没有发声，最终他们向我而来，没有人替我说话了”的担忧。管理者的这种一贯的，一刀切的、有点精神洁癖和完美主义者喜欢的掌控感与清净感让人赞许又害怕，让包括我在内的很多人处于矛盾：激动并自豪于中国人的成就、又觉得这来源于中国人传统的吃苦与奋进，又觉得这是对自己大大压抑和压榨的结果，觉得我们并没有跳出某种循环，让人迷茫于很多事情和自己的意义，感慨于人类历史和经验的复杂和不足够：看不清楚究竟什么是正确的路，估计不出来自己和国人和世界所处的情况、条件等等。</p><p>以上已经做了很多带有敏感词的评论，在我看来邓小平无疑是个奇人，尤其是作为开国领袖级人物，在分割明显的76年之后，又在领袖群体凋落的时代支撑并扭转了中国的大势，这是千秋功业，邓小平在73年的时候说出自己还能再干二十年，实在是几代人的幸运。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;期中作业之一是写一篇邓小平时代的读后感，说实话这种书是实在没空读了，虽然粗略地翻了几章，十分吸引人，但是这两年真的越来越讨厌写文科式的论文，瞎胡诌凑字数曾经也是我作为理科生的优势，但是这一两年对这种风格的文章：东拼西凑，无病呻吟，迷茫又自负的写作非常地厌恶。因为就想玩点花样，做点简单的文本数据挖掘凑凑字数，虽然多花了很多时间，但是毕竟很有意思，有意思的事情就不算浪费时间对吧，没有意思的事情，哪怕一分钟也是对生命的浪费呢。&lt;br&gt;
    
    </summary>
    
      <category term="techniques" scheme="http://james20141606.github.io/categories/techniques/"/>
    
      <category term="data science" scheme="http://james20141606.github.io/categories/techniques/data-science/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="data mining" scheme="http://james20141606.github.io/tags/data-mining/"/>
    
      <category term="matplotlib" scheme="http://james20141606.github.io/tags/matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>Extract Countries&#39; Commercial Data</title>
    <link href="http://james20141606.github.io/2018/04/12/economics/"/>
    <id>http://james20141606.github.io/2018/04/12/economics/</id>
    <published>2018-04-12T15:49:57.000Z</published>
    <updated>2018-04-12T16:10:43.156Z</updated>
    
    <content type="html"><![CDATA[<p>It is a brief pipeline to extract data from datasets in <a href="http://139.129.209.66:8000/d/daedafb854/" target="_blank" rel="noopener">here</a></p><p>The work is from my cute girl friend, who know nothing about code but brag to her mentor she can do it.</p><p>In this work, I use R, Bash and Python to extract different countries different indicators in different years. The data have some property: big, not unified(.RData or .csv), some have mistakes. It is very sparse so it waste many storage. And the conversion of Rdata to csv leads some mistakes, so it needs very careful examination and check work. At first I want to store all of them in HDF5 for better IO, but people in my girl friend’s working team are’t familiar with codes, so I store them in csv. I also think about later work(for example, basic statistical work, model the interaction and time series, maybe a hierarchical time series machine learning model), but I am too busy to help my little bragger to do all kinds of things.<br><a id="more"></a><br>Here are codes I wrote to extract and organize data: <a href="https://github.com/james20141606/economics" target="_blank" rel="noopener">https://github.com/james20141606/economics</a></p><h4 id="wget-to-extract-data"><a href="#wget-to-extract-data" class="headerlink" title="wget to extract data"></a>wget to extract data</h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">getdata</span><span class="selector-class">.sh</span></span><br></pre></td></tr></table></figure><h4 id="check-row-and-col-names-for-further-extraction"><a href="#check-row-and-col-names-for-further-extraction" class="headerlink" title="check row and col names for further extraction"></a>check row and col names for further extraction</h4><h5 id="before-2001"><a href="#before-2001" class="headerlink" title="before 2001"></a>before 2001</h5><p>use awk to read row and columns in csv, then compare them with std names<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#first</span><br><span class="line">extractnames.sh</span><br><span class="line">#second</span><br><span class="line">refer to codes <span class="keyword">in</span> analyze_dim_name<span class="selector-class">.ipynb</span>:检查<span class="number">1995</span>-<span class="number">2000</span>年的行和列名</span><br><span class="line"><span class="selector-id">#run</span> and check</span><br></pre></td></tr></table></figure></p><p><strong>There are some wrong files, need to examine them later</strong></p><h5 id="after-2001"><a href="#after-2001" class="headerlink" title="after 2001"></a>after 2001</h5><p>Use R to extract row and columns and compare<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-id">#first</span> run Rscript to get row and <span class="attribute">columns</span></span><br><span class="line">run extractrowandcol.R</span><br><span class="line">#second</span><br><span class="line">refer to codes <span class="keyword">in</span> analyze_dim_name<span class="selector-class">.ipynb</span>:<span class="number">2001</span>以后的，用R脚本转出来csv，同样的方式读取并判断</span><br><span class="line"><span class="selector-id">#run</span> and check</span><br></pre></td></tr></table></figure></p><p><strong>All the files have exactly the same structure</strong></p><h2 id="extract-data-concerning-CHINA"><a href="#extract-data-concerning-CHINA" class="headerlink" title="extract data concerning CHINA"></a>extract data concerning CHINA</h2><h3 id="analysis"><a href="#analysis" class="headerlink" title="analysis"></a>analysis</h3><p><strong>The data dimension is: </strong> 1435<em>1435</em>41<br>If use RData to extract some matrix to analyze its row and column names,  the  automatically saved names have mistakes. So we use the previous plot to inspire us and find the true data structure:</p><p><img src="http://i1.bvimg.com/640680/0ba5f17f200bc207.png" alt="Markdown"></p><p>The first big block is <strong>to</strong> the first country(AUS)</p><p>So the column names in first big block are:   X&gt;AUS</p><p>When row and columns names match there are values, so there are only values in diagonal. </p><p><strong>(That’s the main reason the R data file is big: the minimum number is :41<em>41</em>35<em>35, but RData have 1435</em>1435*41, 41 fold redundancy)</strong></p><h3 id="How-to-find-a-country"><a href="#How-to-find-a-country" class="headerlink" title="How to find a country"></a>How to find a country</h3><h4 id="after-2001-1"><a href="#after-2001-1" class="headerlink" title="after 2001"></a>after 2001</h4><p>The data we use is RData, use Rscript to extract data</p><h5 id="to-CHINA"><a href="#to-CHINA" class="headerlink" title="to CHINA"></a>to CHINA</h5><p>Locate the country，<strong>CHN is 7th</strong></p><p><strong>The seventh block are all countries to CHINA</strong><br><strong>dat[,,7]</strong>  the matrix dimension is 1435*1435<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">datt&lt;-dat[,,7]</span><br><span class="line">datt[1<span class="string">+35</span>*(i<span class="string">-1</span>):35*i,1<span class="string">+35</span>*(i<span class="string">-1</span>):35*i]</span><br></pre></td></tr></table></figure></p><p>Use for loop, <strong>use a array:35<em>（35</em>41）</strong> to store<br>save to <strong>tochn.csv</strong><br>Rows:c1-c35<br>Columns: every 35 columns are a same country<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Run extract2001.R</span><br><span class="line"><span class="selector-id">#output</span> <span class="keyword">in</span> out directory</span><br></pre></td></tr></table></figure></p><h5 id="CHINA-to"><a href="#CHINA-to" class="headerlink" title="CHINA to"></a>CHINA to</h5><p><strong>each 1435*1435 block’s seventh mini block is China to another country</strong><br><strong>dat[211:245,211:245,i]</strong><br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Run</span><span class="bash"> extract2001.R</span></span><br></pre></td></tr></table></figure></p><p>Use for loop, <strong>use a array:35<em>（35</em>41）</strong>to store<br><strong>save to chnto.csv</strong></p><p>Rows:c1-c35</p><p>Columns: every 35 columns are a same country</p><h4 id="before-2001-1"><a href="#before-2001-1" class="headerlink" title="before 2001"></a>before 2001</h4><p>There are some exceptions we do not deal with at first</p><p>The data we use only has csv, so use python to extract</p><h5 id="to-CHINA-1"><a href="#to-CHINA-1" class="headerlink" title="to CHINA"></a>to CHINA</h5><p>The principle is similar to after 2001</p><p>But the data is just the transpose: (1435<em>41)</em>1435</p><p><strong>The seventh block are all countries to CHINA</strong></p><p><strong>Run extract1995.py</strong><br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datt = dat[<span class="number">1435</span>*<span class="number">6</span>:<span class="number">1435</span>*<span class="number">7</span>,:]   <span class="number">#143</span>5*<span class="number">1435</span>datt[<span class="number">35</span>*<span class="selector-tag">i</span>:<span class="number">35</span>*(i+<span class="number">1</span>),<span class="number">35</span>*<span class="selector-tag">i</span>:<span class="number">35</span>*(i+<span class="number">1</span>)]  #loop</span><br></pre></td></tr></table></figure></p><p>Use for loop, <strong>use a array:35<em>（35</em>41）</strong>to store<br><strong>save to chnto.csv</strong></p><h5 id="CHINA-to-1"><a href="#CHINA-to-1" class="headerlink" title="CHINA to"></a>CHINA to</h5><p><strong>each 1435*1435 block’ seventh mini block is China to another country</strong><br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dattt =dat[1435*i:1435*(i+1),:]  <span class="comment">#the ith country 1435*1435</span></span><br><span class="line"><span class="section">dattt[35*6:35*(6+1),35*6:35*(6+1)]</span></span><br></pre></td></tr></table></figure></p><p>Save to <strong>chnto.csv</strong></p><h2 id="To-do"><a href="#To-do" class="headerlink" title="To do"></a>To do</h2><h3 id="Exception-dealing"><a href="#Exception-dealing" class="headerlink" title="Exception dealing"></a>Exception dealing</h3><ul><li>[ ] before 2001 there are some files not in standard form, needs more examine to extract. Maybe case by case<h3 id="analyze-data"><a href="#analyze-data" class="headerlink" title="analyze data"></a>analyze data</h3><h4 id="plot-the-change"><a href="#plot-the-change" class="headerlink" title="plot the change,"></a>plot the change,</h4>for example, heat map, line chart, animation …</li></ul><p><img src="http://i1.bvimg.com/640680/0ce616088c435eae.gif" alt="Markdown"></p><h4 id="do-simple-statistics"><a href="#do-simple-statistics" class="headerlink" title="do simple statistics"></a>do simple statistics</h4><h4 id="model-the-change"><a href="#model-the-change" class="headerlink" title="model the change"></a>model the change</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is a brief pipeline to extract data from datasets in &lt;a href=&quot;http://139.129.209.66:8000/d/daedafb854/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The work is from my cute girl friend, who know nothing about code but brag to her mentor she can do it.&lt;/p&gt;
&lt;p&gt;In this work, I use R, Bash and Python to extract different countries different indicators in different years. The data have some property: big, not unified(.RData or .csv), some have mistakes. It is very sparse so it waste many storage. And the conversion of Rdata to csv leads some mistakes, so it needs very careful examination and check work. At first I want to store all of them in HDF5 for better IO, but people in my girl friend’s working team are’t familiar with codes, so I store them in csv. I also think about later work(for example, basic statistical work, model the interaction and time series, maybe a hierarchical time series machine learning model), but I am too busy to help my little bragger to do all kinds of things.&lt;br&gt;
    
    </summary>
    
      <category term="interestings" scheme="http://james20141606.github.io/categories/interestings/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="economics" scheme="http://james20141606.github.io/tags/economics/"/>
    
      <category term="girl friend" scheme="http://james20141606.github.io/tags/girl-friend/"/>
    
  </entry>
  
  <entry>
    <title>Setup and Linux</title>
    <link href="http://james20141606.github.io/2018/04/12/setup/"/>
    <id>http://james20141606.github.io/2018/04/12/setup/</id>
    <published>2018-04-12T15:39:17.000Z</published>
    <updated>2018-04-14T17:20:41.471Z</updated>
    
    <content type="html"><![CDATA[<p>分享一点setup和linux的东西，包括使用git，使用支持markdown的笔记软件Bear，Anaconda的一些使用技巧以及jupyter在服务器上的设置。也可以在<a href="https://legacy.gitbook.com/book/lulab/bioinfo-training-2018/details" target="_blank" rel="noopener">这里</a>找到更多分享<br><a id="more"></a></p><h1 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h1><h2 id="版本控制与GitHub管理"><a href="#版本控制与GitHub管理" class="headerlink" title="版本控制与GitHub管理"></a>版本控制与GitHub管理</h2><h3 id="Git简介"><a href="#Git简介" class="headerlink" title="Git简介"></a>Git简介</h3><h4 id="Git是目前世界上最先进的分布式版本控制系统。"><a href="#Git是目前世界上最先进的分布式版本控制系统。" class="headerlink" title="Git是目前世界上最先进的分布式版本控制系统。"></a>Git是目前世界上最先进的分布式版本控制系统。</h4><h5 id="没有版本控制系统会遇到什么困难："><a href="#没有版本控制系统会遇到什么困难：" class="headerlink" title="没有版本控制系统会遇到什么困难："></a>没有版本控制系统会遇到什么困难：</h5><ul><li>版本更新的困难：如果你用Microsoft Word写过长篇大论，那你一定有这样的经历：想删除一个段落，又怕将来想恢复找不回来怎么办？于是只好先把当前文件“另存为”一个新的Word文件，再接着改，改到一定程度，再“另存为”一个新文件，这样一直改下去，最后你的Word文档可能会有几十个不同版本的备份。过了一周，你想找回被删除的文字，但是已经记不清删除前保存在哪个文件里了，只好一个一个文件回去找，非常麻烦。如果是代码的话，来回的更改就更频繁了，如果想找到之前某个版本的代码，很有可能已经被删除了，对于稍微大一点的工程来说可能麻烦就大了。</li><li>合作时的困难：有些部分需要你的合作者帮助写，于是你把文件Copy到U盘里给她（也可能通过Email发送一份给她），然后，你继续修改文件。一段时间后你的合作者把改动后的文件给你，此时，文件的合并就是一件麻烦事了，你要不然得问她一个一个指出她的改动，或者你就要记录自己的改动，和她的文件合并。<br><br></li></ul><p>如果有一个软件，不但能自动帮我记录每次文件的改动，还可以让同事协作编辑，这样就不用自己管理一堆类似的文件了，也不需要把文件传来传去。如果想查看某次改动，只需要在软件里看一眼就可以看到改动的日期和内容，岂不是很方便？</p><h5 id="这就是21世纪的版本控制系统，Git。"><a href="#这就是21世纪的版本控制系统，Git。" class="headerlink" title="这就是21世纪的版本控制系统，Git。"></a>这就是21世纪的版本控制系统，Git。</h5><h4 id="Git诞生"><a href="#Git诞生" class="headerlink" title="Git诞生"></a>Git诞生</h4><p>Git是Linus (Linux之父)花了两周时间用C写的，在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码，Linux反对集中式的，需要联网的版本控制系统，也反对商业版的版本控制系统，于是创造了Git，一个月之内，Linux系统的源码已经由Git管理了。<br>Git迅速成为最流行的分布式版本控制系统，尤其是2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub，这就是程序员最爱的Git和Github的诞生史。</p><h3 id="安装与使用Git"><a href="#安装与使用Git" class="headerlink" title="安装与使用Git"></a>安装与使用Git</h3><h4 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h4><p>只介绍Mac OS系统安装方法</p><ul><li><p>方法一：先安装homebrew，然后通过homebrew安装Git。安装homebrew可查看<a href="http://brew.sh/" target="_blank" rel="noopener">http://brew.sh/</a></p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">brew </span><span class="keyword">install </span>git</span><br></pre></td></tr></table></figure></li><li><p>方法二：<br>第二种方法更简单，也是推荐的方法，就是用Xcode，Xcode集成了Git，不过默认没有安装，在终端输入命令安装command line tools，即可安装git。</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcode-<span class="keyword">select</span> <span class="comment">--install</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="使用git"><a href="#使用git" class="headerlink" title="使用git"></a>使用git</h4><h5 id="创建或使用文件夹作为需要管理的仓库"><a href="#创建或使用文件夹作为需要管理的仓库" class="headerlink" title="创建或使用文件夹作为需要管理的仓库"></a>创建或使用文件夹作为需要管理的仓库</h5><p>在本地建立项目文件夹，或者使用已存在的项目文件夹，如helloworld<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> helloworld</span><br><span class="line">git init <span class="comment">#通过git init命令把这个目录变成Git可以管理的仓库</span></span><br></pre></td></tr></table></figure></p><h5 id="添加或更改文件"><a href="#添加或更改文件" class="headerlink" title="添加或更改文件"></a>添加或更改文件</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi README.md <span class="comment">#创建一个新文件README.md，添加内容并保存</span></span><br><span class="line">git <span class="keyword">add</span><span class="bash"> README.md</span></span><br><span class="line"><span class="bash"><span class="comment">#用命令git add告诉Git，把文件README.md添加到仓库</span></span></span><br><span class="line"><span class="bash"><span class="comment">#如果一次性添加了多个文件，可以使用git add . git会自己判别哪些是新文件。</span></span></span><br></pre></td></tr></table></figure><p>所有的版本控制系统只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，只知道大小的改动，但更改的内容版本控制系统无法知道。</p><h5 id="添加更改信息"><a href="#添加更改信息" class="headerlink" title="添加更改信息"></a>添加更改信息</h5><p>下面可以告诉git你本次更改的内容，如果一次add了多个文件，则所有的文件都会被标注同样的更改信息。比如：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">commit</span> -m <span class="string">"first commit"</span></span><br><span class="line">git <span class="keyword">commit</span> -m <span class="string">"add README.md"</span></span><br></pre></td></tr></table></figure></p><h5 id="上传至GitHub"><a href="#上传至GitHub" class="headerlink" title="上传至GitHub"></a>上传至GitHub</h5><p>首先在github上新建一个repository，如helloworld，你将会看到跳转页面上提示你需要推送到的HTTPS地址<a href="https://github.com/accountname/repositoryname.git" target="_blank" rel="noopener">https://github.com/accountname/repositoryname.git</a><br>接下来使用<br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote <span class="keyword">add</span><span class="bash"> origin https://github.com/accountname/repositoryname.git</span></span><br><span class="line"><span class="bash">git push -u origin master</span></span><br></pre></td></tr></table></figure></p><p>即可把自己的本地仓库推送到github上，速度很快。<br>注意如果第一次把远程地址输入错误，可以用以下命令更正地址<br><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">set-url</span> <span class="string">origin </span><span class="string">https:</span>//<span class="string">github.</span><span class="string">com/</span><span class="string">accountname/</span><span class="string">repositoryname.</span><span class="string">git</span></span><br></pre></td></tr></table></figure></p><h4 id="使用ssh-key-免账户与密码推送方法："><a href="#使用ssh-key-免账户与密码推送方法：" class="headerlink" title="使用ssh key 免账户与密码推送方法："></a>使用ssh key 免账户与密码推送方法：</h4><h5 id="在终端输入"><a href="#在终端输入" class="headerlink" title="在终端输入"></a>在终端输入</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git<span class="built_in"> config </span>--global user.name <span class="string">"yourgithubname"</span></span><br><span class="line">git<span class="built_in"> config </span>--global user.email <span class="string">"yourgithubaccountmail"</span></span><br></pre></td></tr></table></figure><h5 id="生成ssh-key"><a href="#生成ssh-key" class="headerlink" title="生成ssh key"></a>生成ssh key</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh-keygen</span></span><br></pre></td></tr></table></figure><p>生成的密钥在~/.ssh/id_rsa.pub位置。</p><h5 id="配置git-的ssh-key"><a href="#配置git-的ssh-key" class="headerlink" title="配置git 的ssh key"></a>配置git 的ssh key</h5><ul><li>登录github 点击头像选择settings</li><li>选择左侧菜单SSH and GPG keys ；点击右上角的NEW SSH key</li><li>新建ssh 链接。</li><li>title 可随意填写</li><li>Key 将上一步生成的 id_rsa.pub文件 的内容全部复制到此处</li></ul><p>参考链接：<br><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">Git教程</a><br><a href="http://blog.csdn.net/u012373815/article/details/53575362" target="_blank" rel="noopener">SSH连接GitHub、GitHub配置ssh key</a><br><a href="https://peerj.com/preprints/3159/" target="_blank" rel="noopener">version control</a></p><h2 id="支持markdown的轻量笔记软件-Bear"><a href="#支持markdown的轻量笔记软件-Bear" class="headerlink" title="支持markdown的轻量笔记软件 Bear"></a>支持markdown的轻量笔记软件 Bear</h2><p>推荐一款Mac下的非常好用额轻量级笔记软件Bear</p><h5 id="它的优点包括："><a href="#它的优点包括：" class="headerlink" title="它的优点包括："></a>它的优点包括：</h5><ul><li>轻量级，非常顺滑，无任何延迟</li><li>快捷键/markdown支持，符合程序员思维</li><li>加粗，下划线，项目列举，待办方块，代码块，多级标题，均有键盘快捷键以及markdown格式下的快捷键</li><li>网页链接、文件可拖拽至笔记，并显示内容概要。</li><li>内容可无缝衔接至gitbook等支持markdown格式的场合。（比如这些tips都可以直接在Bear编辑好，复制粘贴来就可以。）</li><li>可以快速通过# 加入标签，对笔记进行分类</li></ul><h1 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h1><h5 id="Edited-by-19’-Under-Xupeng-Chen"><a href="#Edited-by-19’-Under-Xupeng-Chen" class="headerlink" title="Edited by 19’ Under Xupeng Chen"></a>Edited by 19’ Under Xupeng Chen</h5><h2 id="Conda-amp-Bioconda"><a href="#Conda-amp-Bioconda" class="headerlink" title="Conda &amp; Bioconda"></a>Conda &amp; Bioconda</h2><p>Conda是一个包管理软件，可以帮助方便地下载各种软件而不需要编译。尤其是Bioconda可以用来管理linux系统上的生信相关的软件，是解决安装权限不够的问题的好工具。</p><h3 id="Conda"><a href="#Conda" class="headerlink" title="Conda"></a>Conda</h3><p>conda是一个包，依赖和环境管理工具，适用于多种语言，如: Python, R, Scala, Java, Javascript, C/ C++, FORTRAN</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>Anaconda安装可以去官方下载，但是强烈推荐使用tuna镜像，免流量，而且速度极快。<br><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">下载地址</a>，下载.sh文件后运行，按照提示一步一步往下运行即可。<br>下载Anaconda后，很多python的常用库都会被自动安装好，另外建议运行以下命令</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --<span class="built_in">add</span> channels http<span class="variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="keyword">cn</span>/anaconda/pkgs/free/</span><br><span class="line">conda config --<span class="built_in">add</span> channels http<span class="variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="keyword">cn</span>/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="keyword">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>这样以后使用conda install packages命令下载需要的包的时候，会自动从tuna镜像下载，速度会非常快。</p><h3 id="Bioconda"><a href="#Bioconda" class="headerlink" title="Bioconda"></a>Bioconda</h3><p>Bioconda是conda上一个分发生物信息软件的频道，使用它的最大好处是，你不用自己编译软件了。<br>Conda tuna 安装 conda设置 从tuna下载免流量，快<br>目前Bioconda有超过130个添加、更新和维护生物信息软件的贡献者，他们为这个频道发布了1500多个软件包。总结起来，bioconda有以下几个特点：</p><ul><li>软件是编译好的，无需自己编译</li><li>跨平台，支持Linux和Mac OS（本身conda还支持Windows）</li><li>支持多种语言，Python/Perl/R/Java/Go等</li><li>兼容多种语言的包管理器，如pip，CRAN，CPAN，Bioconductor，apt-get以及 homebrew<br>针对Python来说，使用conda相比pip的很大优势，就是不用自己编译。安装软件最头疼的问题，就是解决编译报错，很多时候忙活一天就为了把一个软件装好。</li></ul><h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><p>先添加Bioconda频道</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda<span class="built_in"> config </span>--<span class="builtin-name">add</span> channels defaults</span><br><span class="line">conda<span class="built_in"> config </span>--<span class="builtin-name">add</span> channels conda-forge</span><br><span class="line">conda<span class="built_in"> config </span>--<span class="builtin-name">add</span> channels bioconda</span><br></pre></td></tr></table></figure><p>然后即可用conda安装各种需要的软件，可以先去bioconda channel看看自己需要的软件在不在列表内。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="keyword">install </span><span class="keyword">bowtie</span></span><br><span class="line"><span class="keyword">conda </span>create -n myenv <span class="keyword">bwa </span><span class="keyword">bowtie </span>hisat star <span class="comment">#a new environment can be created</span></span><br><span class="line">source activate myenv <span class="comment">#activate the environment</span></span><br></pre></td></tr></table></figure><p>参考资料：<br><a href="https://bioconda.github.io/" target="_blank" rel="noopener">Using Bioconda — Bioconda documentation</a><br><a href="https://bioconda.github.io/recipes.html" target="_blank" rel="noopener">packages list</a></p><h2 id="在服务器上运行jupyter-notebook并在本地浏览器使用"><a href="#在服务器上运行jupyter-notebook并在本地浏览器使用" class="headerlink" title="在服务器上运行jupyter notebook并在本地浏览器使用"></a>在服务器上运行jupyter notebook并在本地浏览器使用</h2><p>Jupyter Notebook是基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写（markdown）、运行代码和展示结果。</p><ul><li><p>jupyter适合课题的早期尝试、绘图等非常便利，代码重复运行和复制粘贴方便，方便反复调试，尤其适合尚未工程化，需要大量尝试的阶段。</p></li><li><p>jupyter非常适合教学，交互效果非常好，github上有大量的教学项目是用jupyter notebook展示的，方便查看结果，查看相关说明、公式，方便学习者进行反复实验。</p></li></ul><h4 id="本地设置服务器信息"><a href="#本地设置服务器信息" class="headerlink" title="本地设置服务器信息"></a>本地设置服务器信息</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi .ssh/config</span><br><span class="line">Host ibme</span><br><span class="line">HostName 166.111.152.116 #ibme的ip</span><br><span class="line">ControlPersist <span class="literal">yes</span></span><br><span class="line">ControlMaster auto</span><br><span class="line">User chenxupeng</span><br><span class="line">DynamicForward 127.0.0.1:32987 #最后的port（如32987）要自己设置，不能与他人冲突</span><br></pre></td></tr></table></figure><h4 id="使用SwitchOmega在本地浏览器设置代理"><a href="#使用SwitchOmega在本地浏览器设置代理" class="headerlink" title="使用SwitchOmega在本地浏览器设置代理"></a>使用SwitchOmega在本地浏览器设置代理</h4><h5 id="添加情景模式，如ibme"><a href="#添加情景模式，如ibme" class="headerlink" title="添加情景模式，如ibme"></a>添加情景模式，如ibme</h5><p>代理协议SOCKS5，代理服务器127.0.0.1，代理端口填写自己设置的port。</p><h5 id="在auto-switch页面添加规则"><a href="#在auto-switch页面添加规则" class="headerlink" title="在auto switch页面添加规则"></a>在auto switch页面添加规则</h5><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">172<span class="selector-class">.235</span><span class="selector-class">.0</span>.*，192<span class="selector-class">.235</span><span class="selector-class">.0</span>.*，<span class="selector-tag">node50</span>*等，情景模式选择<span class="selector-tag">ibme</span></span><br></pre></td></tr></table></figure><p>点击应用选项</p><h5 id="在服务器上设置start-jupyter文件"><a href="#在服务器上设置start-jupyter文件" class="headerlink" title="在服务器上设置start-jupyter文件"></a>在服务器上设置start-jupyter文件</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi ~/bin/start-jupyter</span><br><span class="line">填写：</span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">bsub &lt;&lt;EOF</span><br><span class="line"><span class="comment">#BSUB -J jupyter</span></span><br><span class="line"><span class="comment">#BSUB -R span[hosts=1]</span></span><br><span class="line"><span class="comment">#BSUB -q Z-LU</span></span><br><span class="line"><span class="built_in">cd</span></span><br><span class="line">jupyter notebook --no-browser --ip=0.0.0.0 --port=10087 <span class="comment">#port自己设置一个，不要冲突</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>(也可以使用#BSUB -q Z-BNODE)</p><h4 id="start-jupyter"><a href="#start-jupyter" class="headerlink" title="start jupyter"></a>start jupyter</h4><p>首先start-jupyter启动，会自动提交一个任务到某个节点</p><h5 id="使用节点名称连接"><a href="#使用节点名称连接" class="headerlink" title="使用节点名称连接"></a>使用节点名称连接</h5><p>接下来可以用bjobs看到jupyter被提交到了哪个节点。接下来打开本地浏览器，输入</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node5<span class="number">0</span>*<span class="symbol">:port</span> <span class="comment">#如node504/10087</span></span><br></pre></td></tr></table></figure><p>若使用Z-BNODE，可在浏览器填写</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">zbnode01</span><span class="selector-class">.cluster</span><span class="selector-class">.com</span><span class="selector-pseudo">:port</span></span><br></pre></td></tr></table></figure><h5 id="使用ip连接"><a href="#使用ip连接" class="headerlink" title="使用ip连接"></a>使用ip连接</h5><p>用nslookup获得节点的ip，在本地浏览器输入：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ip</span><span class="selector-pseudo">:port</span> #如192<span class="selector-class">.235</span><span class="selector-class">.5</span><span class="selector-class">.48</span><span class="selector-pseudo">:10087</span></span><br><span class="line">#获得<span class="selector-tag">ip</span>方法</span><br><span class="line"><span class="selector-tag">nslookup</span> <span class="selector-tag">node504</span><span class="selector-class">.cluster</span><span class="selector-class">.com</span></span><br><span class="line"><span class="selector-tag">nslookup</span> <span class="selector-tag">zbnode01</span><span class="selector-class">.cluster</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure><p>第一次登陆需要密码，用bpeek查看任务输出，即可看到token，复制至浏览器即可使用jupyter notebook进行编程了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分享一点setup和linux的东西，包括使用git，使用支持markdown的笔记软件Bear，Anaconda的一些使用技巧以及jupyter在服务器上的设置。也可以在&lt;a href=&quot;https://legacy.gitbook.com/book/lulab/bioinfo-training-2018/details&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;找到更多分享&lt;br&gt;
    
    </summary>
    
      <category term="techniques" scheme="http://james20141606.github.io/categories/techniques/"/>
    
      <category term="linux" scheme="http://james20141606.github.io/categories/techniques/linux/"/>
    
    
      <category term="techniques" scheme="http://james20141606.github.io/tags/techniques/"/>
    
      <category term="bioinformatics" scheme="http://james20141606.github.io/tags/bioinformatics/"/>
    
  </entry>
  
  <entry>
    <title>eMaize_Tutorial</title>
    <link href="http://james20141606.github.io/2018/04/12/emaize-tutorial/"/>
    <id>http://james20141606.github.io/2018/04/12/emaize-tutorial/</id>
    <published>2018-04-12T15:30:17.000Z</published>
    <updated>2018-04-14T17:20:35.461Z</updated>
    
    <content type="html"><![CDATA[<p>这是为实验室写的，借由eMaize问题帮助大家简单了解机器学习基本方法和基础代码的教程。也可以在<a href="https://lulab.gitbooks.io/bioinfo/content/5%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B4%E5%90%88----%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/51.html" target="_blank" rel="noopener">这里</a>看到</p><p>由于jupyter notebook的强大的展示功能，本教程还用jupyter notebook组织且运行，可以获得更好的学习效果，代码在<a href="https://github.com/james20141606/somethingmore/blob/master/bioinfo.ipynb" target="_blank" rel="noopener">这里</a>,欢迎取用。<a href="http://localhost:4000/2018/04/12/setup/" target="_blank" rel="noopener">在这里</a>我简单介绍了如何配置jupyter，在<a href="https://james20141606.github.io/2018/04/10/Deep-Learning-Practice/">Deep Learning tutorial</a>中我也强烈推荐了jupyter，并且介绍了很多基于jupyter的资源，强烈建议尝试一下。<br><a id="more"></a></p><h2 id="0-背景简介"><a href="#0-背景简介" class="headerlink" title="0.背景简介"></a>0.背景简介</h2><p>该通过基因型预测表型的实例来自<a href="http://emaize.imaze.org" target="_blank" rel="noopener">eMaize challenge</a>:<br>eMaize问题要求我们以SNP作为特征，通过训练一个模型，对玉米的三个性状进行预测。<br>接下来的教程会展示从原始数据开始，如何对数据进行转换，存取，特征选择以及回归和后续分析的整个过程。本问题最基本的目标是使用6210个样本中的前4754个样本作为训练集，预测其他样本的性状<br></p><h2 id="I-上机指南"><a href="#I-上机指南" class="headerlink" title="I.上机指南"></a>I.上机指南</h2><p>本任务依赖于python语言及jupyter notebook，所需工具已安装到虚拟机。以下指南的所有代码均可在4.Emaize/jupyter_notebook/basic_tutorial.ipynb 中找到。</p><p>使用方法：</p><ul><li><p>打开终端，进入Bioinfo_Lab/4.Emaize/ 文件夹</p></li><li><p>输入jupyter notebook，等待弹出窗口，或者手动复制粘贴终端显示的网址到浏览器。</p></li><li><p>点击jupyter_notebook,再点击basic_tutorial.ipynb,即可看到本部分的教程。按照相关指南一步一步运行即可。本部分接下来的内容与basic_tutorial.ipynb中的内容一致。</p></li></ul><h4 id="jupyter-notebook基本使用指南："><a href="#jupyter-notebook基本使用指南：" class="headerlink" title="jupyter notebook基本使用指南："></a>jupyter notebook基本使用指南：</h4><p>本教程使用jupyter notebook，可以让使用者获得更好的体验，方便对代码进行修改，以及对结果进行查看和分析</p><ul><li>一段相关的代码在同一个代码框中书写 <br></li><li>同时按住shift与enter即可运行选中的代码框的代码<br></li><li>仅仅按enter键具有回车的效果</li><li><h5 id="使用上方的编辑栏："><a href="#使用上方的编辑栏：" class="headerlink" title="使用上方的编辑栏："></a>使用上方的编辑栏：</h5>点击加号在两个代码框中间插入新的代码框，删除代码框点击剪刀，中止程序点击方框</li></ul><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#导入必需的库</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">from sklearn.random_projection <span class="keyword">import</span> SparseRandomProjection</span><br><span class="line">from scipy.sparse <span class="keyword">import</span> load_npz, save_npz</span><br><span class="line"><span class="keyword">import</span> scipy.stats</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line">from sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">from scipy.stats.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">from sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">#<span class="keyword">import</span> xgboost</span><br><span class="line">#from xgboost.sklearn <span class="keyword">import</span> XGBRegressor</span><br><span class="line">from sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">from sklearn.kernel_ridge <span class="keyword">import</span> KernelRidge</span><br><span class="line">from sklearn <span class="keyword">import</span> neighbors</span><br><span class="line">from sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">from sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessRegressor</span><br><span class="line">from sklearn.gaussian_process.kernels <span class="keyword">import</span> DotProduct</span><br><span class="line">from tqdm <span class="keyword">import</span> tqdm_notebook <span class="keyword">as</span> tqdm</span><br><span class="line">from IPython.display <span class="keyword">import</span> display, Image</span><br><span class="line">%pylab inline</span><br></pre></td></tr></table></figure><h3 id="1-查看原始数据"><a href="#1-查看原始数据" class="headerlink" title="1.查看原始数据"></a>1.查看原始数据</h3><h4 id="1-1-数据种类"><a href="#1-1-数据种类" class="headerlink" title="1.1 数据种类"></a>1.1 数据种类</h4><ul><li>genotype：SNP数据，每个位点可能有三种情况，如AA，AT，TT <br></li><li>trait：共三种，trait1开花期，trait2株高，trait3产量，为连续值 <br></li><li>原始数据中有6210个样本，每个样本SNP位点约为190万个,<br>因为计算资源的原因，这里仅仅选取其中的5000个SNP作为示例,因为数据量的原因，结果肯定不够理想</li></ul><h4 id="1-2-数据格式"><a href="#1-2-数据格式" class="headerlink" title="1.2 数据格式"></a>1.2 数据格式</h4><p>txt存储格式不适合大数据读取的问题，对内存的占用过多。对于结构化的、能够存储为矩阵的数据，可以使用HDF5格式存取，内存占用小，读取速度快</p><h5 id="读取SNP数据，数据格式为HDF5"><a href="#读取SNP数据，数据格式为HDF5" class="headerlink" title="读取SNP数据，数据格式为HDF5"></a>读取SNP数据，数据格式为HDF5</h5><h5 id="在命令行查看数据shape的方法为："><a href="#在命令行查看数据shape的方法为：" class="headerlink" title="在命令行查看数据shape的方法为："></a>在命令行查看数据shape的方法为：</h5><ul><li>cd至文件路径下，输入：h5ls snp_5000 <br></li><li>若使用了新版h5py，可能出现无法打开的情况，此时输入HDF5_USE_FILE_LOCKING=FALSE h5ls snp_5000</li></ul><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">#使用h5py读取5000个SNP：</span></span><br><span class="line">with h5py.File('data/snp_5000') as f:</span><br><span class="line">snps = f[<span class="string">'snp'</span>][<span class="symbol">:</span>]</span><br><span class="line"><span class="section">#查看数据shape,h5py读取出的snps是一个矩阵，可以用.shape查看其shape</span></span><br><span class="line">snps.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看数据内容</span></span><br><span class="line">snps</span><br></pre></td></tr></table></figure><h5 id="读取性状数据"><a href="#读取性状数据" class="headerlink" title="读取性状数据"></a>读取性状数据</h5><p>使用numpy/pandas均可读取性状数据并显示，这里用pandas展示，真正计算时一般用numpy</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">traits</span> = pd.read_csv(<span class="string">'data/pheno_emaize.txt'</span>,delimiter=<span class="string">'\t'</span>)</span><br><span class="line"><span class="comment">#仅显示前五个,4754之后的样本的性状是未知的</span></span><br><span class="line">traits.head()</span><br></pre></td></tr></table></figure><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#pandas dataframe也可查看<span class="built_in">shape</span></span><br><span class="line"><span class="built_in">print</span> traits.<span class="built_in">shape</span></span><br></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#查看性状的分布情况</span><br><span class="line">trait1 = np.array(traits[<span class="string">'trait1'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait2 = np.array(traits[<span class="string">'trait2'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait3 = np.array(traits[<span class="string">'trait3'</span>])[:<span class="number">4754</span>]</span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">ax[<span class="number">0</span>].hist(trait1,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'normalized trait1 value distribution'</span>)</span><br><span class="line">ax[<span class="number">1</span>].hist(trait2,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'normalized trait2 value distribution'</span>)</span><br><span class="line">ax[<span class="number">2</span>].hist(trait3,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title(<span class="string">'normalized trait3 value distribution'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.bvimg.com/640680/30af897795c31338.png" alt="Markdown"></p><h5 id="查看训练集与测试集的划分"><a href="#查看训练集与测试集的划分" class="headerlink" title="查看训练集与测试集的划分"></a>查看训练集与测试集的划分</h5><p>下图中彩色部分为训练集性状，白色部分为待预测性状 <br><br>可以发现其划分方式并不随机，这会导致常规的机器学习方法出现一些问题，由于是基础介绍，这里不讨论如何解决这个问题。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def generate_parent_table(phenotype_file):</span><br><span class="line">phenotypes = pd.read_table(phenotype_file)</span><br><span class="line">pedigree = phenotypes[<span class="string">'pedigree'</span>].str.split(<span class="string">'_'</span>, expand=<span class="symbol">True</span>)</span><br><span class="line">pedigree.columns = [<span class="string">'f'</span>, <span class="string">'X'</span>, <span class="string">'m'</span>]</span><br><span class="line">phenotypes = pd.concat([phenotypes, pedigree], axis=<span class="number">1</span>)</span><br><span class="line">phenotypes[<span class="string">'number'</span>] = np.arange(phenotypes.shape[<span class="number">0</span>])</span><br><span class="line">parent_table = phenotypes.pivot_table(values=<span class="string">'number'</span>, index=[<span class="string">'m'</span>], columns=[<span class="string">'f'</span>], dropna=<span class="symbol">False</span>)</span><br><span class="line">male_ids = [<span class="string">'m%d'</span> <span class="comment">% i for i in range(1, parent_table.shape[0] + 1)]</span></span><br><span class="line">female_ids = [<span class="string">'f%d'</span> <span class="comment">% i for i in range(1, parent_table.shape[1] + 1)]</span></span><br><span class="line">parent_table = parent_table.loc[male_ids, female_ids]</span><br><span class="line">return parent_table</span><br><span class="line">phenotype_file = <span class="string">'data/pheno_emaize.txt'</span></span><br><span class="line">parent_table = generate_parent_table(phenotype_file)</span><br><span class="line">phenotypes = pd.read_table(<span class="string">'data/pheno_emaize.txt'</span>)</span><br><span class="line">fig, ax = subplots(<span class="number">3</span>,<span class="number">1</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">for i in range(<span class="number">3</span>):</span><br><span class="line">trait = [<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>][i]</span><br><span class="line">ax[i].matshow(np.take(np.ravel(phenotypes[trait].values), parent_table), cmap=cm.<span class="symbol">RdBu</span>)</span><br><span class="line">ax[i].set_title(<span class="string">'Phenotypes of training data (%s)'</span><span class="comment">%trait)</span></span><br></pre></td></tr></table></figure><h3 id="2-将SNP数据编码为向量"><a href="#2-将SNP数据编码为向量" class="headerlink" title="2. 将SNP数据编码为向量"></a>2. 将SNP数据编码为向量</h3><p>每个位点的碱基只有三种情况，不会出现更多碱基组合的可能，比如某位点仅有AA，AT，TT三种可能的情况<br><br>我们可以采取三种方式对其编码：</p><ul><li>转化为0、1、2。找到minor allele frequency（MAF），即两种碱基（如A、T）中出现频率低的那个，以A作为MAF为例，则TT为0，AT为1，AA为2，这样可以突出MAF</li><li>转化为3-bit one hot vector,$[1,0,0]^T,[0,1,0]^T,[0,0,1]^T$这样可以保持三种向量在空间距离的一致</li><li>转化为2-bit vector,则AA，AT，TT分别编为$[1,0]^T,[1,1]^T,[0,1]^T$,不需要考虑MAF<br>我们采取第三种方式<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def convert_2bit(seq):</span><br><span class="line">genotypes = np.zeros([6210,2])</span><br><span class="line">a = seq[1].split('/')</span><br><span class="line">for i in range(6210):</span><br><span class="line">if seq[<span class="string">4:</span>][<span class="symbol">i</span>] == a[0] + a[0]:</span><br><span class="line">genotypes[i] = np.array([0,1])</span><br><span class="line">if seq[<span class="string">4:</span>][<span class="symbol">i</span>] == a[0] + a[1]:</span><br><span class="line">genotypes[i] = np.array([1,0])</span><br><span class="line">if seq[<span class="string">4:</span>][<span class="symbol">i</span>] == a[1] + a[1]:</span><br><span class="line">genotypes[i] = np.array([1,1])</span><br><span class="line">genotypes = genotypes.astype('int').T</span><br><span class="line">return genotypes</span><br></pre></td></tr></table></figure></li></ul><h5 id="注意，接下来的步骤耗时14min"><a href="#注意，接下来的步骤耗时14min" class="headerlink" title="注意，接下来的步骤耗时14min"></a>注意，接下来的步骤耗时14min</h5><p>真实计算时此步骤使用C加速计算，这里为了连贯性仅仅展示python的方法 <br><br>可以跳过接下来的代码框步骤，直接使用处理好的结果，结果放在 /data/2bit_geno<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#该代码框可跳过以节约时间，直接运行下一个代码框</span></span><br><span class="line">geno_conv = convert_2bit(snps[1])</span><br><span class="line">for i in tqdm(range(4999)):</span><br><span class="line">geno_conv = np.concatenate((geno_conv,convert_2bit(snps[i+2])),axis =0)</span><br></pre></td></tr></table></figure></p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">#读取处理成2bit格式的SNP</span></span><br><span class="line">with h5py.File('data/2bit_geno') as f:</span><br><span class="line">geno_conv = f[<span class="string">'data'</span>][<span class="symbol">:</span>]</span><br></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看SNP的大致情况</span></span><br><span class="line">fig, <span class="attr">ax</span> = plt.subplots(<span class="attr">figsize=(5,10))</span></span><br><span class="line">ax.matshow(geno_conv[:<span class="number">300</span>,:<span class="number">200</span>],<span class="attr">cmap</span> = cm.binary_r)</span><br></pre></td></tr></table></figure><h3 id="3-特征提取与降维"><a href="#3-特征提取与降维" class="headerlink" title="3. 特征提取与降维"></a>3. 特征提取与降维</h3><ul><li>原数据每个样本有190万个SNP，转化为2bit coding后有大约380万个feature，大多数的feature可能是冗余的 <br></li><li>过多的feature使得机器学习模型无法承受，一个考虑时间开销及效果的feature数量应该在几千至几万量级 <br></li></ul><h4 id="特征选择："><a href="#特征选择：" class="headerlink" title="特征选择："></a>特征选择：</h4><p>特征选择的方法包括filter，wrapper和embedding三大类 <br><br>我们使用过如下方法： <br></p><ul><li>Mutual information:劣势在于需要将连续的性状值离散化，损失信息<br></li><li>ANOVA:通过p-value筛选feature，速度较慢，我们设计了加速ANOVA计算的算法。<br></li><li>基于模型的方法:基于广义线性模型或其他带有feature权重的机器学习模型，根据权重挑选feature<br></li></ul><h4 id="降维："><a href="#降维：" class="headerlink" title="降维："></a>降维：</h4><ul><li>PCA、SVD：劣势在于降维后的feature数量不能超过样本数量，一次性损失的feature过多<br></li><li>Random projection:基于LSH的降维方式，速度较快<br></li></ul><p>通过对问题的后续分析，我们发现对于预测绝大多数样本，基本的降维方法就已经够用<br><br>但是对于部分很难预测的样本，简单的特征选择方法也无法取得好的效果<br><br>我们根据后续开发的针对性的模型，设计了基于模型的特征选择方法，因为内容限制，不在这里使用。</p><h5 id="接下来分别使用ANOVA和Random-projection演示特征选择和降维，对于后续的计算来说，选择其中一种就可以，也可以把不同的方法拼起来使用"><a href="#接下来分别使用ANOVA和Random-projection演示特征选择和降维，对于后续的计算来说，选择其中一种就可以，也可以把不同的方法拼起来使用" class="headerlink" title="接下来分别使用ANOVA和Random projection演示特征选择和降维，对于后续的计算来说，选择其中一种就可以，也可以把不同的方法拼起来使用"></a>接下来分别使用ANOVA和Random projection演示特征选择和降维，对于后续的计算来说，选择其中一种就可以，也可以把不同的方法拼起来使用</h5><h5 id="我们会提供ANOVA、Random-projection处理上面5000个snps后的数据，以及在完整数据集上用Random-projection降维至10000个feature的数据。用于送入下一部分的回归模型。下面的三种方法的处理后的数据可以在feature-selection文件夹下找到，存储格式为HDF5，可用h5py打开"><a href="#我们会提供ANOVA、Random-projection处理上面5000个snps后的数据，以及在完整数据集上用Random-projection降维至10000个feature的数据。用于送入下一部分的回归模型。下面的三种方法的处理后的数据可以在feature-selection文件夹下找到，存储格式为HDF5，可用h5py打开" class="headerlink" title="我们会提供ANOVA、Random projection处理上面5000个snps后的数据，以及在完整数据集上用Random projection降维至10000个feature的数据。用于送入下一部分的回归模型。下面的三种方法的处理后的数据可以在feature_selection文件夹下找到，存储格式为HDF5，可用h5py打开"></a>我们会提供ANOVA、Random projection处理上面5000个snps后的数据，以及在完整数据集上用Random projection降维至10000个feature的数据。用于送入下一部分的回归模型。下面的三种方法的处理后的数据可以在feature_selection文件夹下找到，存储格式为HDF5，可用h5py打开</h5><h5 id="ANOVA数据："><a href="#ANOVA数据：" class="headerlink" title="ANOVA数据："></a>ANOVA数据：</h5><p>feature_selection/anova 包含三个性状各自的feature，大小为4000*6210</p><h5 id="Random-projection-5000-数据："><a href="#Random-projection-5000-数据：" class="headerlink" title="Random projection(5000)数据："></a>Random projection(5000)数据：</h5><p>feature_selection/randomproj_5000 从5000个SNPs降维得到，三个性状使用同一组feature,大小为1000*6210</p><h5 id="Random-projection-whole-SNPs-数据："><a href="#Random-projection-whole-SNPs-数据：" class="headerlink" title="Random projection(whole SNPs)数据："></a>Random projection(whole SNPs)数据：</h5><p>feature_selection/randomproj_whole 从所有SNPs降维得到，三个性状使用同一组feature，大小为10000*6210</p><h4 id="3-1-ANOVA"><a href="#3-1-ANOVA" class="headerlink" title="3.1 ANOVA"></a>3.1 ANOVA</h4><p>方差分析方法可以利用p值挑选feature <br><br>调用scipy.stats.f_oneway,利用SNPs和性状可以很容易地计算出p-value，但是对于大量数据来说速度较慢 <br><br>这里我们使用一种加速ANOVA计算的方法完成计算，相比于scipy.stats的方法可以提升计算速度数百倍。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加速ANOVA算法</span></span><br><span class="line">def fast_anova_2bit(X, y):</span><br><span class="line">y = y - y.mean()</span><br><span class="line">y2 = y*y</span><br><span class="line">N = X.shape[0]</span><br><span class="line">SS_tot = np.sum(y2)</span><br><span class="line"><span class="comment"># 10, 01, 11</span></span><br><span class="line">masks = [np.logical_and(X[:, 0::2], np.logical_not(X[:, 1::2])),</span><br><span class="line"><span class="section">np.logical_and(np.logical_not(X[:, 0::2]), X[:, 1::2]),</span></span><br><span class="line"><span class="section">np.logical_and(X[:, 0::2], X[:, 1::2])]</span></span><br><span class="line">Ni = np.concatenate([np.sum(mask, axis=0) for mask in masks]).reshape((3, -1))</span><br><span class="line">at_least_one = Ni &gt; 0</span><br><span class="line">SS_bn = [np.sum(y.reshape((-1, 1))*mask, axis=0) for mask in masks]</span><br><span class="line">SS_bn = np.concatenate(SS_bn).reshape((3, -1))</span><br><span class="line">SS_bn **= 2</span><br><span class="line">SS_bn = np.where(at_least_one, SS_bn/Ni, 0)</span><br><span class="line">SS_bn = np.sum(SS_bn, axis=0)</span><br><span class="line">SS_wn = SS_tot - SS_bn</span><br><span class="line">M = np.sum(at_least_one, axis=0)</span><br><span class="line">DF_bn = M - 1</span><br><span class="line">DF_wn = N - M</span><br><span class="line">SS_bn /= DF_bn</span><br><span class="line">SS_wn /= DF_wn</span><br><span class="line">F = SS_bn/SS_wn</span><br><span class="line">p_vals = np.ones(F.shape[0])</span><br><span class="line">ind = np.nonzero(M == 2)[0]</span><br><span class="line">if ind.shape[0] &gt; 0:</span><br><span class="line">p_vals[ind] = scipy.stats.f.sf(F[ind], 1, N - 2)</span><br><span class="line">ind = np.nonzero(M == 3)[0]</span><br><span class="line">if ind.shape[0] &gt; 0:</span><br><span class="line">p_vals[ind] = scipy.stats.f.sf(F[ind], 2, N - 3)</span><br><span class="line">return F, p_vals</span><br></pre></td></tr></table></figure></p><h5 id="注意X和y分别是什么"><a href="#注意X和y分别是什么" class="headerlink" title="注意X和y分别是什么"></a>注意X和y分别是什么</h5><p>我们需要输入进 fast_anova_2bit(X, y)的X是处理过的SNPs中前4754个样本的，y是trait1、trait2、trait3<br>因为需要分别预测三个性状，我们需要针对三个性状分别挑选特征</p><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">geno_conv_train = geno_conv[:,:<span class="number">4754</span>]</span><br><span class="line">geno_conv_test = geno_conv[:,<span class="number">4754</span>:]</span><br><span class="line"><span class="built_in">print</span> geno_conv_train.<span class="built_in">shape</span></span><br><span class="line"><span class="built_in">print</span> geno_conv_test.<span class="built_in">shape</span></span><br></pre></td></tr></table></figure><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#分别计算三种性状下<span class="number">5000</span>个SNPs做完ANOVA的p-value</span><br><span class="line"><span class="built_in">F,</span>pval_1 = fast_anov<span class="built_in">a_2bit</span>(geno_conv_train.T,trait1)</span><br><span class="line"><span class="built_in">F,</span>pval_2 = fast_anov<span class="built_in">a_2bit</span>(geno_conv_train.T,trait2)</span><br><span class="line"><span class="built_in">F,</span>pval_3 = fast_anov<span class="built_in">a_2bit</span>(geno_conv_train.T,trait3)</span><br><span class="line">pval_1.shape</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">ax[<span class="number">0</span>].hist(pval_1,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title('<span class="number">5000</span> SNPs p-value for trait1 distribution')</span><br><span class="line">ax[<span class="number">1</span>].hist(pval_2,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title('<span class="number">5000</span> SNPs p-value for trait2 distribution')</span><br><span class="line">ax[<span class="number">2</span>].hist(pval_3,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title('<span class="number">5000</span> SNPs p-value for trait3 distribution')</span><br></pre></td></tr></table></figure><p><img src="http://i1.bvimg.com/640680/b8b10e4aac94c22f.png" alt="Markdown"><br>可以设定一个阈值，比如留下p-value前百分之四十的SNPs,根据index选取留下的SNPs<br><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">threshold1 = np.percentile(pval_1,<span class="number">40</span>)</span><br><span class="line">threshold2 = np.percentile(pval_2,<span class="number">40</span>)</span><br><span class="line">threshold3 = np.percentile(pval_3,<span class="number">40</span>)</span><br><span class="line"><span class="keyword">print</span> 'threshold1: <span class="built_in">%f</span>' <span class="built_in">%threshold</span>1</span><br><span class="line"><span class="keyword">print</span> 'threshold2: <span class="built_in">%f</span>' <span class="built_in">%threshold</span>2</span><br><span class="line"><span class="keyword">print</span> 'threshold3: <span class="built_in">%f</span>' <span class="built_in">%threshold</span>3</span><br></pre></td></tr></table></figure></p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回符合条件的p-value的坐标，即可找到需要留下的SNPs的位置，注意每个SNPs占据两行</span></span><br><span class="line"><span class="attr">anova_index_1</span> = np.where(pval_1&lt;threshold1)[<span class="number">0</span>]</span><br><span class="line"><span class="attr">anova_index_1</span> = np.sort(np.concatenate((anova_index_1,anova_index_1 +<span class="number">1</span>)))</span><br><span class="line"><span class="attr">anova_index_2</span> = np.where(pval_2&lt;threshold2)[<span class="number">0</span>]</span><br><span class="line"><span class="attr">anova_index_2</span> = np.sort(np.concatenate((anova_index_2,anova_index_2 +<span class="number">1</span>)))</span><br><span class="line"><span class="attr">anova_index_3</span> = np.where(pval_3&lt;threshold3)[<span class="number">0</span>]</span><br><span class="line"><span class="attr">anova_index_3</span> = np.sort(np.concatenate((anova_index_3,anova_index_3 +<span class="number">1</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#根据p-value选取保留的SNPs，注意这一步要在所有的6210个样本上做</span></span><br><span class="line"><span class="attr">feature1_anova</span> = np.take(geno_conv,anova_index_1,axis=<span class="number">0</span>)</span><br><span class="line"><span class="attr">feature2_anova</span> = np.take(geno_conv,anova_index_2,axis=<span class="number">0</span>)</span><br><span class="line"><span class="attr">feature3_anova</span> = np.take(geno_conv,anova_index_3,axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h4 id="3-2-Random-projection"><a href="#3-2-Random-projection" class="headerlink" title="3.2 Random projection"></a>3.2 Random projection</h4><p>Random projection 不依赖于性状，仅仅在原SNPs数据进行降维 <br><br>Random projection可以使用scikit-learn下的sklearn.random_projection模块计算 <br><br>包括generate，transform和normalize等步骤 <br><br>这里演示从5000个feature（10000行）降维</p><h5 id="3-2-1-generate"><a href="#3-2-1-generate" class="headerlink" title="3.2.1 generate"></a>3.2.1 generate</h5><p>产生一个稀疏矩阵</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">10000</span>为操作前的feature个数：<span class="number">2</span>*<span class="number">5000</span></span><br><span class="line">X = np.zeros((<span class="number">2</span>, <span class="number">10000</span>))</span><br><span class="line">#确定降维后的个数，这里定为<span class="number">1000</span>，使用sklearn random_projection 模块下的 SparseRandomProjection 函数</span><br><span class="line">proj = SparseRandomProjection(<span class="number">1000</span>)</span><br><span class="line">proj.fit(X)</span><br><span class="line">print proj.components_.shape</span><br></pre></td></tr></table></figure><h5 id="3-2-2-transform"><a href="#3-2-2-transform" class="headerlink" title="3.2.2 transform"></a>3.2.2 transform</h5><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">X</span>= geno_conv.T</span><br><span class="line"><span class="attr">X_</span> = proj.transform(X)</span><br></pre></td></tr></table></figure><h5 id="3-2-3-normalize"><a href="#3-2-3-normalize" class="headerlink" title="3.2.3 normalize"></a>3.2.3 normalize</h5><p>对每个feature进行normalize，避免出现过大的值<br><figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">normalized_feeature = StandardScaler().fit_transform(X_).T</span><br></pre></td></tr></table></figure></p><p>最终大小为1000*6210，结果在feature_selection/randomproj_5000</p><h3 id="4-回归模型"><a href="#4-回归模型" class="headerlink" title="4. 回归模型"></a>4. 回归模型</h3><p>这部分通过几个常用的机器学习模型对上一部处理过的feature进行拟合和预测<br>这里使用sklearn和xgboost提供的模块，这些模块具有很好的封装，使用风格统一，使用时可以查看其官方文档<br><br>这里不介绍具体的机器学习模型的算法原理，可以参考周志华老师的《机器学习》等书进行学习。</p><h4 id="4-1-机器学习模型"><a href="#4-1-机器学习模型" class="headerlink" title="4.1 机器学习模型"></a>4.1 机器学习模型</h4><p>接下来会使用一些常用的可以用于回归的机器学习模型，可以选择其中的一种或几种对feature_selection/文件夹下的三种数据进行回归和预测。下面我们将几个模型列出，并且选择其中的一种作为示例，其他的模型可同理调用。 <br></p><h4 id="4-2-评价指标"><a href="#4-2-评价指标" class="headerlink" title="4.2 评价指标"></a>4.2 评价指标</h4><p>我们使用<script type="math/tex">r^2,pcc</script>作为衡量预测结果的指标<br></p><script type="math/tex; mode=display">r^2 = 1-\frac{SS_{res}}{SS_{tot}}$$<br>$$pcc = \frac{cov(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y} $$<br>我们可以绘制结果的heatmap图，散点图等进行可视化。#### 4.3 交叉验证交叉验证(Cross validation)可以帮助调参，寻找机器学习模型中的超参数 <br>一般可以使用10折或者5折交叉验证，注意在最终预测时，使用调参后的模型在整个训练集上训练，这时不再交叉验证 <br>因为交叉验证需要额外增加计算时间，因此这里只在整个训练集上训练一次，不再展示交叉验证的过程。##### 如果深究的话，本问题还有其特殊性，可以设计特殊的交叉验证方式不同的样本具有关联性CV，有的样本可能来自同一亲本，而且训练集和测试集的划分并不是随机的因此在真正解决这个问题的时候，需要考虑不同的抽样方式下的调参与训练，我们可以使用下图所示的几种抽样方式<figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="function"><span class="keyword">method</span> <span class="title">in</span> <span class="params">(<span class="string">'random'</span>, <span class="string">'by_female'</span>, <span class="string">'by_male'</span>, <span class="string">'cross'</span>)</span>:</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/cv_index.%s'</span>%<span class="function"><span class="keyword">method</span>, '<span class="title">r</span>') <span class="title">as</span> <span class="title">f</span>:</span></span><br><span class="line">index_train = f[<span class="string">'0/train'</span>][:]</span><br><span class="line">index_test = f[<span class="string">'0/test'</span>][:]</span><br><span class="line">fig, ax = subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line">sampling_table = np.zeros(np.prod(parent_table.shape))</span><br><span class="line">sampling_table[index_train] = <span class="number">1</span></span><br><span class="line">sampling_table = np.take(sampling_table, parent_table)</span><br><span class="line">ax[<span class="number">0</span>].matshow(sampling_table, cmap=cm.Greys)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Training samples (%s)'</span>%<span class="function"><span class="keyword">method</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">sampling_table</span> = <span class="title">np</span>.<span class="title">zeros</span><span class="params">(np.prod(parent_table.shape)</span>)</span></span><br><span class="line"><span class="function"><span class="title">sampling_table</span>[<span class="title">index_test</span>] = 1</span></span><br><span class="line"><span class="function"><span class="title">sampling_table</span> = <span class="title">np</span>.<span class="title">take</span><span class="params">(sampling_table, parent_table)</span></span></span><br><span class="line"><span class="function"><span class="title">ax</span>[1].<span class="title">matshow</span><span class="params">(sampling_table, cmap=cm.Greys)</span></span></span><br><span class="line"><span class="function"><span class="title">ax</span>[1].<span class="title">set_title</span><span class="params">(<span class="string">'Test samples (%s)'</span>%<span class="keyword">method</span>)</span></span></span><br><span class="line"><span class="function"><span class="title">plt</span>.<span class="title">tight_layout</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>![Markdown](http://i1.bvimg.com/640680/53ed95bc3fc879c9.png)![Markdown](http://i1.bvimg.com/640680/3a9fec1a694dc533.png)![Markdown](http://i1.bvimg.com/640680/f9198785ddd4e809.png)![Markdown](http://i1.bvimg.com/640680/18e028db8839992e.png)#### 4.4 准备数据sklearn的机器学习模型一般需要提供X和y以供模型训练，然后提供新的X，模型就可以预测新的y <br>通过前面的工作，我们获得了三种不同的X(ANOVA、random projection(5000/whole))，我们还需要将X和y划分为训练集和测试集 <br>注意我们需要分别对三个性状进行预测，因此ANOVA的X是三种 <br>##### 评价模型的时候要注意，y_true的部分值缺失##### 4.4.1 准备y先处理y，y 的train和test是统一的，不受方法影响<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">#y 的train和test的统一的，不受方法影响</span></span><br><span class="line">pheno<span class="emphasis">_whole = pd.read_</span>csv('data/emaize<span class="emphasis">_pheno_</span>whole',delimiter=',')</span><br><span class="line">wholepheno = &#123;&#125;</span><br><span class="line">for trait in ['trait1','trait2','trait3']:</span><br><span class="line">wholepheno[trait] = np.array(pheno_whole[trait])</span><br><span class="line">y_train = &#123;&#125;</span><br><span class="line">y_test = &#123;&#125;</span><br><span class="line">for trait in ['trait1','trait2','trait3']:</span><br><span class="line">y_train[<span class="string">trait</span>] = wholepheno[<span class="string">trait</span>][<span class="symbol">:4754</span>]</span><br><span class="line">y_test[<span class="string">trait</span>] = wholepheno[<span class="string">trait</span>][<span class="symbol">4754:</span>]</span><br></pre></td></tr></table></figure>##### 4.4.2 准备X再处理X，使用ANOVA时X要区分不同性状，Random projection由于是与性状无关的降维方法，三种性状下的feature都一样 <br>因为机器学习模型要求一般数据形式为sample*feature，因此需要对结果转置<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def prepare_data(method):</span><br><span class="line">if method == 'randomproj_5000':</span><br><span class="line">with h5py.File('feature<span class="emphasis">_selection/randomproj_</span>5000') as f:</span><br><span class="line">X_train = f[<span class="string">'data'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test = f[<span class="string">'data'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">if method == 'randomproj_whole':</span><br><span class="line">with h5py.File('feature<span class="emphasis">_selection/randomproj_</span>whole') as f:</span><br><span class="line">X_train = f[<span class="string">'X'</span>][<span class="symbol">:</span>][<span class="string">:4754,:</span>]</span><br><span class="line">X_test = f[<span class="string">'X'</span>][<span class="symbol">:</span>][<span class="string">4754:,:</span>]</span><br><span class="line">if method == 'anova':</span><br><span class="line">X_train = &#123;&#125;</span><br><span class="line">X_test = &#123;&#125;</span><br><span class="line">with h5py.File('feature_selection/anova') as f:</span><br><span class="line">X_train[<span class="string">'trait1'</span>] = f[<span class="string">'feature1'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test[<span class="string">'trait1'</span>] = f[<span class="string">'feature1'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">X_train[<span class="string">'trait2'</span>] = f[<span class="string">'feature2'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test[<span class="string">'trait2'</span>] = f[<span class="string">'feature2'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">X_train[<span class="string">'trait3'</span>] = f[<span class="string">'feature3'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test[<span class="string">'trait3'</span>] = f[<span class="string">'feature3'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">return X<span class="emphasis">_train,X_</span>test</span><br></pre></td></tr></table></figure>选择三种方法之一作为X,注意ANOVA方法返回的X需要指明性状<figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#查看anova方法的X_train X_test</span><br><span class="line">X_train, X_test = prepare_data(<span class="string">'anova'</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'anova method X_train shape: %s'</span> %(X_train[<span class="string">'trait1'</span>].shape,)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'anova method X_test shape: %s'</span> %(X_test[<span class="string">'trait1'</span>].shape,)</span><br></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#查看<span class="built_in">random</span> projection方法的X_train X_test</span><br><span class="line">X_train, X_test = prepare_data('randomproj_5000')</span><br><span class="line"><span class="built_in">print</span> '<span class="built_in">random</span> projection <span class="built_in">method</span> X_train shape: <span class="built_in">%s</span>' <span class="symbol">%</span>(X_train.shape,)</span><br><span class="line"><span class="built_in">print</span> '<span class="built_in">random</span> projection <span class="built_in">method</span> X_test shape: <span class="built_in">%s</span>' <span class="symbol">%</span>(X_test.shape,)</span><br></pre></td></tr></table></figure>#### 4.5 选择需要的机器学习模型接下来会提供多种机器学习模型，并且讲解其使用方法，可以选择自己喜欢的模型进行回归，也可以用sklearn或其他package提供的模型模型包括：- lr: Linear regression- ridge: Ridge regression- kr: Kernel Ridge regression- rfr: Random Forest regression- xgbr: XGBoost regression- knr: K-nearest neigbour regression- gpr: Gaussian Process regression<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def Model(model):</span><br><span class="line"><span class="keyword">if</span> <span class="attr">model=='lr':</span></span><br><span class="line"><span class="attr">reg</span> = LinearRegression()</span><br><span class="line"><span class="comment">#elif model=='xgbr':</span></span><br><span class="line"><span class="comment"># reg = XGBRegressor()</span></span><br><span class="line">elif <span class="attr">model=='ridge':</span></span><br><span class="line"><span class="attr">reg</span> = Ridge()</span><br><span class="line">elif <span class="attr">model=='kr':</span></span><br><span class="line"><span class="attr">reg</span> = KernelRidge(<span class="attr">alpha</span> = <span class="number">10000</span>, <span class="attr">kernel</span> = 'polynomial',<span class="attr">degree</span> = <span class="number">3</span>)</span><br><span class="line">elif <span class="attr">model=='knr':</span></span><br><span class="line"><span class="attr">reg</span> = neighbors.KNeighborsRegressor(<span class="attr">n_neighbors=4,</span> <span class="attr">algorithm='brute')</span></span><br><span class="line">elif <span class="attr">model=='rfr':</span></span><br><span class="line"><span class="attr">reg</span> = RandomForestRegressor(<span class="attr">n_estimators=10,</span> <span class="attr">criterion='mse',</span> <span class="attr">max_depth=12,</span> <span class="attr">n_jobs=5)</span></span><br><span class="line">elif <span class="attr">model=='gpr':</span></span><br><span class="line"><span class="attr">kernel</span> = <span class="number">1.0</span> * DotProduct(<span class="attr">sigma_0=1.0)**4</span></span><br><span class="line"><span class="attr">reg</span> = GaussianProcessRegressor(<span class="attr">kernel</span> = kernel, <span class="attr">optimizer=None)</span></span><br><span class="line">return reg</span><br></pre></td></tr></table></figure>接下来可以使用三种特征（X）中的一种以及七种方法中的一种进行训练和预测 <br>这里我们以randomproj_5000作为特征，用Ridge作为回归模型演示 <br>如果用anova得到的feature，需要注意不同性状的feature不一样 <br>##### 某个机器学习模型的使用方法如下：reg.fit(X,y)用于拟合，reg.predict(X)用于预测。更多用法可以参考sklearn官方文档<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test = prepare_data(<span class="string">'randomproj_whole'</span>)</span><br><span class="line">reg = Model(<span class="string">'gpr'</span>)</span><br><span class="line">y_predict = &#123;&#125;</span><br><span class="line">y_predict_train = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> <span class="class"><span class="keyword">trait</span> <span class="title">in</span> <span class="title">tqdm</span></span>([<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>]):</span><br><span class="line">reg.fit(X_train,y_train[<span class="class"><span class="keyword">trait</span>])</span></span><br><span class="line">y_predict[<span class="class"><span class="keyword">trait</span>] = <span class="title">reg</span>.<span class="title">predict</span></span>(X_test)</span><br><span class="line">y_predict_train[<span class="class"><span class="keyword">trait</span>] = <span class="title">reg</span>.<span class="title">predict</span></span>(X_train)</span><br><span class="line"></span><br><span class="line">X_test.shape</span><br></pre></td></tr></table></figure>计算预测结果与真实值的$$r^2,pcc</script><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">test_nonan = np.where(np.isnan(np.array(pheno_whole[<span class="string">'trait1'</span>])[<span class="number">4754</span>:]) ==<span class="number">0</span>)</span><br><span class="line">pcc_train = &#123;&#125;</span><br><span class="line">pcc_test = &#123;&#125;</span><br><span class="line">r2_train = &#123;&#125;</span><br><span class="line">r2_test = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> <span class="class"><span class="keyword">trait</span> <span class="title">in</span> ['<span class="title">trait1</span>',<span class="type">'trait2'</span>,<span class="type">'trait3']:</span></span></span><br><span class="line">pcc_test[<span class="class"><span class="keyword">trait</span>] = <span class="title">pearsonr</span></span>(y_predict[<span class="class"><span class="keyword">trait</span>][<span class="title">test_nonan</span>],<span class="type">np.array</span></span>(pheno_whole[<span class="class"><span class="keyword">trait</span>])[4754:<span class="type">][test_nonan])</span></span></span><br><span class="line">pcc_train[<span class="class"><span class="keyword">trait</span>] = <span class="title">pearsonr</span></span>(y_predict_train[<span class="class"><span class="keyword">trait</span>],<span class="type">y_train[trait])</span></span></span><br><span class="line">r2_test[<span class="class"><span class="keyword">trait</span>] = <span class="title">r2_score</span></span>(y_predict[<span class="class"><span class="keyword">trait</span>][<span class="title">test_nonan</span>],<span class="type">np.array</span></span>(pheno_whole[<span class="class"><span class="keyword">trait</span>])[4754:<span class="type">][test_nonan])</span></span></span><br><span class="line">r2_train[<span class="class"><span class="keyword">trait</span>] = <span class="title">r2_score</span></span>(y_predict_train[<span class="class"><span class="keyword">trait</span>],<span class="type">y_train[trait])</span></span></span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcc_test</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcc_train</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_test</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_train</span><br></pre></td></tr></table></figure><p>可以看到预测结果并不是很好，在测试集上的pcc只有0.5左右。后续的分析可以发现，这是因为样本之间具有相关性导致的<br><br>具体的原因分析比较复杂，简单来说，因为这组测试集与训练集的样本的亲本之间亲缘关系较远，模型难以从SNPs得到的feature推断出亲本信息，导致预测结果较差。</p><p>绘制heatmap图观察预测结果 <br><br>GPR具有很强的拟合能力，总可以在训练集上得到接近1的PCC<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">2</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line">for i in range(<span class="number">3</span>):</span><br><span class="line">traits = [<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>]</span><br><span class="line">ax[<span class="number">0</span>,i].scatter(y_predict[traits[i]][test_nonan],np.array(pheno_whole[traits[i]])[<span class="number">4754</span>:][test_nonan])</span><br><span class="line">ax[<span class="number">0</span>,i].set_title(<span class="string">'%s test set predict &amp; true value plot'</span> <span class="comment">%traits[i])</span></span><br><span class="line">line1 = [(<span class="number">-4</span>, <span class="number">-4</span>), (<span class="number">4</span>, <span class="number">4</span>)]</span><br><span class="line">(line1_xs, line1_ys) = zip(*line1)</span><br><span class="line">ax[<span class="number">0</span>,i].add_line(<span class="symbol">Line2D</span>(line1_xs, line1_ys, linewidth=<span class="number">1</span>, color=<span class="string">'red'</span>))</span><br><span class="line">ax[<span class="number">0</span>,i].set_xlim(left=<span class="number">-4</span>, right=<span class="number">4</span>)</span><br><span class="line">ax[<span class="number">0</span>,i].set_ylim(bottom=<span class="number">-4</span>, top=<span class="number">4</span>)</span><br><span class="line">ax[<span class="number">1</span>,i].scatter(y_predict_train[traits[i]],y_train[traits[i]])</span><br><span class="line">ax[<span class="number">1</span>,i].set_title(<span class="string">'%s train set predict &amp; true value plot'</span> <span class="comment">%traits[i])</span></span><br><span class="line">ax[<span class="number">1</span>,i].add_line(<span class="symbol">Line2D</span>(line1_xs, line1_ys, linewidth=<span class="number">1</span>, color=<span class="string">'red'</span>))</span><br><span class="line">ax[<span class="number">1</span>,i].set_xlim(left=<span class="number">-4</span>, right=<span class="number">4</span>)</span><br><span class="line">ax[<span class="number">1</span>,i].set_ylim(bottom=<span class="number">-4</span>, top=<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p><p><img src="http://i1.bvimg.com/640680/dc071479d62b84c7.png" alt="Markdown"></p><p>绘制完整真实值与预测值的heatmap图 <br><br>从图中我们可以清晰地看出一个基本的模型的问题： <br><br>模型强烈地依赖已有信息进行预测，当未知样本的父本与已知训练集的亲缘关系较远时，模型只能依赖母本（横坐标）进行预测 <br><br>导致预测的heatmap图有明显的与母本相关的特征，而实际上子代的性状更容易被父本主导 <br></p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">wholepre = np.concatenate((y_predict[<span class="string">'trait1'</span>],y_predict[<span class="string">'trait2'</span>],y_predict[<span class="string">'trait3'</span>])).reshape(<span class="number">3</span>,<span class="number">-1</span>)</span><br><span class="line">predictions = pd.DataFrame(wholepre.T)</span><br><span class="line">predictions.columns = [<span class="string">'trait1'</span>, <span class="string">'trait2'</span>, <span class="string">'trait3'</span>]</span><br><span class="line">predictions = predictions.set_index(np.arange(<span class="number">4754</span>,<span class="number">6210</span>))</span><br><span class="line">def normalize_phenotype(x, range_pheno=<span class="number">4.0</span>):</span><br><span class="line"><span class="keyword">return</span> (np.clip(x, -range_pheno, range_pheno) + range_pheno)/<span class="number">2.0</span>/range_pheno</span><br><span class="line"><span class="keyword">for</span> <span class="class"><span class="keyword">trait</span> <span class="title">in</span> <span class="title">traits</span>:<span class="type"></span></span></span><br><span class="line">fig, ax = subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line">ax[<span class="number">0</span>].matshow(np.take(np.ravel(normalize_phenotype(pheno_whole[<span class="class"><span class="keyword">trait</span>].<span class="title">values</span>)), <span class="type">parent_table)</span>, <span class="type">cmap=cm.RdBu_r)</span></span></span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Phenotypes of whole true data (%s)'</span>%<span class="class"><span class="keyword">trait</span>)</span></span><br><span class="line"></span><br><span class="line">trait_pred = np.full(phenotypes.shape[<span class="number">0</span>], np.nan)</span><br><span class="line">trait_pred[predictions.index.tolist()] = normalize_phenotype(predictions[<span class="class"><span class="keyword">trait</span>].<span class="title">values</span>)</span></span><br><span class="line">ax[<span class="number">1</span>].matshow(np.take(trait_pred, parent_table), cmap=cm.RdBu)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Prediction on test data (%s 1)'</span>%traits)</span><br></pre></td></tr></table></figure><p><img src="http://i1.bvimg.com/640680/b514a9c8b7cc7943.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/bbe789a8598188da.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/19a5441ffb4534eb.png" alt="Markdown"></p><h3 id="后续分析"><a href="#后续分析" class="headerlink" title="后续分析"></a>后续分析</h3><h4 id="不同样本具有不同的预测难度"><a href="#不同样本具有不同的预测难度" class="headerlink" title="不同样本具有不同的预测难度"></a>不同样本具有不同的预测难度</h4><p>普通的机器学习模型在测试集上表现结果不好，但是通过多次的十字交叉抽样模拟，可以发现不同样本的预测难度不同，在大多数样本上，不需要专门设计的机器学习模型就足够表现很好</p><h4 id="样本之间具有关联性"><a href="#样本之间具有关联性" class="headerlink" title="样本之间具有关联性"></a>样本之间具有关联性</h4><p>不服从一些基本的假设，比如线性模型下，残差并不是独立的，需要考虑问题的特殊性进行额外的设计。<br><br>由于存储空间和计算时间的限制，无法展示其他有效的方法，有兴趣的同学可以查找育种领域的其他模型进行尝试。</p><h4 id="复杂的机器学习模型并不一定有效"><a href="#复杂的机器学习模型并不一定有效" class="headerlink" title="复杂的机器学习模型并不一定有效"></a>复杂的机器学习模型并不一定有效</h4><p>育种领域目前最好的模型依然是线性模型，通过特殊的设计，可以考虑到亲缘关系、显著相关的SNP(causal)以及随机效应部分<br>而寻找合适的feature是预测结果好坏的决定性因素，至今没有非常好的方法。</p><p>我们通过模拟特殊的十字交叉抽样方式发现，虽然测试集的样本不好预测，但是大多数的样本使用简单的机器学习方法就可以在大多数样本上取得较好的结果 <br><br>由于计算资源限制，下面直接展示模拟结果</p><p>我们使用一种特殊的十字交叉抽样，在训练集上抽样1000次，用来测试基本的机器学习模型结果 <br><br>我们使用了2bit coding编码的SNPs,通过random projection降维至80000 <br><br>然后使用Gaussian Process Regression作为回归模型 <br><br><img src="http://i1.bvimg.com/640680/839f4f607631b772.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/4c1eb79af4bbb5fb.png" alt="Markdown"><br>可以看到一千次抽样的测试结果，大多数测试的PCC都比较高</p><p><img src="http://i1.bvimg.com/640680/bea286d0f130d044.png" alt="Markdown"><br>按照样本查看每个样本多次抽样的平均PCC，注意这里是有bias没有消除的<br><img src="http://i1.bvimg.com/640680/17df0a3dcaa71ada.png" alt="Markdown"></p><p>这里绘制了每个样本的平均PCC heatmap图像,可以发现大多数的样本是很好预测的，样本性状基本由父本性状主导(纵坐标为父本),但是少数亲缘关系较远的父本（图中蓝色线）就很难预测。<br><img src="http://i1.bvimg.com/640680/50adb2cb87536a3d.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/48ee63cf0c78d296.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/d3bb77a76c162d53.png" alt="Markdown"></p><p>不同父本的性状有显著差别，而子代的性状由于设计原因，主要由父本控制。<br><br>我们可以通过绘图查看不同父本的性状的变化<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">male_index = np.ndarray([<span class="number">6210</span>,]).astype(<span class="string">'int'</span>)</span><br><span class="line">for i in range(<span class="number">6210</span>):</span><br><span class="line">male_index[i] = int(np.array(phenotypes[<span class="string">'pedigree'</span>])[i].split(<span class="string">'_'</span>)[<span class="number">2</span>][<span class="number">1</span>:])</span><br><span class="line">male_trait1 = np.concatenate((male_index.reshape(<span class="number">1</span>,<span class="number">-1</span>),np.array(pheno_whole[<span class="string">'trait1'</span>]).reshape(<span class="number">1</span>,<span class="number">-1</span>))).<span class="symbol">T</span></span><br><span class="line">male_trait1_bysort = male_trait1[male_trait1[:,<span class="number">0</span>].argsort()]</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line">ax.plot(male_trait1_bysort[:,<span class="number">1</span>])</span><br><span class="line">ax.set_title(<span class="string">'different males have varied values'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="http://i1.bvimg.com/640680/818f1d13de885240.png" alt="Markdown"><br>以上内容简要地介绍了eMaize问题使用的一些基本的常用的机器学习方法，包括数据预处理、特征选择、降维、回归以及分析。本教程还顺便展示了一些python常用的工具包的使用，读者有时间可以慢慢体会其中的具体操作，因为jupyter notebook的可视化与交互性很强，读者可以方便地查看中间步骤的数据情况，更好地理解代码所进行的操作。<br><br>由于实际工作的步骤、数据量、变量等问题，还需要慎重考虑计算时间、任务管理等工作 <br><br>想要预测较难预测的样本仅仅靠常规的机器学习方法并不够用，将机器学习应用于生物学问题时，不能简单套用模型，还需要根据问题进行针对性的设计，才有可能取得更好的结果。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是为实验室写的，借由eMaize问题帮助大家简单了解机器学习基本方法和基础代码的教程。也可以在&lt;a href=&quot;https://lulab.gitbooks.io/bioinfo/content/5%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B4%E5%90%88----%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/51.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;看到&lt;/p&gt;
&lt;p&gt;由于jupyter notebook的强大的展示功能，本教程还用jupyter notebook组织且运行，可以获得更好的学习效果，代码在&lt;a href=&quot;https://github.com/james20141606/somethingmore/blob/master/bioinfo.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;,欢迎取用。&lt;a href=&quot;http://localhost:4000/2018/04/12/setup/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;在这里&lt;/a&gt;我简单介绍了如何配置jupyter，在&lt;a href=&quot;https://james20141606.github.io/2018/04/10/Deep-Learning-Practice/&quot;&gt;Deep Learning tutorial&lt;/a&gt;中我也强烈推荐了jupyter，并且介绍了很多基于jupyter的资源，强烈建议尝试一下。&lt;br&gt;
    
    </summary>
    
      <category term="techniques" scheme="http://james20141606.github.io/categories/techniques/"/>
    
      <category term="machine learning" scheme="http://james20141606.github.io/categories/techniques/machine-learning/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="machine learning" scheme="http://james20141606.github.io/tags/machine-learning/"/>
    
      <category term="techniques" scheme="http://james20141606.github.io/tags/techniques/"/>
    
      <category term="bioinformatics" scheme="http://james20141606.github.io/tags/bioinformatics/"/>
    
  </entry>
  
  <entry>
    <title>陈炳林回忆录 序言</title>
    <link href="http://james20141606.github.io/2018/04/11/auto0/"/>
    <id>http://james20141606.github.io/2018/04/11/auto0/</id>
    <published>2018-04-11T02:10:01.000Z</published>
    <updated>2018-04-12T15:22:53.537Z</updated>
    
    <content type="html"><![CDATA[<p>本文章同时被整理成一本小书，放置在我的gitbook账户下，点击<a href="https://legacy.gitbook.com/book/james20141606/grandpa-autobiography/details" target="_blank" rel="noopener">这里</a>可以阅读。</p><h1 id="Preface-前言"><a href="#Preface-前言" class="headerlink" title="Preface 前言"></a>Preface 前言</h1><p>这份不长不短的回忆录源自于清华大学的毛中特课程的一份作业，在一年以前就打算选择冯务中老师的课，原因就是打听了各个老师的任务，对这项任务非常感兴趣，无奈没有抢到课，但是却开始了帮助爷爷奶奶整理这份回忆录的过程。平时每个周末都会和爷爷奶奶视频聊天一两个小时，自从有了这个想法，就会专门和爷爷奶奶聊过去的故事，顺带鼓励他们动笔写一些。爷爷年轻时是县委组织部的笔杆子，虽然已经七十多岁了，听到我的鼓励也有些心动，多年未提笔，写起来却是收不住，听奶奶说爷爷经常凌晨四五点起来就开始写，边写边流泪，回忆幼年时的艰辛与不易。这份回忆录，讲到了爷爷中年时期即止，爷爷说，年轻的生活更加刻骨铭心，令人难忘，后来生活好转，一切顺利如意，倒也没什么可写了。<br><a id="more"></a></p><p>这份回忆录以爷爷为主要视角叙述，补充了很多和奶奶讨论之后获得的细节，家里过去非常的穷，留下的资料几乎为零，曾经爷爷的哥哥大爷试图整理一份家谱出来，也被爷爷的爸爸在大爷去世后烧毁，因此我们也觉得能够再整理出一些过去的故事非常有意义。这里面的一些故事朴实又动人，在我整理的过程中充满了感慨和感动，让我体会到祖辈们的艰苦和不屈的精神。有的故事还带来了意想不到的惊喜，比如爷爷专门回忆了他年轻时结识的一个好朋友周聚照，已经几十年联系不上了，我整理完爷爷的回忆录，对这位朋友印象深刻，因此自告奋勇帮爷爷联系，在几个可能的地点的百度贴吧发布帖子，真的找到了这位老人的家人。爷爷和奶奶非常激动，第二天就坐车前去看望，周聚照老人已经不在了，但是他的后代生活的很好，孙辈们都获得了很好的教育，考入了很好的大学，改变了自己的命运，真的很令人感慨。另一个故事，爷爷没有亲手写下来，但是还是忍不住告诉了我，就是回忆录的最后一个故事，关于正义的故事，这个发生于爷爷的父亲身上的真实的故事深深的震撼了我，让我对那个混乱的年代有了更深的体会。<br>最后还整理了一个简单的按照年份的时间表，还用一个专门的软件macfamilytree制作了一个这三四代人的家谱树，希望未来的家谱树可以越来越大，开枝散叶，生生不息。</p><h1 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title="目录   Table of Contents"></a>目录   Table of Contents</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><a href="https://james20141606.github.io/2018/04/11/auto0/">前言</a></h2><h2 id="Chapter-Ⅰ-我的童年"><a href="#Chapter-Ⅰ-我的童年" class="headerlink" title="Chapter Ⅰ 我的童年"></a><a href="https://james20141606.github.io/2018/04/11/auto1/">Chapter Ⅰ 我的童年</a></h2><h2 id="Chapter-Ⅱ-初中生活"><a href="#Chapter-Ⅱ-初中生活" class="headerlink" title="Chapter Ⅱ 初中生活"></a><a href="https://james20141606.github.io/2018/04/11/auto2/">Chapter Ⅱ 初中生活</a></h2><h2 id="Chapter-Ⅲ-难忘的一九五八"><a href="#Chapter-Ⅲ-难忘的一九五八" class="headerlink" title="Chapter Ⅲ 难忘的一九五八"></a><a href="https://james20141606.github.io/2018/04/11/auto3/">Chapter Ⅲ 难忘的一九五八</a></h2><h2 id="Chapter-Ⅳ-新的篇章"><a href="#Chapter-Ⅳ-新的篇章" class="headerlink" title="Chapter Ⅳ 新的篇章"></a><a href="https://james20141606.github.io/2018/04/11/auto4/">Chapter Ⅳ 新的篇章</a></h2><h2 id="Chapter-Ⅴ-休学的日子"><a href="#Chapter-Ⅴ-休学的日子" class="headerlink" title="Chapter Ⅴ 休学的日子"></a><a href="https://james20141606.github.io/2018/04/11/auto5/">Chapter Ⅴ 休学的日子</a></h2><h2 id="Chapter-Ⅵ-婚后的生活"><a href="#Chapter-Ⅵ-婚后的生活" class="headerlink" title="Chapter Ⅵ 婚后的生活"></a><a href="https://james20141606.github.io/2018/04/11/auto6/">Chapter Ⅵ 婚后的生活</a></h2><h2 id="Chapter-Ⅶ-喜上加喜-喜中有忧"><a href="#Chapter-Ⅶ-喜上加喜-喜中有忧" class="headerlink" title="Chapter Ⅶ 喜上加喜 喜中有忧"></a><a href="https://james20141606.github.io/2018/04/11/auto7/">Chapter Ⅶ 喜上加喜 喜中有忧</a></h2><h2 id="Chapter-Ⅷ-工作-崭新的篇章"><a href="#Chapter-Ⅷ-工作-崭新的篇章" class="headerlink" title="Chapter Ⅷ 工作 崭新的篇章"></a><a href="https://james20141606.github.io/2018/04/11/auto8/">Chapter Ⅷ 工作 崭新的篇章</a></h2><h2 id="Essays-短文数篇"><a href="#Essays-短文数篇" class="headerlink" title="Essays    短文数篇"></a><a href="https://james20141606.github.io/2018/04/11/auto9/">Essays    短文数篇</a></h2><h3 id="忆祖母"><a href="#忆祖母" class="headerlink" title="忆祖母"></a>忆祖母</h3><h3 id="忆母亲"><a href="#忆母亲" class="headerlink" title="忆母亲"></a>忆母亲</h3><h3 id="四伯家生活写照"><a href="#四伯家生活写照" class="headerlink" title="四伯家生活写照"></a>四伯家生活写照</h3><h3 id="八岁孩子学走路"><a href="#八岁孩子学走路" class="headerlink" title="八岁孩子学走路"></a>八岁孩子学走路</h3><h3 id="我的第一双棉鞋"><a href="#我的第一双棉鞋" class="headerlink" title="我的第一双棉鞋"></a>我的第一双棉鞋</h3><h3 id="大伯和父亲给祖母惹祸"><a href="#大伯和父亲给祖母惹祸" class="headerlink" title="大伯和父亲给祖母惹祸"></a>大伯和父亲给祖母惹祸</h3><h3 id="真实故事三则"><a href="#真实故事三则" class="headerlink" title="真实故事三则"></a>真实故事三则</h3><h3 id="我的朋友周聚照"><a href="#我的朋友周聚照" class="headerlink" title="我的朋友周聚照"></a>我的朋友周聚照</h3><h3 id="人生机遇只有一次"><a href="#人生机遇只有一次" class="headerlink" title="人生机遇只有一次"></a>人生机遇只有一次</h3><h3 id="过个革命化春节"><a href="#过个革命化春节" class="headerlink" title="过个革命化春节"></a>过个革命化春节</h3><h3 id="石人传说二则"><a href="#石人传说二则" class="headerlink" title="石人传说二则"></a>石人传说二则</h3><h3 id="Poems-诗歌九则"><a href="#Poems-诗歌九则" class="headerlink" title="Poems 诗歌九则"></a><a href="https://james20141606.github.io/2018/04/11/auto10/">Poems 诗歌九则</a></h3><h4 id="玩秋千"><a href="#玩秋千" class="headerlink" title="玩秋千"></a>玩秋千</h4><h4 id="石人山景"><a href="#石人山景" class="headerlink" title="石人山景"></a>石人山景</h4><h4 id="恋家"><a href="#恋家" class="headerlink" title="恋家"></a>恋家</h4><h4 id="四伯"><a href="#四伯" class="headerlink" title="四伯"></a>四伯</h4><h4 id="无题"><a href="#无题" class="headerlink" title="无题"></a>无题</h4><h4 id="思往昔看今朝"><a href="#思往昔看今朝" class="headerlink" title="思往昔看今朝"></a>思往昔看今朝</h4><h4 id="石人山下荡秋千"><a href="#石人山下荡秋千" class="headerlink" title="石人山下荡秋千"></a>石人山下荡秋千</h4><h4 id="咏春"><a href="#咏春" class="headerlink" title="咏春"></a>咏春</h4><h4 id="大竹园变堰潭"><a href="#大竹园变堰潭" class="headerlink" title="大竹园变堰潭"></a>大竹园变堰潭</h4><h2 id="Story-of-Justice-一个关于正义的故事"><a href="#Story-of-Justice-一个关于正义的故事" class="headerlink" title="Story of Justice    一个关于正义的故事"></a><a href="https://james20141606.github.io/2018/04/11/auto11/">Story of Justice    一个关于正义的故事</a></h2><h2 id="Chronology年表"><a href="#Chronology年表" class="headerlink" title="Chronology年表"></a><a href="https://james20141606.github.io/2018/04/11/auto12/">Chronology年表</a></h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文章同时被整理成一本小书，放置在我的gitbook账户下，点击&lt;a href=&quot;https://legacy.gitbook.com/book/james20141606/grandpa-autobiography/details&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;可以阅读。&lt;/p&gt;
&lt;h1 id=&quot;Preface-前言&quot;&gt;&lt;a href=&quot;#Preface-前言&quot; class=&quot;headerlink&quot; title=&quot;Preface 前言&quot;&gt;&lt;/a&gt;Preface 前言&lt;/h1&gt;&lt;p&gt;这份不长不短的回忆录源自于清华大学的毛中特课程的一份作业，在一年以前就打算选择冯务中老师的课，原因就是打听了各个老师的任务，对这项任务非常感兴趣，无奈没有抢到课，但是却开始了帮助爷爷奶奶整理这份回忆录的过程。平时每个周末都会和爷爷奶奶视频聊天一两个小时，自从有了这个想法，就会专门和爷爷奶奶聊过去的故事，顺带鼓励他们动笔写一些。爷爷年轻时是县委组织部的笔杆子，虽然已经七十多岁了，听到我的鼓励也有些心动，多年未提笔，写起来却是收不住，听奶奶说爷爷经常凌晨四五点起来就开始写，边写边流泪，回忆幼年时的艰辛与不易。这份回忆录，讲到了爷爷中年时期即止，爷爷说，年轻的生活更加刻骨铭心，令人难忘，后来生活好转，一切顺利如意，倒也没什么可写了。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅰ  我的童年</title>
    <link href="http://james20141606.github.io/2018/04/11/auto1/"/>
    <id>http://james20141606.github.io/2018/04/11/auto1/</id>
    <published>2018-04-11T02:10:00.000Z</published>
    <updated>2018-04-12T07:56:57.045Z</updated>
    
    <content type="html"><![CDATA[<p>我出生在石桥街西夹后布袋街外祖母家那个巷子里，是一九四零年(民国二十九年)生，赶上三十年年成那年。我出生后家里有四口人，大哥已经两岁。在集镇上住，家里没地没房，不做生意，生存十分困难。后来经人介绍，父亲用卖菜的筐一头一个孩子，挑着我们去白河东沙山给地主彭山种地。地主给了草房两间，几亩薄地，生活勉强过得去。日本侵华后战乱频起，又逢灾年（指1942年七月到1943年春天的那场大灾荒，河南受灾总人数达1200万人，约三百万人死亡），祖母不愿骨肉分离，我们一家四口只好又两手空空搬到祖母借住地薛庄去（魏庄西边西边的那个庄）。<br><a id="more"></a><br>1941年春天母亲得了一场大病（奶花疮），那时我才不足一周岁，正值三十年年成，没饭吃也没奶喝，眼看着就要饿死。父亲只得将家里的一床被子和一条床单带上，徒步到老河口换点吃的。当他第三天凌晨回到沙山家里时，我和母亲两人已经两天没有吃东西了。父亲忙生火做面麸汤面水救命，我竟一口气喝了三大碗，肚子撑得得鼓鼓的，父亲说当时我肚子上的青筋都能看到，我还想再喝一些，母亲坚决不要我再喝，说否则会把人撑死，还是母亲心细。这两升麸面可是救了我的命啊。</p><p>再一次搬回薛庄后，祖母，大伯，爹妈，大哥和我六口人没吃没喝，据说那时候能够食用的榆树皮都被剥光了，树枝、豆科的角皮都吃，人吃了以后拉不出来就用竹签剜，母亲说我当时就用的这个办法，吃饭已艰难至此，总不能全家一起饿死吧，为了减轻压力，祖母带着自己平时少言寡语，木讷死板的大儿子，也就是我的大伯远走他乡要饭去。为了大家的生存，大伯也只能跟着祖母要饭去了。母亲说，为了不让我饿死，她只好把我的大哥也送到外公家，留下我自己一个孩子。好心的黄奶（她有一个终身未娶的儿子留在身边）每顿煮菜汤的时候剩下的饭跟都会让我喝，两家人的饭跟救活了我，黄奶也是我的救命恩人！</p><p>奶奶领大伯远走他乡本身就够难了，大伯一个大男人实在是委屈，进村后他就站在树下或者墙根处，不愿进院子里。可是这样怎么能讨得来饭呢。于是每顿都是祖母先讨来饭让大伯吃，吃的差不多了再去要几口饭自己吃，如果要不到，两个人就只能饿肚子。她要饭不是为了大儿子，不是为了她自己，她带走大儿子，留下我们，是为了留下家族的火种。饿死大伯只饿死一个，饿死我们一家人，不知道陈家还能不能延续下去。祖母说：“人留子孙，草留根”，当时的我们，真可谓是离离原上草，一岁一枯荣；野火烧不尽，春风吹又生了。</p><p>灾荒终于过去，祖母和大伯回家了，大伯没有饿死，祖母没有饿死，我也没有饿死，大家都没有饿死，陈氏家族总算有一线希望了。祖母很伟大，大伯的牺牲值得铭记，我还是大伯的过继儿，大伯的恩情我不会忘记。</p><p>解放前，薛庄有个大地主叫做郭老八，大名并不记得了。他每日都搬一个大圈椅，坐在槐树下纳凉，经常自言自语道：我儿强似我，要钱做什么；我儿不如我，要钱干什么？此人精明算计，在土改前他竟然大肆低价变卖土地、房屋，挥霍家产，到了土改时家产变卖一空，竟然成了贫农，我们才知道原来是人家外边有人，提前知道了形势，想躲过一劫。我的祖母、长辈因长期地无一分、椽无一根，困苦惯了，深受压榨剥削，为了有两亩地，竟然在土改的前一年全家人节衣缩食，纺花织布，买下了两亩薄地。结果第二年就土改了，你说傻不傻，没有知识和文化，真是命苦啊！因我们家里太穷，土改时定为雇农，因此将地主李氏南家最好的三间大瓦房分给我们，后来因为此处没有庭院，所以将瓦房推倒，在现在的老家旧居所用这些砖瓦盖了新房。当时还分得一张核桃木雕花木床，两把圈椅，木床不幸遗失，两把圈椅送去了寺庙中。</p><p>一九四八年，八周岁的我的得了天花，发高烧，没有吃的也没有药医，后来竟然下不了床，不会走路了，于是大伯经常用长腰带绑着我带我重学走路，这次大难不死，没有落下什么大毛病，只是让我的体质变得特别差，这也是我一生体质不好的原因。</p><p>我八岁到十岁的几年主要跟随奶奶去石人沟四伯家生活，他那里吃饱饭没有什么大问题，那几年我终身难忘，有苦有乐，有悲有喜。一九五零年的春天，我开始在尹店小学读书，三年后转学到皇路店完小上学。那时候的学校不布置作业，家里又没有一个识字的人，学的怎么样谁又知道呢？</p><p>抽空拾柴捡粪是我那时候最喜欢干的主业，当时土改给我家分了几亩地，我做梦都想买来一头牛耕地，攒粪让庄稼长得好，能够有吃有喝站到人前，这就是我当时的梦想了！父亲答应了我，买了一头全身黑色的小母牛娃，条件是我不能因此耽误了上学，这头小牛完全由我负责，我当然无比爽快地答应。每日上学和放学路上，我都不走大路，一定要从田间地埂走，割青草喂我心爱的小牛，我爱我的小牛就像现代人爱自己的宝马车一样，这牛是我的希望呀。夏季牛拴在外边，我就把床铺到它的附近，生怕有人晚上偷走它，我上学、养牛两不耽误，把小牛照顾得很好。两年之后，它产下了一头小牛犊，这可把我高兴坏了，生牛肚那晚，我一夜未眠，我想：梦想要实现了，我家现在有两头牛了啊！</p><p>既上学又养牛已经够忙活了，后来小我四岁的弟弟炳义也开始在皇路店上小学了，刚吃过饭去上学还好，他有劲就自己走，等放学回家肚子饿了，他就坐在地上耍赖，非要我背他回去，作为哥哥我就只能背着他走一段路，这可耽误了我割草了啊。</p><p>那时候家里穷，没有任何防寒、避雨的工具，夏季还好办，到了冬天，一下雪可就惨了，我只能把鞋子脱下夹在腋下（只有一双鞋，不能弄湿），脚总是会冻得钻心地痛。</p><p>小学离家有两公里地，下雪的时候就干脆不回家吃午饭了，等晚上路上结冰时再穿鞋回家，当然也是因为中午回家也没什么好吃的，不回去还能少一趟冻脚之苦。我从小喜爱咸饭，若是做了咸面条，妈绝对会给留一大碗。有时候母亲也会托人中午捎来一点红薯面馍，啃一口一个白印。吃红薯太多伤胃，我也因此落下了终身的胃病。</p><p>一九五六年小学毕业后我成功考入石桥镇上的初级中学，当时小升初率不高，所以我真是很幸运。我小学时的班主任张文彬老师亲自步行来家里送录取通知书。全家都高兴极了，家里有中学生啦，就像中了状元似的。父亲一定要留张老师吃午饭，老师答应了，那顿饭也就算是谢师宴了吧！后来我也和张老师成了好朋友，忘年之交了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我出生在石桥街西夹后布袋街外祖母家那个巷子里，是一九四零年(民国二十九年)生，赶上三十年年成那年。我出生后家里有四口人，大哥已经两岁。在集镇上住，家里没地没房，不做生意，生存十分困难。后来经人介绍，父亲用卖菜的筐一头一个孩子，挑着我们去白河东沙山给地主彭山种地。地主给了草房两间，几亩薄地，生活勉强过得去。日本侵华后战乱频起，又逢灾年（指1942年七月到1943年春天的那场大灾荒，河南受灾总人数达1200万人，约三百万人死亡），祖母不愿骨肉分离，我们一家四口只好又两手空空搬到祖母借住地薛庄去（魏庄西边西边的那个庄）。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅱ  初中生活</title>
    <link href="http://james20141606.github.io/2018/04/11/auto2/"/>
    <id>http://james20141606.github.io/2018/04/11/auto2/</id>
    <published>2018-04-11T02:09:59.000Z</published>
    <updated>2018-04-12T07:57:06.487Z</updated>
    
    <content type="html"><![CDATA[<p>入学后我被分到了56丁班，和我后来的妻子是同班同学，她从小学就学习刻苦，成绩优秀，是初中部的学习部长，那时我们是纯洁的同学关系，很少有接触，几乎没有怎么说过话。<br><a id="more"></a></p><p>上初中时正值全国性反右的高潮，一九五六年在庐山会议上本来要纠左，彭德怀上了万言书，反而被毛泽东定性为反党集团，全国轰轰烈烈的反右运动开始了。学校教师有将近一半被划为右派，初中生虽然不划右派，但是对个别学生的言论也进行批判，令其退学。比如薛庄村学生王慧敏受运动刚开始时大鸣大放的影响（即向党提意见），她草书“向毛主席开一炮”，甲班学生柏长松在教工厕所门口写了“屎不一样”，抨击教师和学生生活水平不同，学生生活水平不好。这两人被查出来之后，被全校批判，勒令退学，开除学籍，丧失了继续学习的权利。教职工、学生都被这样的政治空气笼罩着，多数老师被划为右派，可我的班主任贾之广是反右运动中的左派，一副盛气凌人的气度，在丁班大搞紧张气氛，把我和几个要好的同学打成所谓的“小集团”。中央有彭、黄、张、周反革命集团，而我们这小集团是什么性质？我们这些十几岁的娃娃根本不懂，班主任这样做为了什么，我们也不懂。他组织全班同学揭发我们，每晚组织班干部揭发批判，揭什么呀，批什么呀！</p><p>小集团成员是不得随意离校的，离校要遵循请假制度，我们这些人（曹成才、翟清合、王明跃、王松林、雷清茂等人），一举一动都会被人监视着。我当时没钱在大伙就餐，只能立小灶，这小灶可不是现在改善生活的那种，我每周都得回家里挑做饭要烧的柴火，玉米糁和红薯等，可是找班主任请假，他不批准，这可让人怎么生活呀！他越是这样，我们这些好友靠的越紧，凑空就在一起互相诉苦，心情也是越来越差，气氛越来越紧张。</p><p>请不下来假，不回家拿吃的可如何上学？一次周六下午我写好了请假条让贾批准，天色已晚，学生们已经离校了，因为紧张我忘记敲门，直接推门进去了，这时我亲眼看见一个年轻的女教师正仰面躺在他的床上，二人正低声私语。这实在是够尴尬了，可我没有退出来，拿着请假条死缠着要回家，这举动自然是激怒了他，他要我出去，我想着反正他没有把我关起来，也没说不准我回家，我就摸黑偷偷溜回家了。到家后我把当时的情况讲给了父亲，他怒火中烧，说要找贾评理，。我当时不懂，不但给父亲说了此事，也对小集团的成员们讲了贾的所作所为，大家都极其不满，消息估计也传开了，让贾也知道了。父亲出于愤怒竟然也去学校找贾，因此师生间矛盾再次升级，我的对手可是年近四十的人，在国民党电台任过台长，还是反右左派，斗争经验丰富，我就像一个不会反抗的犯人一样，被牢牢地控制住了。</p><p>由于我精神压力巨大，不久就得了一种怪病：正走路时眼前一黑，头一晕，腿发软，就向前摔去，摔得鼻青脸肿。不用班主任勒令我回家，我自己也只得休学了！</p><p>贾的恶作剧并没有结束，他极其会戏弄人，命令小集团的成员用学校拉垃圾的车子拉我回家，路上这群无知的青年竟然还兴高采烈，欢声笑语，驾着垃圾车飞跑，好像我刚从恐怖的监狱里逃出来一样高兴。不管怎样，我休学回家了，当时我并不知道，学生会学习部长王若平也因小学的时候和小集团成员曹成才同班同学（年龄比她大两岁，是小集团首领），被威逼要揭发小集团，她哪知道揭发批斗什么，当然什么都说不出来。后来可恶的贾芝庞组织其他干部把矛头全对准她，向她施压，批判她，她没有经受得住，精神也不正常了，在我休学之前她就已经休学啦，被人送回家养病。结婚后我们两个谈及此事，真觉得不可思议，上帝究竟是如何安排的，让我们两个经历这九九八十一难啊。</p><p>紧接着河南又刮起了一阵反潘、杨、王风，直指潘复生，杨珏，王庭栋。纠左开始了，这才把贾芝庞给揭露了出来，将他绳之以法，判了三年刑。</p><p>被判小集团期间我心情极差，休学回家治疗了一个多月，是尹店中医李连奇给治的，每天一副中药，药引是童便。病治好后该返校了，但是大哥突然罹患脑膜炎病逝，年仅二十岁。当时他已订好婚，五八年底就该结婚了，大哥的猝然离世对家人的打击太大了，父亲因此变得精神不太正常，不思茶饭。在身体极度虚弱的情况下，大队硬是派他去云阳铁牛庙水库做工，在水库父亲也累得病倒了。</p><p>我的病刚好，大哥离世，父亲在水库也病倒了，一九五百年真是灾难性的一年，是黑色的一九五八。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;入学后我被分到了56丁班，和我后来的妻子是同班同学，她从小学就学习刻苦，成绩优秀，是初中部的学习部长，那时我们是纯洁的同学关系，很少有接触，几乎没有怎么说过话。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅲ  难忘的一九五八</title>
    <link href="http://james20141606.github.io/2018/04/11/auto3/"/>
    <id>http://james20141606.github.io/2018/04/11/auto3/</id>
    <published>2018-04-11T02:09:57.000Z</published>
    <updated>2018-04-12T07:57:23.193Z</updated>
    
    <content type="html"><![CDATA[<p>父亲病倒后水库指挥部通知家人，去云阳水库接回父亲。家里只有我可以担当此仁，此时我已经十八岁，刚刚成年。接到通知的时候我害怕极了，父亲可千万不能出事啊。我恨不得自己能赶快长出一双翅膀飞过去接他回家。<br><a id="more"></a><br>第二天一大早，我拉着架子车就上路了，开始时我是跑着拉车，走过鸭河之后就心有余而力不足了，上坡路是绝对跑不动了，但是心里着急，还是一刻不停地走着，一天只喝了几次水，没有进食任何东西，经过一天的奔波，晚上才到云阳，因为是头一次去，走的晕头转向，肚子一天没有吃东西却也不觉饿，只是口渴难耐，说不出话。经过打听之后得知还有十公里路，没有正路可走，步行沿着河边走倒是可以快一点，但是车子放哪里呢？没有车子第二天如何拉父亲呢？可是我太急于见到父亲确定他没事，人受挫折武艺高，我找了一家修车铺，放掉车胎气，自述架子车放了炮，得补胎，我把架棚靠人家店外，下盘搬进屋子里，说好了明天来拉车付款。我顾不得吃晚饭，就按照人家指的路线摸黑去水库。天黑路生，河里不时发出响声，好像是鱼儿拍打水面，没有出过远门，没有一个人走过夜路的我，自然情绪紧张，稍有风吹草动就会东张西望。我越紧张，就越觉得背后有什么东西在跟着我，我吓得头发梢支棱着，然而再怕也不能停下，我只能一直往前行，大概在晚上十一点左右终于看到了灯光，那是水库指挥部所在地了。</p><p>指挥部工作人员刚吃过夜宵，我向负责人说明情况后，他叫炊事员把剩下的一大碗甜面片给我吃，还给我拿了几根蒜薹，饭已经凉了，可我终于有了极大的饿意，吃的狼吞虎咽、风卷残云，几分钟就吃完了，噎得直打嗝。他让我找个空铺睡下休息，并通知工地，让父亲第二天一早过来。我哪里睡得着啊，只盼着早点见到父亲，父亲接到指挥部通知说儿子在指挥部等他，已经卧床的他竟然起身一个人摇摇晃晃地往指挥部走。次日拂晓我和父亲终得相见，我们像久别重逢一般抱头痛哭，父亲安慰我说，见到你我的病就轻得多啦。我的泪水不光是因为见到了父亲，酸甜苦辣咸五味俱全，这几年我都体验了一遍啊，心中的苦楚一起涌上心头：小集团、生病、休学、兄长病殁、父亲精神失常、小弟炳都得转头虱病。正所谓男儿有泪不轻弹，只是未到伤心处。</p><p>太阳冉冉升起来啦，我和父亲一起，扶着他向云阳走去，在停架子车的店铺说明情况后取出架子车，走进旁边的一家食堂。他说：“今天我们父子俩吃炝锅面，再买一斤油条，加进去美美气气吃一顿。”父子见面，他的病好了一些，我折腾了一天一夜，但是心里轻松得多了，我只觉得自己腿酸乏力，因为自己也才病愈，又一口气跑了那么远。吃完饭，我强打精神，他坐车我拉车，往回家的路走，边走边聊。父亲见我也是强打精神，他说上坡时我下来，下坡时我再坐车，走一阵咱俩换换，我拉车你坐车。听父亲这么说，我不怕了，父亲还能活！当天夜里我们顺利到家了。别了，黑色一九五八！！</p><p>当父亲处理完这些事情后，就带着我复学，他先领我见了四中当时的校团委书记和宝兴，请他多关照我，和宝兴家在皇路店沽沱村，不知道父亲是怎么认识他的。复学前后还在学校经历了勤工俭学、大炼钢铁、白河淘铁砂（炼钢用）等运动，我的求学路可谓一波三折啊，孙辈们是难以想象的！</p><p>勤工俭学：五人一辆独轮木质手推车（当时称之为小车），去南召三岔口买柴，因为没有大路走，只能从全是乱石的河滩里推着走，我们披星戴月，买柴卖柴，赚了多少钱已经记不清啦。</p><p>炼钢铁：就在学校西南角空地处放一个炼铁炉，大风箱得六七个人同时拉才能拉动，炉子里放的是铁锅、铁盆、生铁之类的铁制品，各种废铁堆在一起烧，至于能烧出多少铁根本没有人管它，这样荒唐的事当时正在神州大地的每个角落发生，在大炼钢铁的过程中，南阳县四中的全体学生也都停课了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;父亲病倒后水库指挥部通知家人，去云阳水库接回父亲。家里只有我可以担当此仁，此时我已经十八岁，刚刚成年。接到通知的时候我害怕极了，父亲可千万不能出事啊。我恨不得自己能赶快长出一双翅膀飞过去接他回家。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅳ  新的篇章</title>
    <link href="http://james20141606.github.io/2018/04/11/auto4/"/>
    <id>http://james20141606.github.io/2018/04/11/auto4/</id>
    <published>2018-04-11T02:09:55.000Z</published>
    <updated>2018-04-12T08:11:41.163Z</updated>
    
    <content type="html"><![CDATA[<p>我在一九五九年夏季初中毕业，学校要求毕业生要主要报考高中、师范。高中是绝对上不起的，当教师是臭老九，经过反复的斟酌，我选择了当时自己觉得最受人崇拜的专业：农机化专业，这可是毛主席提出的四化之一，就这样我顺利录取到了郑州农机化专科学校（1960年，郑州农业机械化专科学校并入河南农学院（现河南农业大学），组建河南农学院农业机械化分院），我仿佛已经能够想象出自己开着铁牛奔驰在祖国广阔原野上的场景了。<br><a id="more"></a><br>那年全校有毕业班四个，录取农机化专业的一共有四个人，甲班的王文武，丙班的丁立志，以及丁班的我和王若平。九月份就要开学啦，我们的学校在省城郑州，郑州在哪里，路有多远，要坐汽车和火车才能到达，这些对于没出过远门的我（在石桥上学期间只到过南阳城区一次，参观李花庄铁牛耕地，面粉厂的大型面粉加工设备）来说，真是无比新鲜，更何况就要长期离开父母，相隔好几百里呢。去郑州要结伴，毕竟人多智谋广啊，我觉得约上同班同学，又录取同校的王若平是首选，我估计她也会首选我结伴同行。经过打听得知，郑州农机化专科学校和郑州计划经济学校在同一条路上（农业路），距离很近，为此又约上录取该校的赵玉珍，闫学珍结伴。</p><p>行动路线、时间、人员集合地点等确定后，我们头一天先各自步行至南阳，晚上住在闫学珍的亲戚家（地址在老一中东，现在的市第八小学附近）。第二天一大早我们乘坐南阳开往许昌的代客车（也就是货车上加一个帆布篷，车厢上固定有大连椅），到达许昌汽车站已经是下午了，经过购票排队，在火车站排队候车，终于坐上了一辆从三门峡至许昌的火车，我们于次日凌晨抵达省城火车站。经过打听得知去北郊（那时农业路附近是郑州的郊区）那趟公交车是烧木炭的车，夜里无法发车，于是我们决定坐三轮车去学校。其实当时学校在火车站设有接待站，有车接我们，可是我们奔波两天，初到省城，火车站又乱，竟然没有注意到。</p><p>从偏僻的农村到南阳首府，到许昌，到河南的省会，全国交通大动脉，漫长的路程，全新的景象，我心中的那份心情可想而知，生活，全新的生活就要开始了！</p><p>入校之后学校首先对我们进行了专业教育，介绍学校环境：大礼堂、小礼堂、校医院、图书馆、教学大楼、大体育场等，学校有高水平的篮球队，棒球队和排球队，学校的业余剧团，还能去校外演出的剧团。每周末学校都会放电影，有各种球队比赛等娱乐活动。学校有大型实习工厂，车钳电焊，车床设备齐全，所加工的游标卡尺，缸盖修理等工艺具有很先进的水平，可以当做商品售卖，有订单，能赚钱。大小汽车数量，实习用各型号链式和轮式拖拉机齐全。学校还有菜地百亩，黄河滩可耕地几百亩，每年收成很多小麦，伙食是八人一盒菜，而且吃饭不限量，管理生活的副校长在大礼堂讲话时宣布，要把大家都养成大胖子。</p><p>学校不收书本费、生活费，每人每月12.5元，除了医疗费1.5元外全是生活费。生活、学习、环境全都令人满意，四中时期的阴影全都抛到脑后了，那里的生活是崭新的，前途是无量的，只等毕业分配工作，当干部，拿工资，养家糊口了。</p><p>然而好景不长，一九六零年的秋季，左倾思潮翻涌，阶级斗争、政治运动席卷全国，粮食生产急剧下降，人民群众的生活水平降到了最低水平线（1960-1962年发生了著名的三年自然灾害，河南等粮食产地受灾尤为严重）。省城告急了，就要断炊了，刚开始学校提出“低标准，瓜菜代”，用东北运来的大豆面加上黄河滩的蒲草做窝窝头吃，稠一点的大米饭用秤称。再往后，火车运到郑州的粮食竟然来不及开进粮店，大专院校的车就已经开到火车站拿着粮本开始接货了，学校再也坚持不下去了，郑州也坚持不下去了，唯一的方法是减少城市人口，减少不种地只吃饭的人的数量，于是在六一年，人口集中的大专院校全部停办，以减轻省城压力，农村是广阔的天地，我只能重新回到广阔的农村了，我重新回到了阔别两年的家。</p><p>虽然能见到久别的父母，可是回家的心情一点都不愉快。我心事重重，学校宣布放长假，有多长？还能回校吗？连粮户关系（指粮食与户口关系，当时有农业与非农业两种户口）都又非转农了，还有机会农转非吗？看来只能做一辈子的农民啦。你放假，我放假，结伴回老家。又是经历同样的交通路线，经过一天一夜的折腾才到南阳，那时又是凌晨，我和同学王若平背着行囊，低头不语，步行走在回家的路上。天亮才走到蒲山殷庄她的家，该歇歇脚了。她慈祥的妈妈为我俩做了一顿削过皮的红薯白面疙瘩，接待诚恳热情，她哪里知道接待的人竟是她未来的女婿呀！那可是三年自然灾害期间，这顿饭我终生难忘，饿了甜似蜜，不饿蜜不甜啊，削过皮的白面面疙瘩，又香又甜不塞牙，怎么能轻易忘记呢，这是我在若平家吃的第一顿饭。</p><p>结伴同行去郑，结伴同行回家，感谢您招待的这顿饭，感谢我的老同学，再见吧老同学，再见！不送啦！我又迈步向家的方向走去，可我像霜打了一样，无精打采，徒步走回魏庄的家里。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我在一九五九年夏季初中毕业，学校要求毕业生要主要报考高中、师范。高中是绝对上不起的，当教师是臭老九，经过反复的斟酌，我选择了当时自己觉得最受人崇拜的专业：农机化专业，这可是毛主席提出的四化之一，就这样我顺利录取到了郑州农机化专科学校（1960年，郑州农业机械化专科学校并入河南农学院（现河南农业大学），组建河南农学院农业机械化分院），我仿佛已经能够想象出自己开着铁牛奔驰在祖国广阔原野上的场景了。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅴ 休学的日子</title>
    <link href="http://james20141606.github.io/2018/04/11/auto5/"/>
    <id>http://james20141606.github.io/2018/04/11/auto5/</id>
    <published>2018-04-11T02:09:53.000Z</published>
    <updated>2018-04-12T08:11:53.357Z</updated>
    
    <content type="html"><![CDATA[<p>回乡后的我很快就适应了农村的生活，我是地道的农民的儿子，但是我心里还是惦记着上学时的生活，惦记着我的老同学，他们现在生活的怎么样，他/她们在干什么呢？老家尹店每年农历四月初八的庙会规模大，总是有两台戏，约老同学来赶庙会、叙叙旧应该是不错的选择！于是同班同学王若平和赵玉珍应约前往，逛完庙会又去了我的家里，父母热情地接待了她们，也让她们感动不已。<br><a id="more"></a><br>同样的命运，同样的环境，同样的人生遭遇，五年的同窗同学生活，我和王若平见面有太多想说的，有太多的共同语言，我们倾诉着各自的遭遇、生活中的喜怒哀乐，缘分就是这么奇妙，所谓日久生情，时间久了，我们的关系从普通的同学关系，变得不太一样了，内心仿佛多了些什么？</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;回乡后的我很快就适应了农村的生活，我是地道的农民的儿子，但是我心里还是惦记着上学时的生活，惦记着我的老同学，他们现在生活的怎么样，他/她们在干什么呢？老家尹店每年农历四月初八的庙会规模大，总是有两台戏，约老同学来赶庙会、叙叙旧应该是不错的选择！于是同班同学王若平和赵玉珍应约前往，逛完庙会又去了我的家里，父母热情地接待了她们，也让她们感动不已。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅵ  婚后的生活</title>
    <link href="http://james20141606.github.io/2018/04/11/auto6/"/>
    <id>http://james20141606.github.io/2018/04/11/auto6/</id>
    <published>2018-04-11T02:09:51.000Z</published>
    <updated>2018-04-12T08:11:58.734Z</updated>
    
    <content type="html"><![CDATA[<p>燕尾山拾柴历险记</p><p>经过双方父母见面，我们这两个老同学确立了夫妻关系，于一九六二年农历七月十一日喜结良缘，开始了又一段崭新的生活。我不仅是一名失学的学生，农村的农民，还是一名丈夫，而且很快，就要成为父亲了。</p><p>一九六二年的农历闰四月，家里连一点可以吃的东西都没有了。已经怀了身孕的妻子只能靠着白水煮红薯干充饥，想吃点别的什么食物都是奢望。老家每年四月八号的庙会总会有亲朋好友和同学们来家里，断炊了还拿什么招待呢？我决定跟随邻居，去燕尾山拾柴变卖来赚些钱买点粮食。<br><a id="more"></a><br>为什么偏要去燕尾山呢，因为那座山较险峻，海拔高，很少有人涉足，所以山上容易弄到枯枝烧柴。我们出发的时候只带了能吃七天的玉米糁，脚穿妻子给我做的新布鞋。南召人说：南召到路上，七十二道脚不干。前四月山区还有些冷，河水依然冰冷，一会脱鞋淌水，一会儿穿上走山路。上山的时候要拉着荆藤向上爬，下来可就难多了，所谓上山容易下山难之说，这时才体会的格外清楚。夜晚露宿在山岔里，盖那床又脏又薄的褥子。四月的山区，夜间比平地还要冷上好几度，晚上睡觉是怎么也暖不热的。</p><p>玉米糁吃光了，拾到的柴还不够一车，没东西吃了，我和邻居李连有大叔只能饿肚子。李大叔不知道怎么想到办法，从山区的支部书记老婆那里弄来了免费的玉米糁，不过是发了霉的，像蚂蚱牙似的，不管怎么样，吃的问题总算是解决了。</p><p>支部书记夫人四十多岁，穿着扎花鞋，还用红头绳扎着头发，有着山里人特有的气质。我们一日三餐都吃着她提供的发霉了的玉米糁，饿了甜似蜜，填饱肚子第一，我们也不挑。不知道那位支书夫人是不是出于可怜之心，第二天又给我们送来了发粘的芥菜丝让我们陪着饭吃，李连有大叔竟然感动得跪地磕头致谢，场面令我也感到震撼，我也从内心深处感谢这位女菩萨的施舍。</p><p>终于拾够了一整车的柴，我们满载而归，上山坡时你推我拉，互相帮助，饿了找背风处生火做饭，天黑人困了找山坡背风处睡觉。遮风避雨的小宿舍几分钟就可以搭建好，我们也没有功夫像现在的野营爱好者那样花那么多力气。用拉车的人常备的支杆将车把支牢固，取下小铺盖，裹上被子于车下即可酣然入睡好解乏。不失眠，超过席梦思，赛过金銮殿。</p><p>这趟北山拾柴历经十天，竟卖了六斤肉（瘦了六斤），脸瘦了一大圈，出发时穿的那双新布鞋也已经破了，脚跟露在外边了。全家人在家吃着清水煮红薯片等着我，而我上山拾柴那几天，想吃红薯片汤都难啊，当时的生活就是艰难至此。</p><p>苦味是五味之首，有苦才有甜，这是最质朴却深刻的人生哲理。卖掉一半柴火用来购粮食，另一半留下烧锅，顺利地度过了难关。这年五月初一，我的长子陈华军出生了，你说我的心里该有多甜啊，这样的苦难过后的甜，真是世上最甜的滋味了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;燕尾山拾柴历险记&lt;/p&gt;
&lt;p&gt;经过双方父母见面，我们这两个老同学确立了夫妻关系，于一九六二年农历七月十一日喜结良缘，开始了又一段崭新的生活。我不仅是一名失学的学生，农村的农民，还是一名丈夫，而且很快，就要成为父亲了。&lt;/p&gt;
&lt;p&gt;一九六二年的农历闰四月，家里连一点可以吃的东西都没有了。已经怀了身孕的妻子只能靠着白水煮红薯干充饥，想吃点别的什么食物都是奢望。老家每年四月八号的庙会总会有亲朋好友和同学们来家里，断炊了还拿什么招待呢？我决定跟随邻居，去燕尾山拾柴变卖来赚些钱买点粮食。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅶ 喜上加喜 喜中有忧</title>
    <link href="http://james20141606.github.io/2018/04/11/auto7/"/>
    <id>http://james20141606.github.io/2018/04/11/auto7/</id>
    <published>2018-04-11T02:09:49.000Z</published>
    <updated>2018-04-12T08:12:06.547Z</updated>
    
    <content type="html"><![CDATA[<p>我和若平两人背景相同，志同道合，结婚后朝夕相处，可以永不分离，两个人形影不离，生活觉得甜蜜极了，结伴扛着农具干活去，在乡下的生活倒也过得有滋有味。我的长子陈大军出生后，全家都高兴坏了。父亲说，长子得了长孙，家里人丁兴旺了起来，再困难也得办几桌酒席，让亲朋好友齐聚一堂，共享快乐。父亲是非常能干厉害的人，在那么困难的条件下（三年灾害刚刚过去），操办了全席酒宴，我由衷地感激父亲。<br><a id="more"></a><br>开席了，村里面很多年没有人家办全席了，男女老幼满庭院，孩童们将白馒头偷偷揣进怀里，大人们猜枚行令，真是热闹非凡。</p><p>两点多啦，酒宴临近撤席，有的亲戚朋友到院外互相问候、攀谈，准备道别。女人们争相到妻子床边亲眼看一看儿子的容貌。为了准备这十几桌酒席，我忙活了好几天，这会是个空隙，我搬个小凳子坐在大门外左侧池塘边那棵桃树下稍事休息，成家啦，得子啦，还是个小子呢！我忍不住开心地笑着。这棵桃树桃儿满枝头，硕果累累，这树是我亲手所栽，一点点培育长大的呢！农家人的快乐、幸福与满足一齐涌上心头，多久都没有这么快乐过了呢！</p><p>正想着心里的事，有两个推着自行车的人朝大门口走去，询问陈炳林、王若平两人是否住在这里。我抬头望去，两个人的面孔好生熟悉，这是哪里来的客人呢，怎么这个时候才到，我该怎么招待呀。再仔细一看，原来是郑州学校的班主任何老师和教汽托课的邢仁军老师，我赶忙跑步过去迎接。我心里震惊得说话都语无伦次了，我说，老师您吃饭了没有，您咋知道我和王若平的家在这里？在校时我俩是他们的学生，现在我们已经成为了夫妻，孩子都出生了，正好赶上办酒席，真的有点尴尬。</p><p>邢仁军老师教汽车拖拉机课，他语言精练易懂实践经验丰富，实习课上他经常让我操作示范给大家看，对我器重有加，青眼相看，我也非常喜欢他，他是我心中的偶像。班主任和我最喜欢的老师来到家里，自然是非常激动。</p><p>接下来的消息更是让人激动不已，老师说：祝贺你们双喜临门，学校也要复课啦，这是入学通知书，交给你们。我双手接住了两份沉甸甸的通知书。</p><p>事前没有任何的讯息，二位老师又千里迢迢将入学通知书递到了手里，我既惊喜又感激。我说：老师，我和王若平已经结婚生子了，学校还会要我们吗？老师的回答是坚定的：这个问题是国家造成的，你们没有过错，学校会接收你们的。你们在校时的表现我是知道的，王若平还是班干部，学生会的学习委员哩，放心吧，学校一定会收你们的！</p><p>我校能复课开学，乃是占了“农”字的光。因着毛主席提出“农业的根本出路在机械化”的批示得以率先复课，其他的院校都还没消息呢。</p><p>瞬间，地道的农民又可以上学啦，可以重新当城里人，读书人了。做了爸妈的人要去上学啦，儿子怎么办呢？在农村出了这样的新鲜事，你说稀奇不稀奇？</p><p>距离开学只剩下两个月了，谁去谁留？都去都留？欣喜之后是烦恼，这个问题始终困扰着我俩，萦绕在我们心头。全家人也争论不休，我们征求了岳父母的意见，也和内兄写信联系，大家的意见是，都去上学。岳父母资助了一些费用，内兄也汇来了钱款。再难也得坚持下去啊，妻子也强调，不管谁去谁留都可能给婚姻和家庭带来变故，而我们都极其渴望重新上学，改变命运，因此最终我们达成了一致，一起复课学习。</p><p>两个月飞速过去，我俩要离开这个家了，要离开儿子了，儿子虽然个头不小，可是因为他母亲怀他时严重营养不良，这时竟然连头也直不起来。儿子让我们割舍不下，心疼不已，后来在沽沱村找到奶妈，草草安置后，含泪依依不舍地离开了家，我们重新踏上了求学之路。</p><p>可怜天下父母心，儿子是母亲身上掉下来的肉，儿行千里母担忧，如今是母行千里，留儿子在家里。在最后一年的学生生涯里，儿子的身影时刻萦绕在她的心头，她上课经常走神，清净时甚至能隐约听到儿子啼哭的声音，身边没人时她就经常把自己为儿子做的一身小衣服，连同帽子摆在自己床上，摆弄摆弄看是否合身。她只要听到楼上女教师儿子的啼哭声就会不由自主地流眼泪。这一年应该说是短暂的，对我们来说却是无比漫长的。春节到了，本来是个千载难逢的探望家人的机会，团聚一堂的机会，可以和家人还有儿子团聚了，可是因为没有经费，我俩只能回去一个人，于是妻子回家，我一人留在学校，我会情愿吗，实在是无奈之举啊。妻子为了既能探望婆家人，又能见到父母，拉着架子车把婆婆和儿子拉到外婆家，以达到和儿子分秒不离的目的。留在学校的我心中是什么滋味，就让各位读者自己品味吧！</p><p>在这最后的学生生活里，因为精神压力大，我曾多次生病，眼睛患结膜炎、角膜炎，还有胸膜炎，胃病，失眠等疾病。由于视力极度下降，怕光、怕风、流泪，我无法进行毕业笔试考试，后来经校方特批，部分课程改成口述答题。坚持就是胜利，最后我竟然以优异的成绩顺利完成考试，毕业了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我和若平两人背景相同，志同道合，结婚后朝夕相处，可以永不分离，两个人形影不离，生活觉得甜蜜极了，结伴扛着农具干活去，在乡下的生活倒也过得有滋有味。我的长子陈大军出生后，全家都高兴坏了。父亲说，长子得了长孙，家里人丁兴旺了起来，再困难也得办几桌酒席，让亲朋好友齐聚一堂，共享快乐。父亲是非常能干厉害的人，在那么困难的条件下（三年灾害刚刚过去），操办了全席酒宴，我由衷地感激父亲。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅷ 工作,崭新的篇章</title>
    <link href="http://james20141606.github.io/2018/04/11/auto8/"/>
    <id>http://james20141606.github.io/2018/04/11/auto8/</id>
    <published>2018-04-11T02:09:47.000Z</published>
    <updated>2018-04-12T08:12:12.567Z</updated>
    
    <content type="html"><![CDATA[<p>一九六四年八月中旬，我和妻子顺利毕业了，回宛后住在现在的新华宾馆等地方人事部门分配工作，妻子被分配到原安皋拖拉机站，我被安排到茶庵拖拉机站，过着两地分居的生活。</p><p>我在茶庵期间，单位的一把手杨永江是原来的茶庵区副区长，人很能干精明。他是姑婆家（槐树湾姑爷妹妹的老公）亲戚，待我非常的好，我就和他住在一个房间，他既是领导，也是朋友、同事，我们无话不说，因此工作上我就不怕了，谁也不敢欺负我。一九六四年八月十五日到达工作岗位后，我赶上了发工资，领到了人生的第一笔工资，成了国家的正式干部。<br><a id="more"></a><br>当时交通不便利，从茶庵到南唐路这十几里不通车，一下雨雪连步行都困难，虽说我们夫妻二人同在南阳县，可是相见格外的难，茶庵至南阳二十公里，在南阳东南角，安皋距南阳二十五公里。平时我们工作繁忙，一年四季在农村犁地，昼夜在田间摸爬滚打，一收车回单位就要修车，两人相见甚难。每年有一次表彰先进大会（在县里开），是唯一的可以见面的机会。</p><p>六四年十一月，小四清运动开始，茶庵是第一批重点，收车回单位搞小四清运动，气氛紧张得很。职工、干部人人自危，整天开会，宣扬着坦白从宽、抗拒从严的一套，工作队员凶神恶煞，非常的阴森恐怖。</p><p>我刚分配工作到茶庵，没有四不清问题，经过审查后被认定为运动积极分子，亲眼目睹了那场小四清不小的整人运动。单位李书祥被逼把头往砖块上撞，一般干部周文甫吓得尿裤裆。会计穆胜力被逼得悬梁，那天晚上正是我值班看守他，当晚戏园有演出，我想去看两眼，就告诉穆胜力找本书看看，不要乱想，你没有贪污，肯定会弄清楚的。我反锁房门就去了戏园，当我走到茶庵街跃进门旁时，天冷打了一个喷嚏，皮带断了，穿着棉裤没法走路，只好原路返回。我开了他房间的门，油灯灭啦，掏出火柴一划，人也不见了，又划了一根火柴，才看清楚他已经站在了办公桌凳子上做好了悬梁自尽的充分准备：绳子套在脖子上，只待用脚蹬凳子，顷刻间就会命丧黄泉。只消再晚三分钟，小穆成了冤死鬼，我也会因为失职而受到处分。我赶紧帮他下来，经过我耐心地劝导，他不再有了寻死的想法，我当然也轻松了，我了解他，他为人正直，我向他保证，会让他见一下他刚出生还没见过一次的儿子，后来我也帮他实现了。我主动请缨参与穆胜力贪污案，查案的过程就不详述了，最后终于查明是冤假错案，他没死，而且清白了，后来调到了安皋区拖拉机站继续干会计。运动后期小穆跪在我面前，跪谢我的救命之恩，我当然也理解他的心情，当年我也被人冤枉过，我发誓这辈子都不能冤枉别人，不能整人，更要帮助被冤枉的人，这是我做人的准则。</p><p>我因为在运动中表现突出，被定为中共预备党员，我是一九六四年十一月在茶庵区拖拉机站入党的，入党介绍人是机务队长王风杰。因有行政负责人杨永江推荐，在四清运动中表现好，查案立功，我在六六年初被调至县拖拉机总站，也就是现在的农机局。</p><p>到任后我被分配在机务科工作，任技术员。从此进城了，有了自己的办公室、办公用品、单人房和各种办公设施，取暖设施也齐全。城乡是有一定差别的，我开始了崭新的生活，这也为妻子从安皋调进南阳奠定了基础，在南阳生活、安家，养儿子。我一九六六年调南阳后经做工作，王若平于一九六九年被调县农机局修配厂当车工、新的生活开始啦。</p><p>一九六六年六月十六日，中央下达通知，一场轰轰烈烈的大革命开始了。那时候我才二十几岁，刚刚步入社会，缺乏经验，文革的是非曲直都让别人写吧，全国都一个模式，说不清楚，写不完，就全部省略了吧！反正我不是当权者，当然不受批判，性格决定我也不做亏心事，不做过激的事，因此也没留下大后患。那场大运动对我们这些从校门步入社会的大小知识分子，年轻人来说，实在是弊大于利，害了一大批风华正茂的年轻人，甚至有人为此付出了生命的代价。</p><p>现在年纪大了，经验和教训积累了很多，有很多感慨。年轻人易冲动，好鼓动，感情用事，不瞻前顾后，不思考后果，不听长者劝告，一意孤行，一头撞到南墙上，会吃大亏的。儿孙们都要记住，做任何事都要三思而后行，要多思考，深思熟虑后再行动，还要多请教别人，三个臭皮匠赛过诸葛亮。</p><p>文革后期成立了革命委员会，“农林水机电革命委员会”，把五个单位合为一体，我被安排在农业局担任政工工作，接着去李华庄生物制药厂担任政工工作，职位虽然不高，但是因为厂里两个领导互不相让，反而大权旁落，让我成了实际的做决策的人，生活、工作都顺心如意。</p><p>一九七六年调到了县委办公室，几个月后正式安排在县委组织部监察科任科员（即现在的纪委前身），这岗位最容易得罪人，因为负责的就是管干部查处违纪领导干部，这里面水很深，因为经验不足，方法欠缺，我想纪律监察不得罪人才怪哩！</p><p>一九七八年开始对技术人员评定职称，那时人们对职称看得很重，有职称的人可以让子女享受农转非的优惠政策，我一心评定职称，执意干老本行，回到农机局，这一干就干到了退休。</p><p>性格决定了我，祖辈们的教诲也帮助我成长，我不办亏心事，不做伤天害理的事，不管到哪里都有很好的人缘，工作不马虎，虽无大功，但也无大过，没有官帽但有实权，顺顺溜溜几十年，两袖清风肚子圆，落下的毛病是自己的问题啦。退休之日，我还是个普普通通的公务员，痛耶，悲耶，喜耶？知足也！<br>这一生酸甜苦辣咸，可谓是五味都齐全了！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一九六四年八月中旬，我和妻子顺利毕业了，回宛后住在现在的新华宾馆等地方人事部门分配工作，妻子被分配到原安皋拖拉机站，我被安排到茶庵拖拉机站，过着两地分居的生活。&lt;/p&gt;
&lt;p&gt;我在茶庵期间，单位的一把手杨永江是原来的茶庵区副区长，人很能干精明。他是姑婆家（槐树湾姑爷妹妹的老公）亲戚，待我非常的好，我就和他住在一个房间，他既是领导，也是朋友、同事，我们无话不说，因此工作上我就不怕了，谁也不敢欺负我。一九六四年八月十五日到达工作岗位后，我赶上了发工资，领到了人生的第一笔工资，成了国家的正式干部。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 短文数篇</title>
    <link href="http://james20141606.github.io/2018/04/11/auto9/"/>
    <id>http://james20141606.github.io/2018/04/11/auto9/</id>
    <published>2018-04-11T02:09:45.000Z</published>
    <updated>2018-04-12T08:12:18.675Z</updated>
    
    <content type="html"><![CDATA[<h1 id="忆祖母-饮水思源"><a href="#忆祖母-饮水思源" class="headerlink" title="忆祖母 饮水思源"></a>忆祖母 饮水思源</h1><p>没有共产党就没有新中国，共产党像太阳，照得万物亮堂堂。赠给万物生命和力量。而祖母是陈氏家族的根蒂。象征家族生命的传承，没有她就没有这个家族的复兴和希望。<br><a id="more"></a><br>祖母娘家姓张，南阳县石桥镇东夹后街，家庭背景一般。她身高1 米七以上，面容慈祥可亲，虽是小脚，走起路来腰杆挺直硬朗，农耕、纺织、厨艺样样精良。她能把面条切的像粉丝一样。祖母勤劳、善良、乐施好善，她甚至还是一个土郎中、村医生、还会给人接生。她是一块经得起任何利器砥砺的玉石。经历了社会、家庭、婚姻的种种挑战，不屈不挠，引领一个支离破碎的陈氏家族拼搏向前。她坚信困难、黑暗总会过去，曙光就在前头。她是一个中国封建社会女强人的代表，带领这个家族迈向曙光。她有着普通男人都无法承受的经历。苦水、眼泪通通咬牙咽下，一生的磨难从不外扬。直到生命垂危时，祖母已无法进食，才汇集家人，字字血、声声泪地诉说那可歌可泣，悲壮的人生经历。我们劝她休息一会儿，可祖母不愿意停下，我们用棉花沾着水滋润祖母的嘴唇，泣而无声地听祖母讲述。祖母已无多少力气，声音颤抖无力。记下了，您血和泪的哭诉我们记下了，嘱托、希望我们也记下了，到今天我可以说，您当年的期望，我没有辜负，您的后代没有辜负您。</p><p>1962年9月2日（农历八月初四），祖母去世，去了天堂，临走是那样满足安详。祖母享年90岁。此时我已结婚，临终时她的孙媳妇也在身边。虽说当时条件不好，我们还是为她举行了隆重的葬礼，因为她是这个家族的基石，没有她就没有家族的希望和未来（祖母葬于皇路店魏庄祖坟处，此处是一块风水宝地，一弯河水环抱，继续保佑着陈家的未来）。</p><p>祖父去世的时候，我的大伯还是个孩子，父亲才几个月大。祖母擦干眼泪，振奋精神，带领着一群未成年人在生死线上挣扎。（大伯、父亲、四伯、大表姐、二表姐和母亲）。</p><p>堂伯幼年父母双亡，自己没有生活能力，奶奶将其抚养长大。大姑结婚后剩下两女，得病身亡。两个女儿也要交由她们的外婆抚养。我的母亲是童养媳，八岁进入陈家。</p><p>这哪里算是一个家啊，这就是一个托儿所、幼儿园。管吃管住管穿戴，所有人的吃穿住全部仰仗着祖母，还要把大家抚养成人、成家结婚。祖母好像办了一个慈善机构，只是没有捐款、没有住房、没有耕地，只有一群苦命的儿童。</p><p>祖父死后，祖母带着六个孩子四处流浪，从石人沟到濛山，雷家沟，柳树沟，再到薛庄落脚，最后到魏庄，经历了土改，终于有了房子。</p><p>祖母身材高大，体魄健康。是她给下一代遗传了魁梧的身材。她传授给父亲很多生存技能、道德规范。父亲说，奶奶传给他最宝贵的精神财富是：坚强、果断、不畏艰难，相信车到山前必有路，没有过不去的火焰山。教育父亲不能只会种地，还要学会做些生意、广交朋友，以仁者之心待人接物。多做善事，好人定会有好报。她还说，男儿有泪不轻弹，动不动就哭是弱者的表现。祖母这样一位坚强勇敢又有智慧的女性，是后代的楷模。</p><p>做好人，办好事是有分寸的；在那个混乱黑暗的年代，人善被人欺，马善被人骑，好汉子出嘴上，好马出腿上。连这个道理都不敢讲怎能称得上是男人？父亲一生都在践行祖母教诲，受益匪浅。祖母教育父亲的这一切，父亲言传身教，又教了我一些，我也体悟了一些人生经验。</p><p>祖母不是日月星辰，不是盛满油的汽油灯，她是一个在困难的年代独撑一个家的身材高大、身影伟岸的女人，她在黑暗的年代，像萤火虫一样发出微光，引领者她的儿孙们在腥风血雨中摸爬滚打着走向了光明。</p><h1 id="忆母亲"><a href="#忆母亲" class="headerlink" title="忆母亲"></a>忆母亲</h1><p>母亲忠厚、淳朴、善良，性格不急不躁，很少对儿女大发雷霆。从不举手打骂我们。她和邻里关系和睦，待人接物大方。与人与事无争，能忍能让，百善孝为先是她留给下一代的宝贵精神财富，在这一点上她是典范。</p><p>在处理邻里关系时，有时我们兄妹会和别人家孩子争抢甚至打骂，当双方家人参与时，她总会自责揽下责任，向对方赔礼，矛盾自然化解。再如，过去我们生活困难，有时连油盐、面粉都要向别人家暂借，母亲归还时总会比借来的多还一些，还面时，总是要把面瓢按瓷实了，她说，这样下次别人才会愿意借给咱。母亲的生活的智慧可见一斑。</p><p>关于孝道，母亲对奶奶比对她的亲妈还要亲，从不在别人面前说奶奶的一句坏话，在别人面前提到奶奶，都是称呼妈，不似现在很多人家的婆媳关系一样。</p><p>我和兄妹从小生活水平就很低，母亲为了不让祖母受苦，让她和大伯一同开灶，让生活好点。分灶后祖母在大魏庄住，我们在现在的地方住，每逢过年过节稍微改善生活，妈想到的第一碗饭就是祖母的，不把这第一碗饭送过去，是不准开饭的。</p><p>母亲记忆力很强，语言表达能力超过常人，她虽然不识字，但是对过去发生的事情，总能绘声绘色地演绎出来，讲话点滴不漏，就像是把当时的现场复现出来一样，我很佩服母亲这样的能力。</p><p>母亲的四不精神：不热、不冷、不饿、不累。</p><h3 id="不热"><a href="#不热" class="headerlink" title="不热"></a>不热</h3><p>夏季很热，母亲除了做家务、做饭，还要去地里帮干农活，回家后父亲和我们乘凉休息，母亲还要再干家务，做一大家人的饭。大家劝她，歇会儿再说吧，天太热了，母亲说:我不热。</p><h3 id="不冷"><a href="#不冷" class="headerlink" title="不冷"></a>不冷</h3><p>过去的冬天非常冷，没有任何取暖的设备，到了春节前，母亲彻夜不睡，做针线活到天亮还做不完。我睡在被窝里尚且浑身冰冷，醒来问母亲，这么冷怎么还一夜不睡在做针线活，母亲说：我不冷。<br>可我看到，母亲的手指和手背都冻得开裂了。</p><h3 id="不饿"><a href="#不饿" class="headerlink" title="不饿"></a>不饿</h3><p>过去的生活非常困难，很少有改善生活的时候，如果哪顿饭能有点味道、汤稠一点，孩子们就会抢着吃，我们会说，妈你也吃点吧，要不就没了，母亲就说，你们吃吧，我不饿。<br>那时候我还小，搞不懂，我们都饿坏了，母亲怎么老是不饿。</p><h3 id="不累"><a href="#不累" class="headerlink" title="不累"></a>不累</h3><p>人不是钢铁，是血肉之躯，当看到母亲满头大汗，甚至快要倒下的时候，我问母亲，妈你累不累，她说：我不累。</p><p>母亲说人的一生要多做善事，不做亏心事。做了坏事、亏了心，神仙会知道的。她说自己儿女多，受贫薄，哪有功夫念弥陀，可我心里一直在念啊。</p><p>母亲像一架永不生锈，不会损坏的钢铁机器，一直在转动。贫困、劳累、饥饿早已将她摧垮，只是她不愿说，不愿表达，钢铁之躯也有停止工作的一天。</p><p>母亲于1985年腊月初一晚上十点，坐在靠椅上洗脚时心脏停止了跳动。时年66岁。母亲含辛茹苦，把我们兄妹六人养大，还未及报恩，她还没有真正过上好日子，就这么离开了我们。连一粒救命的药都来不及吃。母亲死时没有痛苦，可我心里痛苦呀。我没有完全尽到儿子应尽的责任，自责也没有用了。望天下所有的儿女们，父母在时要抽空多陪伴，尽点孝心，多些体谅，少些抱怨。说什么现在我太忙，抽不出时间，现在还困难，等有钱了再说，可是人都没了，还能孝顺谁去。树欲静而风不止，子欲养而亲不待。这样的道理，还是早点想通了好，要不然只能空留下遗憾了！</p><h1 id="四伯家生活写照"><a href="#四伯家生活写照" class="headerlink" title="四伯家生活写照"></a>四伯家生活写照</h1><p>四伯成年后离开了奶奶，也就是他的三婶，独自回到石人沟生活，他在石人沟居住于自己的山坡边修建的“金銮殿”。这栋房子全由四伯一人独立建造，石头、土坯做墙体，木棍、竹子做房梁，竹子做椽子。房子深约三米半、长约六米。</p><p>房内家当摆设：靠西山墙放置土坯床一个，靠东山墙土锅台一个，小铁锅一个，铲锅刀一把，木勺子一个，竹刷子一把，没有盛水缸，只有一个小瓦罐（吃水方便，随用随提，所以也不用水缸）。没有案板，只有木锨板大小的一块板做案板。</p><p>他用竹子编了一个大竹篓，用来盛红薯干、花生之类专用。用泥制缸来盛放大米，洗脸盆是一个的烂一半的瓦盆。那时候没有电，屋内也没有油灯，实在需要照明时，用灰麻杆或者竹子点燃后照明。这房子除了门没有窗户，只在前墙体留个洞。冬季用稻草堵死不让进风。这座房子周围环境优美，生态环境好，门前的小溪清澈见底，四季都不干涸，水源于山上的雨水与山泉，常年流水不断，水清冽甘甜，十分解渴。山泉处挖了大坑，那里是我夏季玩水嬉戏洗澡的好地方。</p><p>现在的水库是当年大竹园的位置，竹园周围，房前屋后植被茂盛，春天时百花争艳、开的分外灿烂明艳，林间、尤其是竹园，百鸟争鸣，从早吵到晚。房后的葛花树、梨树、桃树、杏树和不知名的野草野花交相辉映，这样的原生态花园现在可是难觅了。</p><h1 id="八岁孩子学走路"><a href="#八岁孩子学走路" class="headerlink" title="八岁孩子学走路"></a>八岁孩子学走路</h1><p>1948年八周岁时，我得了天花。当时医疗条件极差，而且天花患者年龄越大越不易治愈，我接连发高烧，连路都不会走了。我是大伯的过继儿，他看在眼里，急在心里。他说：万万不敢出什么事，要不将来百年后我那杆大旗谁抗啊。后来他常用自己系腰的长腰带兜着我两个胳膊，教我重学走路。当时家里人多，生活水平很差，大伯分灶吃饭，他有严重胃病，每逢做了好吃的饭，他都偷偷暗示我到他那儿吃点，慢慢的我的身体逐步恢复。大伯晚年时胃病很重，我参加工作后，虽然工资很低，每次回家都要给他留几块钱，谢救命之恩。他过世时我在茶庵区拖拉机站工作。路程远，交通不便，没能通知我及时返回送他最后一程。那杆大旗是我的长子陈华军扛的，那时华军年幼，是被人抱着扛起来的。他扛和我扛是一样的。几十年了。<br>逢年过节，我都不忘给他送好多纸钱（大伯的坟在魏庄，和父母的坟在一处），他不会缺钱花的，这恩情我要永远记得呀。</p><h1 id="我的第一双棉鞋"><a href="#我的第一双棉鞋" class="headerlink" title="我的第一双棉鞋"></a>我的第一双棉鞋</h1><p>在我印象中，上初中前的冬季我从未穿过棉鞋，因为脚被冻坏了，成年后冬天不穿棉鞋脚就会生冻疮。母亲跟着哄老三的时候，有一年冬天脚又冻着了，走路一瘸一拐。母亲问我：怎么走路一瘸一拐的，我不小心脱口而出：都怪你小时候不给我做棉鞋，脚留下冻疮的根。我还补充道：从记事起，冬天没穿过棉鞋。母亲回答我说：是你不记得了，你小时候还穿连脚裤呢，这不是棉的吗。这话说的我啼笑皆非，想起来真是好笑。<br>因为家穷兄妹多，印象中冬季不穿棉鞋像是事实。1955年我的干姐（苏大妮，家住白河东长嘴村）在春节前给我做了双偏开口气眼棉鞋，捎信给我，让我年根去拿。为了这双鞋我起早赶路去她家里。可返回时道路开冻了，泥泞不堪。我不舍得穿，手拿棉鞋，光脚往回走。这鞋在我心中是宝贝，要留到大年初一穿，能舍得叫沾上泥吗？</p><h1 id="大伯和父亲给祖母惹祸"><a href="#大伯和父亲给祖母惹祸" class="headerlink" title="大伯和父亲给祖母惹祸"></a>大伯和父亲给祖母惹祸</h1><p>大伯成年后只会干农活，少言寡语，性格内向，不善交流，说话简单粗暴，不好听。有一次他挑完茅粪后，粪桶在堰潭里清洗，一群妇女在堰潭里洗衣服，骂他是猪狗不如之人。他破口还人家，言语粗俗，引一群妇女和家里男人与他厮打。大伯用挑粪扁担将人打伤，我的父亲见状，非但不劝架，反而参加打斗。打斗的对手是丁老庄的一户有钱人家，状告官府要陈家道歉、赔偿药费，甚至扬言要抓人坐牢。祖母只得四处找人说情，道歉，还要四处借钱，变卖衣物，摆了十几桌宴席，才算平息了此事。我未吸取长辈教训，有时因头脑发热，办事简单粗暴，也办过一些错事。父亲年轻时个子高大，长相不差，十几岁时去小石桥做生意，返家时路遇土匪，以为父亲家里有钱，将他绑架。父亲被麻绳困住双手，膏药贴住双眼，口被毛巾堵上，投进了红薯窖里。土匪向家里要钱，却没有料到此人是穷光蛋，后经人周旋，祖母又摆了几桌酒席，才将父亲放回家，祖母难啊！</p><h1 id="真实故事三则-2016年八月二十五"><a href="#真实故事三则-2016年八月二十五" class="headerlink" title="真实故事三则 2016年八月二十五"></a>真实故事三则 2016年八月二十五</h1><h2 id="一-龙闸水"><a href="#一-龙闸水" class="headerlink" title="一 龙闸水"></a>一 龙闸水</h2><p>小时候的一年夏天，上游山区下暴雨，小岔河发了大水（就在父母坟地西北方靠河边的高粱地），水在那里打旋，不往下走。当水势退去，那里青蛙、癞蛤蟆、大小蛇类、鱼虾横尸遍野。我亲眼目睹，觉得现象怪异。那是块龙地啊，龙闸水啊，人亦是属龙的吗？</p><h2 id="二-怪病吃钱喉"><a href="#二-怪病吃钱喉" class="headerlink" title="二 怪病吃钱喉"></a>二 怪病吃钱喉</h2><p>在皇路店上小学期间，每天太阳升起时总要肚子疼上一阵，有一天，当一轮红日冉冉升起时，我正站着看火球慢慢升起，就是在现在的老家住宅处，突然感到肚子巨疼无比，豆大的汗珠直流。父亲叫家人赶紧生办法找生大烟膏喝，要不会疼死人，郭保国的父亲郭老三准备去犁地，路过家门口。他手持挂了一大串铜钱的长杆旱烟袋，边吸边走，见此情景，他让找点黄豆嚼嚼看看什么样，结果没有任何效果。接着他从烟袋上取下一枚铜钱放我嘴里让我用牙咬。这铜钱用牙咬着竟然像是被软化了一样，马上被咬成了小碎渣，他让我和着一口水咽下，顷刻肚子不疼了。他说这病叫吃钱喉，得不到及时治疗会丧命的。这病人畜都会患，吃钱喉现代医学如何解释呢？</p><h2 id="三-一庹长大蛇戏水"><a href="#三-一庹长大蛇戏水" class="headerlink" title="三 一庹长大蛇戏水"></a>三 一庹长大蛇戏水</h2><p>1950年我已在尹店小学上学，校址在三皇姑庙院内，我小时候胆小怕事，弟弟陈炳义胆大顽皮，他小我四岁，但夜里要办事时我总会约他一起办。一年夏天的晚上母亲突然患病，头疼欲裂，呕吐不止，需要去贾庄请医生。那时从魏庄到贾庄没有正路（至今也没有一条正路），得从地埂荒路走。常听村里人说，去贾庄过河渡口处看见过一条大蛇，长约一米五，平时藏在大石堆中（石头是国民党时期想修鸭河水库所以从蒲山运来的），因经常听人提起，本来对此处就心生忌惮，夜里伸手不见五指，河里正是水势充沛，可别让我真的遇上大蛇了。过河时我让炳义走前面，我紧跟其后，刚一下水，果真惊动了那条大蛇，吓得我一头栽到了河里。当时没有桥、没有任何照明的设施，我们拿着灰麻杆照路，究竟有多长并没有看清。到了第二年发洪水，那条蛇被冲到尹店榆树林杂草堆中，发现时已经死了，才知道大约有一庹（两臂左右平伸，掌心向前，两手指尖之间的距离，通常叫做一庹）那么长。</p><h1 id="我的朋友周聚照"><a href="#我的朋友周聚照" class="headerlink" title="我的朋友周聚照"></a>我的朋友周聚照</h1><h4 id="2016-5"><a href="#2016-5" class="headerlink" title="2016.5"></a>2016.5</h4><p>我和妻子于1962年农历七月成婚，那是物资奇缺，正值困难时期。结婚时为购置食品，父亲没少犯愁。不仅肉类奇缺，鸡子鱼鸭更难买，就连最普通的莲菜都买不到。后来找到南召县农场的杨厂长，给了些莲藕代用。当时的农场就在村旁边。那时年轻人结婚能办几桌全席极少，城镇里工人干部也很少能做到。父亲能为我们办那么丰盛的婚宴全席，让我终身难忘。</p><p>那时穿衣凭布票，每人每年才几尺布票。结婚时我们俩把上学时各自的被褥，拆洗后合在一起，算是新婚床铺，为了新婚当天能在床上铺上新床单以示吉庆，我们的太平洋床单还是借用郭保玉的，举行完婚礼即刻归还，当时连床单都没有，真是难为妻子了，至今仍然觉得心怀歉疚。可妻子无怨无悔，当时也都不讲排场。结婚头一年，总得给岳父家送点薄礼，这是农村老习惯。那是买不到猪肉，我在犯愁送什么礼。正为难时，父亲在新野县王庄的朋友王叔造访，说养了一头小猪，春节给免费送些猪肉。因为心急，我于当年腊月二十三就前去取肉。家里距离新野约六十公里，我还没有骑单车这么远过。骑到南阳时我已筋疲力尽，屁股像涂了辣椒水一样，再也不想坐自行车的破座椅了。中午我啃了些干粮，还得继续南下，骑骑推推，到沙堰时天色已晚，还不知王庄离此地还有多远，便到处打听。</p><p>当打听到沙堰区政府门口时，见到一个年轻人站在那里。他仔细打量着我胸前戴的郑州农机化专科学校校徽，当时正是放长假时期，我是有意戴上的，他看我的模样就热情攀谈起来，我后来得知他是区里通信员，他说自己叫周聚照。我们坐在接待室里，他看我非常疲惫，像是没吃晚饭，就到厨房让炊事员弄来一大碗水饺和两个火烧吃。他的热情深深打动了我，我表示了谢意后要离开，他却执意不让走，说我俩都是男人，不必嫌弃，就一起睡在大床上，大冬天就不要在晚上赶路了，这里离王庄还是十几里呢。我太累了，也因为他的热情就住下了。我们不似初见，倒像是久别重逢的老友一样，海阔天空地聊着，我竟忘了一天的劳累，忘怀地聊着笑着。第二天我醒来时，他为我准备了一瓶热水供洗漱，还端来了饭菜。饭后他甚至请假陪我去王庄，还要让我骑他的新自行车，他骑着我的旧车去。到了王庄，王叔热情接待了我们，当二人分别时，他非要给我全国粮票十斤，并给我布票几尺，做送别朋友之礼，留作纪念。我推辞不过，万分感激地收下了。返回时路况熟了，又因为在百里之外交了一位热情大方、诚恳可爱、彬彬有礼的朋友，心情大好，骑车也不觉得累了。</p><p>我们两个多次书信联系，他还专程来魏庄看望我。后来因为各自工作变化、地址变化失去联系。</p><p>好人一生平安，我的朋友周聚照会幸福的，祝你晚年生活愉快，儿孙满堂，笑口常开。福如东海长流水，寿比南山不老松。</p><p>老友陈炳林追忆。</p><h5 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h5><p>在大家的努力下，爷爷奶奶在2017年春天得以寻回当年老友一家的联系方式，并去探望，周爷爷已经不在人世，其后人生活幸福美满，子孙受到很好的教育，所谓好人必有好报。</p><h1 id="人生机遇只有一次"><a href="#人生机遇只有一次" class="headerlink" title="人生机遇只有一次"></a>人生机遇只有一次</h1><p>一九七九年我在县委组织部监察科工作，三十九岁，符合军分区提拔武装部领导的条件。在自己不知情的情况下，军分区给南阳县武装部发来命令，调我去石桥人武部当部长，兼任副书记。我当时非常高兴，可我的妻子却高兴不起来，坚决反对我去石桥任职。她以一人无法照料四个孩子为由百般阻止。那可不是组织部普通的人事调动，而是一张盖有由军事部门大印的命令，压在县武装部军事科长余科长办公桌玻璃板下的命令。一个党员是该无条件服从的，怎么办？县人武部长告诉我，一个党员干部，在这个命令下达后，没有特殊理由是不能不去的，除非身体方面的原因，我找到了关系要好的文副部长，他给我出了个妙主意：我患有胃下垂，严重溃疡，你拿我的片子，换成你的名字，让医生开诊断证明，兴许管用。我果真照办，骗过了分区领导。一般人对于个人升迁、提拔都持积极态度，甚至有人送礼说情，削尖脑袋往上爬，我却死活不领情不赴任，少见稀奇。那时才三十九岁。直到我光荣退休，依然是大科员一名，真是个大笨蛋。不过这几十年妻子从没埋怨过我无能，唉，都快八十岁的人了，想这些干什么，都过去了，无官一身轻，钱多是非多，过好余生吧。<br>注：石桥人武部已配好了办公室、办公桌等，配好了火炉水瓶，连年终救济三十元都评定好了，因为主要理由是负担大而不上任，对得起组织吗？</p><h1 id="过个革命化的春节"><a href="#过个革命化的春节" class="headerlink" title="过个革命化的春节"></a>过个革命化的春节</h1><p>一九六五年拖拉机总站提出过革命化的春节，春节不放假，奋战生产一线的口号。大年初一那天我的车组（链式东方红五四车）被调到高庙乡王连庄村耕地。成员有：杨志堂、杜保清、侯西荣等五人，那天天非常的冷，天寒地冻，大雪纷飞。我们提出过革命化的春节，要有革命化的表现，不扰民，拉人做些食物吃就行了。他们找到了一个双目失明，独自一人靠算卦活命的老头家的一间草房，白馍、熟肉、粉条都有，队里说这个瞎眼的老头干净、会做饭，可是中午到他家吃饭时，发现这些食物全都烧糊黏住了，一股乌鸦的臭味。大家都拒绝吃这顿大年初一的年饭，发牢骚。快到中午时总站机务科副科长郭孔印冒着雪骑着破自行车走了三十多公里到我们车组慰问，他也够辛苦了，而我们只能把气撒在他身上，村民围了一大片看热闹。<br>后来村民编了一个顺口溜：拖拉机板真吊旦，大肉白馍叫随便赞，初一中午搞绝食，提抗议要发难，说是穿着蟒袍衣，走上大街叫看看。<br><em>这般形象：一身灰满脸油，不是拖拉机手是老球，远看是要饭，近看像卖炭的，走到跟前一看是拖拉机站的。</em>有油没菜拖拉机光坏（出故障，犁不成地），有菜没酒拖拉机不会走，有酒有菜，地犁得又好又快。<br>*吃花卷馍，犁花卷地：代耕唐河县桐河村，拖拉机进了村，来了荷枪实弹护卫军，犁地时持枪站在地头护卫，怕敌人破坏车辆。当晚请南阳曲剧团演戏（野火春风斗战城），戏台观看席摆桌凳茶水茶具，专供拖拉机手用，这也够风光了。吃饭二人一席（因两人一班车不停，换班吃饭），每人一条红烧或者糖醋大鲤鱼。<br>睡觉：换下夜班后露宿野地（野餐大多送到了地头，吃后便睡），天作被，地作床，处处都是席梦思，上边盖得太平洋，呼噜呼噜入梦乡。<br>卫生条件：在本站辖区耕地，任务重，为不误时间，村民都将饭菜送到地头，不可能一年四季处处有水，吃饭时不洗手、不洗脸，抓把黄土做洋碱，两手一搓就开饭。吐口吐沫在手指上，手指身上蹭就算干净了，就可以吃饭了，省时间就地取材，又天然。<br>机耕结束，某次全县人员集中总部开表彰大会，大学生牛某某，工作衣服的缝开了，用铁丝串着，就这还露屁股露大腿（这人本来就邋遢），后来县里决定发劳动布，专门用来补工作服。</p><h1 id="石人传说二则"><a href="#石人传说二则" class="headerlink" title="石人传说二则"></a>石人传说二则</h1><h2 id="一"><a href="#一" class="headerlink" title="一"></a>一</h2><p>一个晚上，石老婆正在石人山碾米，有一个路人从石碾边上的山路经过问路。石婆指完路，又问路人：你看这米碾到这样中不中啊？那人抓起一大把米细看，说道：中啦，然后转身上路。第二天那路人洗手时，发现指甲缝里有东西，一看是金米，他后悔极了，早知道是金米，何不抓上一大把？</p><h2 id="二"><a href="#二" class="headerlink" title="二"></a>二</h2><p>过去农家干农活，收工晚，吃完晚饭就睡了，只有小油灯作为照明设备，夏夜里吃晚饭都坐外边，这样凉快些。那时陈家人口很多，盛饭时你来我往，好不热闹。有好几次家人隐隐觉得有一身材高大之人也来往盛饭，但天黑看不清楚，也没人在意，有一次祖爷在暗处吃晚饭，此人又趁着空隙盛饭，祖爷猛扑过去，把饭勺扣到他的头上，于是那人慌忙跑了。第二天祖爷上石人山砍柴时，发现石人头上有大米饭，这才醒悟过来，原来头天晚上盛饭的人是石人呀。</p><p>注：此为祖母所讲的故事。1951年我重返石人山，亲眼见到地质人用绿帆布将石人周围拉起来，进行勘探、研究，现在石人肚脐处的那个洞就是搞地质的人挖的，至于发现了什么就不得而知了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;忆祖母-饮水思源&quot;&gt;&lt;a href=&quot;#忆祖母-饮水思源&quot; class=&quot;headerlink&quot; title=&quot;忆祖母 饮水思源&quot;&gt;&lt;/a&gt;忆祖母 饮水思源&lt;/h1&gt;&lt;p&gt;没有共产党就没有新中国，共产党像太阳，照得万物亮堂堂。赠给万物生命和力量。而祖母是陈氏家族的根蒂。象征家族生命的传承，没有她就没有这个家族的复兴和希望。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 童年的诗</title>
    <link href="http://james20141606.github.io/2018/04/11/auto10/"/>
    <id>http://james20141606.github.io/2018/04/11/auto10/</id>
    <published>2018-04-11T02:09:42.000Z</published>
    <updated>2018-04-12T08:12:26.086Z</updated>
    
    <content type="html"><![CDATA[<center><font color="#DC143C" size="5"> 玩秋千 石人山情节 </font> </center><p align="right">2016.9.11</p><center>茅草小屋金銮殿，桃杏梨花来装点。</center><center>春日争相露笑脸，葛花树上玩秋千。</center><center>若有同龄孩童伴，情景定会不一般。</center><center>良辰美景一人享，亦开心来亦孤单。</center><a id="more"></a><center><font color="#DC143C" size="5"> 石人山景 </font> </center><center>石人山景美若画，儿时记忆难忘下。</center><center>高山顶峰衬其峻，云雾缭绕摹其神。</center><center>谷满林竹花锦绣，潺潺流水汇清泉。</center><br><br><center><font color="#DC143C" size="5"> 恋家 </font> </center><center>少时寄住石人山，犹似修隐仙景间。</center><center>天亮登山陪桑蚕，入夜土炕头边玩。</center><center>山风怒吼夜狼嚎，柴房家犬牙齿露。</center><center>一日三餐尚果腹，思乡遥望东方愁。</center><br><br><center><font color="#DC143C" size="5"> 四伯 追思堂伯父 </font> </center><center>幼时父母皆亡殁，凄凉处境人怜惜。</center><center>尝尽人间冷与暖，变得木讷而寡言。</center><center>不养鸡鸭不养猪，不种蔬菜只种谷。</center><center>厨中并无盐油醋，舌尖哪有美味留。</center><br><br><center><font color="#DC143C" size="5"> 无题 </font> </center><center>民国三十年，恰逢吾降生。</center><center>上天不下雨，庄家未收成。</center><center>家园遭天灾，倭寇来侵略。</center><center>人在襁褓中，母亲患大病。</center><center>断了生命水，差点送性命。</center>- 注：生命之水指母亲奶水。<center><font color="#DC143C" size="5"> 思往昔看今朝 </font> </center><p align="right">2015.3</p><center>忆往昔峥嵘岁月稠，</center><center>想痛处，满脸沟壑老泪流。</center><center>看今朝国盛家富，</center><center>家和睦儿孙老人事事顺溜。</center><br><br><center><font color="#DC143C" size="5"> 忆石人涧茅草小屋“金銮殿” </font> </center><p align="right">2016.9.9</p><center>石人身高八丈三，一半身在云雾间。</center><center>石婆闲来无去处，身贴悬崖避风寒。</center><center>谷底花树高又俊，秀拔挺立直冲天。</center><center>房后园中绿竹林，粗若碗口真稀罕。</center><center>门前小河水不断，源自上游山泉涧。</center><center>春风吹佛小山村，桃杏梨花齐斗艳。</center><center>吾辈此时何处去，葛藤树上荡秋千。</center><br><br><center><font color="#DC143C" size="5"> 咏春 石人山旧居 </font> </center><center>茅草小屋金銮殿，桃杏梨花来装点。</center><center>三亩翠竹作盆景，门前溪水流不断。</center><center>欲问清水何处来，遥指山谷泉水涧。</center><center>春色美景独享有，葛花树上荡秋千。</center><br><br><center><font color="#DC143C" size="5"> 大竹园变堰潭 </font> </center><center>旧时竹园改了观，现已变成大堰潭。</center><center>鱼儿为觅漂浮时，头儿伸出乱眨眼。</center><center>若想尝下新鲜味，一网下去捞两篮。</center><ul><li>注：原来的大竹园在58年时，竹子被砍伐，修成了大堰潭，原生态的景观也被破坏殆尽</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;font color=&quot;#DC143C&quot; size=&quot;5&quot;&gt; 玩秋千 石人山情节 &lt;/font&gt; &lt;/center&gt;
&lt;p align=&quot;right&quot;&gt;2016.9.11&lt;/p&gt;

&lt;center&gt;茅草小屋金銮殿，桃杏梨花来装点。&lt;/center&gt;
&lt;center&gt;春日争相露笑脸，葛花树上玩秋千。&lt;/center&gt;
&lt;center&gt;若有同龄孩童伴，情景定会不一般。&lt;/center&gt;
&lt;center&gt;良辰美景一人享，亦开心来亦孤单。&lt;/center&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
</feed>
