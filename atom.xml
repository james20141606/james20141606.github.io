<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>James Chen&#39;s Blogs</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://james20141606.github.io/"/>
  <updated>2018-04-21T02:54:34.254Z</updated>
  <id>http://james20141606.github.io/</id>
  
  <author>
    <name>James Chen</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Solution of MCM Problem C</title>
    <link href="http://james20141606.github.io/2018/04/21/mcm/"/>
    <id>http://james20141606.github.io/2018/04/21/mcm/</id>
    <published>2018-04-21T01:15:19.000Z</published>
    <updated>2018-04-21T02:54:34.254Z</updated>
    
    <content type="html"><![CDATA[<hr><p>It is about our solution of 2018 MCM contest, our result get Meritorious award.<br><div class="row"><iframe src="https://drive.google.com/file/d/1dsWsVDi-VES_-OSU2MX2PceZ4GOeYXlv/preview" style="width:100%; height:550px"></iframe></div><br><a id="more"></a><br>I have put the codes and others in <a href="https://github.com/james20141606/MCM2018problemC" target="_blank" rel="noopener">GitHub</a><br>Here is the final paper of our solution:<br><div class="row"><iframe src="https://drive.google.com/file/d/1qpGsc65yvT8BGrGisMkxNSOspTGXFo6G/preview" style="width:100%; height:550px"></iframe></div></p><h2 id="Abstract-of-Paper"><a href="#Abstract-of-Paper" class="headerlink" title="Abstract of Paper"></a>Abstract of Paper</h2><p>In this paper, we construct two evaluation systems: Renewable Energy Indicator (REI) and Network Instability Indicator (NII). By using data mining methods and developing two models, we succeed in visualizing, characterizing, evaluating and predicting the energy flow network and the use of renewable energy.\par</p><p>First, we process the data. We do data screening to select two groups of variables to characterize the energy profile. As some data is missing, we do imputation based on existing data and data from other reliable sources. The data constructing key indicators are normalized with all fifty states. To illustrate energy profile, we also do data visualization with vivid diagrams like Sankey diagram and radar diagram.\par</p><p>Second, we construct two evaluation systems REI and NII to trace and compare the energy profiles of four states and their evolution. NII is derived from a Constrained-Ridge model to characterize the structural stability of energy flow. To specify on renewable energy, we define REI with five key indicators. We use combined Analytic Hierarchy Process(AHP) and Entropy Weight Method(EWM) to construct REI, which characterizes the profile for use of cleaner, renewable energy. We then compare REI and NII of four states and Arizona performs best.\par</p><p>Third, we use several time series models to predict the energy profile of each state in the future. Structural profile of energy flow NII is predicted with Constrained-Ridge model, and renewable energy profile REI is predicted with Autoregressive Integrated Moving Average Model(ARIMA) and Long Short Term Memory(LSTM). Based on the comparison and prediction, we determine the renewable energy usage target for four states and propose several feasible actions.\par</p><p>Finally, we conduct sensitivity analysis of our model. We try several machine learning models to predict 5 key indicators, and use independent validation datasets to evaluate their performances. We also do a perturb-and-profile test to evaluate Constrained-Ridge model’s power to characterize network profile.</p><p>Our model is reasonable and legible with theoretical and data support. The model can be easily applied to characterize the energy profile of renewable energy and energy flow network after data training.</p><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p>Used data in data file, produced data in produced data</p><h2 id="Codes-and-method"><a href="#Codes-and-method" class="headerlink" title="Codes and method"></a>Codes and method</h2><p>For quick work in limited time, all codes are written in jupyter notebook, which is a good interactive environment easier to plot and analyze data.<br>We have implemented some algorithm and some visualization method to analyze data.  We use AHP and EWM to construct REI, use ARIMA, Machine Learning model and Deep Learning model to predict time series data. We construct a Restricted Ridge model, using optimization method to depict the network relationship. We use sankey plot, radar plot, and many ordinary plots to visualize data vividly.</p><h2 id="Key-point-manually-feature-selection"><a href="#Key-point-manually-feature-selection" class="headerlink" title="Key point: manually feature selection"></a>Key point: manually feature selection</h2><p>We use a network to extract key features to depict the energy profile. The network is visualized through sankey plot.</p>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;p&gt;It is about our solution of 2018 MCM contest, our result get Meritorious award.&lt;br&gt;

	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/1dsWsVDi-VES_-OSU2MX2PceZ4GOeYXlv/preview&quot; style=&quot;width:100%; height:550px&quot;&gt;&lt;/iframe&gt;
	&lt;/div&gt;


&lt;br&gt;
    
    </summary>
    
      <category term="projects" scheme="http://james20141606.github.io/categories/projects/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="contest" scheme="http://james20141606.github.io/tags/contest/"/>
    
      <category term="math model" scheme="http://james20141606.github.io/tags/math-model/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression Assignment 8</title>
    <link href="http://james20141606.github.io/2018/04/20/line3/"/>
    <id>http://james20141606.github.io/2018/04/20/line3/</id>
    <published>2018-04-20T02:01:19.000Z</published>
    <updated>2018-04-20T02:53:27.442Z</updated>
    
    <content type="html"><![CDATA[<p>The seventh assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.<br><a id="more"></a><br>You may also find the <a href="https://github.com/james20141606/somethingmore/tree/master/linear_regression_pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this assignment. Which is more recommended. <strong>Or here</strong>:<br><div class="row"><iframe src="https://drive.google.com/file/d/1JQjkq4iBhUmCgrJ9ijq9lxTrsroQKeZC/preview" style="width:100%; height:550px"></iframe></div></p><h1 id="1"><a href="#1" class="headerlink" title="1"></a>1</h1><h2 id="a"><a href="#a" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># read the data</span><br><span class="line">setwd(&apos;~/Desktop/三春/5线性回归分析/作业/HW8/&apos;)</span><br><span class="line">dat&lt;-read.csv(&quot;hw8.csv&quot;)</span><br><span class="line">X1&lt;-dat$x1</span><br><span class="line">X2&lt;-dat$x2</span><br><span class="line">X3&lt;-dat$x3</span><br><span class="line">X4&lt;-dat$x4</span><br><span class="line">Y&lt;-dat$y</span><br><span class="line"># plot stem and leaf plots</span><br><span class="line">stem(X1)</span><br><span class="line">stem(X2)</span><br><span class="line">stem(X3)</span><br><span class="line">stem(X4)</span><br></pre></td></tr></table></figure><p>It seems that X3 has a denser concentration and the following boxplot supports it. X1 has two outliers. X2 is asymmetric</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">library(vioplot)</span><br><span class="line">vioplot(X1,X2,X3,X4,col=&quot;gold&quot;)</span><br><span class="line">boxplot(X1,X2,X3,X4)</span><br></pre></td></tr></table></figure><h2 id="b"><a href="#b" class="headerlink" title="b"></a>b</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pairs(~X1+X2+X3+X4+Y,data=dat, </span><br><span class="line">   main=&quot;Scatterplot Matrix&quot;)</span><br><span class="line">cor(dat)</span><br></pre></td></tr></table></figure><p>obviously X3 and X4 has high correlation.</p><h2 id="c"><a href="#c" class="headerlink" title="c"></a>c</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Fit = lm(Y~X1+X2+X3+X4, data=dat)</span><br><span class="line">anova(Fit)</span><br><span class="line">summary(Fit)</span><br></pre></td></tr></table></figure><p>$\hat Y = -124.38 + 0.30 x_1 + 0.05 x_2 + 1.31 x_3 + 0.52 x_4$<br>It seems X2 should be excluded from the model since the p-value=0.4038.</p><h1 id="2"><a href="#2" class="headerlink" title="2"></a>2</h1><h2 id="a-1"><a href="#a-1" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">library(leaps)</span><br><span class="line">best &lt;- function(model, ...) </span><br><span class="line">&#123;</span><br><span class="line">  subsets &lt;- regsubsets(formula(model), model.frame(model), ...)</span><br><span class="line">  subsets &lt;- with(summary(subsets),</span><br><span class="line">                  cbind(p = as.numeric(rownames(which)), which, adjr2))</span><br><span class="line"></span><br><span class="line">  return(subsets)</span><br><span class="line">&#125;  </span><br><span class="line">round(best(Fit, nbest = 6), 4)</span><br></pre></td></tr></table></figure><p>The four best subset regression models are</p><div class="table-container"><table><thead><tr><th>subset</th><th>$R^2_{a,p}$</th></tr></thead><tbody><tr><td>x1, x3, x4</td><td>0.956</td></tr><tr><td>x1,x2,x3,x4</td><td>0.955</td></tr><tr><td>x1,x3</td><td>0.927</td></tr><tr><td>x1,x2,x3</td><td>0.925</td></tr></tbody></table></div><h2 id="b-1"><a href="#b-1" class="headerlink" title="b"></a>b</h2><p>There are $C_p$ Criterion, #AIC_p# and #SBC_p# which can be used as criterion to select the best model. They all place penalties for adding predictors.</p><h1 id="3"><a href="#3" class="headerlink" title="3"></a>3</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">library(MASS)</span><br><span class="line">Null = lm(Y ~ 1, dat)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">addterm(Null, scope = Fit, test=&quot;F&quot;)</span><br><span class="line">NewMod = update( Null, .~. + X3)</span><br><span class="line">addterm( NewMod, scope = Fit, test=&quot;F&quot; )</span><br><span class="line">NewMod = update( NewMod, .~. + X1)</span><br><span class="line">dropterm(NewMod , test = &quot;F&quot;)</span><br><span class="line">addterm( NewMod, scope = Fit, test=&quot;F&quot; )</span><br><span class="line">NewMod = update( NewMod, .~. + X4)</span><br><span class="line">dropterm( NewMod, test = &quot;F&quot; )</span><br><span class="line">addterm( NewMod, scope = Fit, test=&quot;F&quot; )</span><br></pre></td></tr></table></figure><ul><li>As shown, start with no predictors, X3 is chosen because of smallest p-value.</li><li>Then regressing y on x3 and additional one predictor, the result shows that X1 has the smallest p-value (1.578e-06&lt; 0.05). Therefore X1 can be included in the model. In the same time a test is given to see if x3 should be dtropped. Since p-value (6.313e-13&lt;0.10), X3 is retained.</li><li>Then regressing y on X3, X1 and any one of the rest two, it shows that X4 has the smallest p-value (0.0007354 &lt; 0.05) and hence being included in the model.In the same time a test is given to see if x3 or x1 should be dtropped. Since both of their p-value &lt; 0.10, they are both retained.</li><li>Finally, regressing y on all four predictors and x2 isn’t significant to be included (0.4038 &gt; 0.05). Thus it is deleted from the model.</li><li>The best subset of predictor variables to predict job proficiency is (x1,x3,x4)</li></ul><h2 id="b-2"><a href="#b-2" class="headerlink" title="b"></a>b</h2><p>The model evaluated using the forward stepwise regression shows the same result as earlier chosen variables under the criteria of adjusted R square.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The seventh assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;br&gt;
    
    </summary>
    
      <category term="school work" scheme="http://james20141606.github.io/categories/school-work/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="R" scheme="http://james20141606.github.io/tags/R/"/>
    
      <category term="assignment" scheme="http://james20141606.github.io/tags/assignment/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="linear regression" scheme="http://james20141606.github.io/tags/linear-regression/"/>
    
  </entry>
  
  <entry>
    <title>Reading Notes of Wittgenstein&#39;s Bio</title>
    <link href="http://james20141606.github.io/2018/04/17/Reading-Notes-of-Wittgenstein-s-Bio/"/>
    <id>http://james20141606.github.io/2018/04/17/Reading-Notes-of-Wittgenstein-s-Bio/</id>
    <published>2018-04-17T14:37:17.000Z</published>
    <updated>2018-04-20T02:56:36.088Z</updated>
    
    <content type="html"><![CDATA[<p>Some notes and thoughts concerning <strong>Ludwig Wittgenstein: The Duty of Genius</strong> by Monk, Ray. To be honest, I first found Wittgenstein very mysterious and great (part of the reason is his wonderful german name). But now I feel little disappointed. I see more a crazy and strange man rather than a genius. He may be a genius, but if it is because his madness and defect (I know it is wrong to say like this, but I can always have such feelings that some man is “great” just because he is strange or even mad), I don’t think it is a great thing. Also I am always confused about philosopher, they always think themselves have the right to judge everything, it is really ridiculous. So I really hate many of his thoughts concerning language, science and maths.<br><a id="more"></a><br><div class="row"><iframe src="https://drive.google.com/file/d/1T24zGxWcLN4W33lQm1CbFhy_yFUMzih0/preview" style="width:100%; height:550px"></iframe></div></p><h1 id="RELUCTANT-PROFESSOR"><a href="#RELUCTANT-PROFESSOR" class="headerlink" title="RELUCTANT PROFESSOR"></a>RELUCTANT PROFESSOR</h1><p>My part is CHAP 20, the reluctant professor. This chapter contains many things, including WITTGENSTEIN work and life after his return to Cambridge. He gives some lectures and courses about aesthetics, science, religion, mathematics. He also struggles with his love with Francis and experience many guilt after Francis death. It helps to better understand WITTGENSTEIN.</p><h2 id="Return-to-Cambridge"><a href="#Return-to-Cambridge" class="headerlink" title="Return to Cambridge"></a>Return to Cambridge</h2><p>Anschluss( [‘ɑ:nʃ lu:s) is one of the reason WITTGENSTEIN return to Cambridge ([vitɡən’ʃtain]). His attempts to find a niche in life outside academia has been at best inconclusive. His savings, of £300 or £400, would not have lasted a lifetime. Eventually, he would have had to have found some paid employment.<br>That is, as he had put it to Moore in 1930, <strong>he would have had to have found someone who had a use for the sort of goods he produced. And the place where these goods were in most demand was, inevitably, in academic life, and particularly in Cambridge</strong>.<br>So at some time or other he would have applied for a lectureship.  However, is that if it had not been for the Anschluss, this would not have been as early as April 1938.<br>This is not only because Wittgenstein was then <strong>not eager to return to teaching</strong>, but also because he was worried about his <strong>relationship with Francis</strong>. </p><ul><li>[x] he was deeply concerned about the sensuality that existed between himself and Francis, and anxious whether, on his part at least, such sensual desires <strong>were compatible with true love.</strong> </li></ul><h2 id="Live-as-Couple"><a href="#Live-as-Couple" class="headerlink" title="Live as Couple"></a>Live as Couple</h2><p>Upon his return he moved into Francis’s lodgings and for over a year they lived <strong>as a couple.</strong> But by 1939 it had deteriorated, and that for the following two years it was only Francis’s undyingly <strong>faithful</strong>, perhaps even <strong>clinging, love</strong> for Wittgenstein that kept it going.<br>Wittgenstein’s love for Francis didn’t survive the physical closeness that he at once <strong>craved and feared</strong>. </p><h2 id="New-Disciples"><a href="#New-Disciples" class="headerlink" title="New Disciples"></a>New Disciples</h2><p>Wittgenstein found a <strong>new generation of disciples</strong>.<br>In order to keep his class down to a size with which he felt comfortable, he <strong>did not announce his lectures in the usual way</strong> in the Cambridge University Recorder. Some students were asked if they would be interested about the classes. No more than about ten students attended</p><p>Unfortunately, one of the fact is that those whom Wittgenstein <strong>influenced most strongly</strong>, particularly in the <strong>1930s</strong> did not enter <strong>academic life</strong>. So a large and important aspect of Wittgenstein’s influence is not reflected in the large body of academic literature that Wittgenstein’s work has inspired. </p><p>During this lecture Wittgenstein told one of the students to stop making notes: </p><p> ~If you write these spontaneous remarks down, some day someone may publish them as my considered opinions. I don’t want that done. For I am talking now freely as my ideas come.~ </p><p>Fortunately, this request was ignored, and notes from these lectures have indeed been published.</p><h1 id="Aesthetics-and-Religion"><a href="#Aesthetics-and-Religion" class="headerlink" title="Aesthetics and Religion"></a>Aesthetics and Religion</h1><h2 id="Attach-Worship-of-Science"><a href="#Attach-Worship-of-Science" class="headerlink" title="Attach Worship of Science"></a>Attach Worship of Science</h2><p>These lectures are <strong>unique</strong> among Wittgenstein’s corpus. They are concerned, not with mathematics or philosophy generally, but with <strong>aesthetics and religious belief.</strong><br>What distinguishes these lectures is their tone. Precisely because he was speaking in a <strong>spontaneous and unguarded manner</strong><br>And his target is more about the <strong>wretched effect that the worship of science and the scientific method has had upon our whole culture.</strong></p><p>He believes that in areas of <strong>thought and life, scientific method is not appropriate</strong>, and efforts trying to make it <strong>so lead to distortion, superficiality and confusion</strong>.<br>Wittgenstein told his audience that what he was doing was ‘persuading people to change their style of thinking’ He said he is really <strong>disgusted with worship of science</strong><br>He gives an example: </p><p>~Jeans has written a book called The Mysterious Universe and I loathe it and call it misleading.3 Take the title … I might say the title The Mysterious Universe includes a kind of idol worship, <strong>the idol being Science and the Scientist</strong>.~</p><h2 id="Rescue-Artistic-Appreciation"><a href="#Rescue-Artistic-Appreciation" class="headerlink" title="Rescue Artistic Appreciation"></a>Rescue Artistic Appreciation</h2><p>He was also trying to rescue questions of artistic appreciation from the idea that there could be <strong>a kind of science of aesthetics</strong>:<br>He said:  </p><p>~You might think Aesthetics is a science telling us what’s beautiful – almost too ridiculous for words.I suppose it ought to include also what sort of coffee tastes well~.</p><p>When  asked about his ‘theory’ of deterioration Wittgenstein answered:</p><p>~‘Do you think I have a theory? Do you think I’m saying what deterioration is? What I do is <strong>describe different things called deterioration</strong>~</p><p>He said that Appreciation often will not consist in saying anything. Appreciation <strong>will be shown</strong></p><ul><li>by actions as often as by words</li><li>by certain gestures of disgust or satisfaction</li><li>by the way we read a work of poetry or play a piece of music</li><li><p>by how often we read or listen to the same piece, and how we do so.<br>These different forms of appreciation <strong>do not have any one thing in common that one can isolate in answer to the question: ‘What is artistic appreciation?’</strong> </p></li><li><p>[x] (They are, rather, linked by a complicated series of ‘family resemblances’. )</p></li></ul><p>So It is <strong>impossible to describe what it consists</strong> because we would have to describe the whole environment. </p><h2 id="Religious-Belief"><a href="#Religious-Belief" class="headerlink" title="Religious Belief"></a>Religious Belief</h2><p>Regarding religious, Wittgenstein did not wish to <strong>see God or to</strong> <strong>find reasons for His existence</strong>. He thought that if he could overcome himself – if a day came when his whole nature ‘bowed down in humble resignation in the dust’ – then God would  come to him and he would be saved.<br>But in his lectures on religious belief he concentrates only on the first part of this convictiont<strong>he denial of the necessity to have reasons for religious beliefs</strong>.<br><strong>He said:</strong></p><p>~‘Russell and the parsons between them have done infinite harm, infinite harm.’~ </p><p>This is because they both have encouraged the idea that a <strong>philosophical justification for religious beliefs is necessary for those beliefs</strong>  So Both of them have fallen victim to the <strong>idol-worship of the scientific style of thinking.</strong> <strong>Religious beliefs are not analogous to scientific theories, and should not be accepted or rejected using the same evidential criteria.</strong><br> Wittgenstein insists that : The kind of experience that can make a man religious, is not at all like the experience of <strong>drawing a conclusion from an experiment or from a collection of data.</strong></p><h1 id="Pride-and-Ambivalence"><a href="#Pride-and-Ambivalence" class="headerlink" title="Pride and Ambivalence"></a>Pride and Ambivalence</h1><h2 id="Apologize-for-Everything"><a href="#Apologize-for-Everything" class="headerlink" title="Apologize for Everything"></a>Apologize for Everything</h2><p>Wittgenstein is determined not to let himself get away with the smallest misbehavior. For example he once wrote a letter to apologize for a very minor mistake:<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Dear Mrs Stewart</span><br><span class="line">I must apologise <span class="keyword">for</span> an untruth I told you today <span class="keyword">in</span> Miss Pate’s office. </span><br><span class="line">I said <span class="keyword">that</span> I had seen Mrs Thomson recently <span class="keyword">in</span> Birmingham; </span><br><span class="line">&amp; only when I came home this evening <span class="keyword">it</span> occurred <span class="keyword">to</span> <span class="keyword">me</span> <span class="keyword">that</span> this wasn’t <span class="literal">true</span> <span class="keyword">at</span> all.</span><br><span class="line">……</span><br><span class="line">Please forgive <span class="keyword">my</span> stupidity. </span><br><span class="line">Yours sincerely, L. Wittgenstein</span><br></pre></td></tr></table></figure></p><h2 id="Pride-in-Work"><a href="#Pride-in-Work" class="headerlink" title="Pride in Work"></a>Pride in Work</h2><p>However, things are very interesting in philosophy work. Though he tried  to exclude pride from his work, as he put it, <strong>‘to the glory of God’ rather than out of vanity</strong>,<br>yet we find again and again that <strong>‘pride of Lucifer’</strong> occurs most often in philosophy work.<br>He said: </p><p>~I was obliged to learn that my results  variously misunderstood…. This stung my vanity and I had difficulty in quieting it.~ </p><h2 id="Become-Professor"><a href="#Become-Professor" class="headerlink" title="Become Professor"></a>Become Professor</h2><p>After G. E. Moore’s resignation, He decided to apply for the post of Professor of Philosoph<br>The disadvantage is  one of the electors Collingwood was disagree with Wittgenstein’s work. The advantage is that among the electors there was John Keynes.<br>The fact is that, by 1939 he was recognized as the <strong>foremost philosophical genius of his time</strong>. </p><p>~‘To refuse the chair to Wittgenstein’ ‘would be like refusing Einstein a chair of physics.’~ , said C. D. Broad. Broad was not a admirer of Wittgenstein’s work; he was simply stating a fact. </p><p>On 11 February Wittgenstein was duly elected professor. </p><h1 id="Mathematics"><a href="#Mathematics" class="headerlink" title="Mathematics"></a>Mathematics</h1><h2 id="Redescribe-Math"><a href="#Redescribe-Math" class="headerlink" title="Redescribe Math"></a>Redescribe Math</h2><p>After he became a Professor, He decided to rescue math by giving a series of lectures to the subject.</p><p>So his aim was to reinterpret mathematics – to redescribe it was not a fascinating world waiting for mathematicians, but a swamp of philosophical confusions. </p><ul><li>The mathematician Hilbert had once said: ‘No one is going to turn us out of the paradise which Cantor has created.’</li><li>Wittgenstein told his class: ‘I wouldn’t dream of trying to drive anyone out of this paradise’ I would do something quite different: I would try to show you that it is not a paradise so that you’ll leave of your own accord</li></ul><p>The lectures on mathematics is one of Wittgenstein’s general attack on the idol-worship of science. Wittgenstein thought the idolization of science was the <strong>most significant symptom and a contributory cause of the decay of our culture.</strong> </p><h2 id="Argue-with-Turing"><a href="#Argue-with-Turing" class="headerlink" title="Argue with Turing"></a>Argue with Turing</h2><p>One of the lectures audience was one of the greatest mathematicians of the century: Alan Turing.<br>The lectures often developed into a <strong>dialogue</strong> between Wittgenstein and Turing, with the f<strong>ormer attacking and the latter defending the importance of mathematical logic</strong>.<br>The presence of Turing is very essential to the theme of the discussion, once when he announced he would not be attending a certain lecture, Wittgenstein told the class that, therefore, that lecture would have to be ‘somewhat parenthetical’</p><p>He said he would try again and again to show that what is called a <strong>mathematical discovery is actually a mathematical invention</strong>. On his view, nothing for the mathematician to discover. A proof in mathematics does not mean the truth of a conclusion but fix the meaning of certain signs.<br>He thought that <strong>mathematical propositions are grammatical</strong>. </p><p>After some more lectures Turing stopped attending, convinced that if Wittgenstein would not admit a contradiction is a fatal flaw in a system of mathematics, then there could be no common ground between them.<br>I think it is very brave of Turing to attend the classes as the representative of all that Wittgenstein was attacking, surrounded by Wittgenstein’s students and discussing the issues in a way that was unfamiliar to him. </p><h1 id="The-Death-of-Francis"><a href="#The-Death-of-Francis" class="headerlink" title="The Death of Francis"></a>The Death of Francis</h1><h2 id="Death-of-Francis"><a href="#Death-of-Francis" class="headerlink" title="Death of Francis"></a>Death of Francis</h2><p>By the time the second world war broke out, Skinner’s period as an apprentice had come to an end and he returned to Cambridge and he seems to have made an attempt to return to theoretical work<br>He knew that he was losing Wittgenstein’s love. After his return to Cambridge, he and Wittgenstein lived separately</p><p>In 1941 Francis had been taken seriously ill with polio and had been admitted into hospital. On 11 October 1941, Francis died.<br>Wittgenstein’s initial reaction was <strong>one of delicate restraint</strong>. In letters to friends telling them of Francis’s death, he managed a <strong>tone of quiet dignity.</strong> :</p><p>~He died without any pain or struggle entirely peacefully. I was with him. I think he has had one of the happiest lives I’ve known anyone to have, &amp; also the most peaceful death.~ </p><p>By the time of the funeral  his restraint had gone. He behaves like a <strong>‘frightened wild animal’</strong> at the ceremony, after the ceremony he refused to go to the house but  walked around town.</p><p>But Wittgenstein’s guilt over Francis was entirely unconnected with the way in which he had influenced him. It had to do with more <strong>internal matters</strong><br>He wrote: </p><p>~In the last 2 years of his life very often loveless and, in my heart, unfaithful to him. If he had not been so boundlessly gentle and true, I would have become totally loveless towards him.~ </p><p>~Think a great deal about the last time I was with Francis; about my odiousness towards him … I cannot see how I can ever in my life be freed from this guilt~</p><h2 id="Solipsism-Philosophy-and-Love"><a href="#Solipsism-Philosophy-and-Love" class="headerlink" title="Solipsism: Philosophy and Love"></a>Solipsism: Philosophy and Love</h2><p>Compared with other people Wittgenstein love but not get reward, we can see the characteristics of his love: <strong>a certain indifference to the feelings of the other person.</strong> Neither Pinsent nor Marguerite nor Kirk  were in love with him seemed not to affect his love for them. Indeed, it perhaps made <strong>his love easier to give</strong>, for the relationship could be <strong>safe</strong>, in the <strong>splendid isolation of his own feelings</strong>.<br>So at last there is a very important concept about Wittgenstein’s love and philosophical ideas:  <strong>solipsism</strong></p><p>Most of his later work is to against the philosophical solipsism which once attracted his very much. He characterized his later work as <strong>an attempt to show the fly the way out of the fly-bottle</strong>)<br>Its parallel is the emotional solipsism. With Francis that isolation was threatened, and, in the face of that threat, Wittgenstein had withdrawn. I think it is the major reason he behaves really badly towards Francis in his last few years and made him so guilty.</p><p>So that’s all about Chapter 20, about the life when he returned to Cambridge, his thought towards science, aesthetics, religious, mathematics and love. It shows what a complicated man Wittgenstein was, most importantly, the author gives us the parallel comparison about his love and his work. We can have a better understanding how one man’s characteristics can deeply shape him,  especially for such a genius.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Some notes and thoughts concerning &lt;strong&gt;Ludwig Wittgenstein: The Duty of Genius&lt;/strong&gt; by Monk, Ray. To be honest, I first found Wittgenstein very mysterious and great (part of the reason is his wonderful german name). But now I feel little disappointed. I see more a crazy and strange man rather than a genius. He may be a genius, but if it is because his madness and defect (I know it is wrong to say like this, but I can always have such feelings that some man is “great” just because he is strange or even mad), I don’t think it is a great thing. Also I am always confused about philosopher, they always think themselves have the right to judge everything, it is really ridiculous. So I really hate many of his thoughts concerning language, science and maths.&lt;br&gt;
    
    </summary>
    
      <category term="thoughts" scheme="http://james20141606.github.io/categories/thoughts/"/>
    
    
      <category term="philosophy" scheme="http://james20141606.github.io/tags/philosophy/"/>
    
      <category term="Wittgenstein" scheme="http://james20141606.github.io/tags/Wittgenstein/"/>
    
      <category term="thoughts" scheme="http://james20141606.github.io/tags/thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Assignments of Statistic Inferences</title>
    <link href="http://james20141606.github.io/2018/04/16/Statistic-Inferences/"/>
    <id>http://james20141606.github.io/2018/04/16/Statistic-Inferences/</id>
    <published>2018-04-16T06:33:06.000Z</published>
    <updated>2018-04-16T06:46:36.287Z</updated>
    
    <content type="html"><![CDATA[<p>ALL the assignments of <strong>Statistic Inferences</strong>. The assignment is written in Rmarkdown/LaTeX, LaTeX is a classic formula editor but a little hard to use intensely. Rmarkdown is introduced by TA and it is a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.<br><a id="more"></a><br>You may also find the <a href="https://github.com/james20141606/somethingmore/tree/master/statistic_inderences_pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this assignment. Which is more recommended.</p><p>Apart from all the math and knowledge I learned from SI course, one of the most useful techniques a obtain from the course is definitely “writing skill”. Statistic Inferences is my first statistic minor course. Before this course I rarely use LaTeX or markdown.(Only when I write math model course paper and project report). So I am rusty at writing complex formulas at first. But thanks to this course, I use LaTeX and markdown really proficiently. Now I write nearly every file in LaTeX of markdown. I also want to recommend <a href="http://www.bear-writer.com/" target="_blank" rel="noopener"><strong>Bear</strong></a>, a markdown based notes manager, which is perfect especially for coders. I have transferred all my codes, work, plan to it for nearly two years and it really helps me to be more effective. One of many benefits is I can simply copy all my notes in bear in my posts without changing anything, for hexo and bear both use markdown(as well as Rmarkdown and LaTeX and gitbook and all README file, they all appear in my daily life quite often).</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ALL the assignments of &lt;strong&gt;Statistic Inferences&lt;/strong&gt;. The assignment is written in Rmarkdown/LaTeX, LaTeX is a classic formula editor but a little hard to use intensely. Rmarkdown is introduced by TA and it is a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;br&gt;
    
    </summary>
    
      <category term="school work" scheme="http://james20141606.github.io/categories/school-work/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="R" scheme="http://james20141606.github.io/tags/R/"/>
    
      <category term="assignment" scheme="http://james20141606.github.io/tags/assignment/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression Assignment 7</title>
    <link href="http://james20141606.github.io/2018/04/16/line2/"/>
    <id>http://james20141606.github.io/2018/04/16/line2/</id>
    <published>2018-04-16T06:01:19.000Z</published>
    <updated>2018-04-20T02:59:10.467Z</updated>
    
    <content type="html"><![CDATA[<p>The seventh assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.<br><a id="more"></a><br>You may also find the <a href="https://github.com/james20141606/somethingmore/tree/master/linear_regression_pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this assignment. Which is more recommended. <strong>Or here</strong>:<br><div class="row"><iframe src="https://drive.google.com/file/d/10Oo7Rb7sKNbT7XPEzdGwlfQRO1O42Y0h/preview" style="width:100%; height:550px"></iframe></div></p><h1 id="1"><a href="#1" class="headerlink" title="1"></a>1</h1><h2 id="a"><a href="#a" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># read the data</span><br><span class="line">setwd(&apos;~/Desktop/三春/5线性回归分析/作业/HW7/&apos;)</span><br><span class="line">Data&lt;-read.table(&quot;hw7.txt&quot;)</span><br><span class="line">names(Data) = c(&quot;Hours&quot;,&quot;Cases&quot;,&quot;Costs&quot;,&quot;Holiday&quot;)</span><br><span class="line">Fit = lm(Hours~Cases+Costs+Holiday, data=Data)</span><br><span class="line">anova(Fit)</span><br><span class="line">SSTO = sum( anova(Fit)[,2] )</span><br><span class="line">MSE = anova(Fit)[4,3]</span><br><span class="line">SSR = sum( anova(Fit)[1:3,2] )  </span><br><span class="line">MSR = SSR / 3                  </span><br><span class="line">SSE = anova(Fit)[4,2]</span><br></pre></td></tr></table></figure><p>From the table we have: $SSR(X_1) = 136366$,$SSE(X_1,X_2,X_3) = 985530$</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Fit2 = lm(Hours~Cases+Holiday, data=Data)</span><br><span class="line">anova(Fit2)</span><br></pre></td></tr></table></figure><p>$SSR(X_3|X_1) = 2033565$</p><p>$SSR(X_2|X_1,X_3) = SSE(X_1,X_3)-SSE(X_1,X_2,X_3)$ = 992204 - 985530 = 6674</p><h2 id="b"><a href="#b" class="headerlink" title="b"></a>b</h2><script type="math/tex; mode=display">H_0: \beta_2 = 0, H_a: \beta_2 \neq 0. \\</script><p>From a we have:</p><script type="math/tex; mode=display">SSR(X_2|X_1,X_3)  = 6674, SSE(X_1,X_2,X_3) =  985530\\F^* = \frac{(6674/1)}{985530/48} = 0.32491 \\F(0.95,1,48) = 4.04265 \\If \  F^* \leqslant 4.04265 \ conclude H_9, otherwise \ conclude H_a \\P-value = 0.5713</script><h2 id="c"><a href="#c" class="headerlink" title="c"></a>c</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Fit2 = lm(Hours~Cases+Costs, data=Data)</span><br><span class="line">anova(Fit2)</span><br><span class="line">Fit3 = lm(Hours~Costs+Cases, data=Data)</span><br><span class="line">anova(Fit3)</span><br></pre></td></tr></table></figure><p>So we have $SSR(X_2|X_1) +SSR(X_1) = 136366 + 5726 = 11395+130697 =SSR(X_1|X_2) +SSR(X_2)$ </p><p>Yes, it is always true because: $SSR(X_2|X_1)+SSR(X_1) = SSE(X_1) - SSE(X_1,X_2) +SSR(X_1) = SSTO -SSE(X_1,X_2)$</p><p>$SSR(X_1|X_2)+SSR(X_2) = SSE(X_2) - SSE(X_1,X_2) +SSR(X_2) = SSTO -SSE(X_1,X_2)$</p><h1 id="2"><a href="#2" class="headerlink" title="2"></a>2</h1><p>From question1, We have $SSR(X<em>1) = 136366,SSR(X_2) =  5726 , SSR = 2176606,SSTO = 3162136$ \<br>So $R^2</em>{Y<em>1} = 0.0431,R^2</em>{Y<em>2} =0.00181,R^2 = 0.6883$ \<br>From homework6 we have $r_12 = 0.10059216$, so $R^2</em>{12} =0.0101 $ \</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Fit4 = lm(Hours~Costs, data=Data)</span><br><span class="line">anova(Fit4)</span><br><span class="line">Fit5 = lm(Hours~Cases, data=Data)</span><br><span class="line">anova(Fit5)</span><br></pre></td></tr></table></figure><p>$R^2<em>{Y1|2} = \frac{SSR(X_1|X_2)}{SSE(X_2)}$ = 130697/3150741 = 0.04148\<br>$R^2</em>{Y2|1} = \frac{SSR(X_2|X_1)}{SSE(X_1)}$ = 5726/3025770 = 0.001892\</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Fit6 = lm(Hours~Cases+Holiday, data=Data)</span><br><span class="line">anova(Fit6)</span><br></pre></td></tr></table></figure><p>$R^2_{Y2|13} = \frac{SSR(X_2|X_1,X_3)}{SSE(X_1,X_3)}$</p><p>$SSR(X_2|X_1,X_3) = SSE(X_1,X_3)-SSE(X_1,X_2,X_3)$ = 992204 - 985530 = 6674 </p><p>$SSE(X<em>1,X_3)$ = 992204, so $R^2</em>{Y2|13}$ = 6674/992204 = 0.006726</p><h1 id="3"><a href="#3" class="headerlink" title="3"></a>3</h1><h2 id="a-1"><a href="#a-1" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Fit = lm(Hours~Cases, data=Data)</span><br><span class="line">summary(Fit)</span><br></pre></td></tr></table></figure><p>So regression function is $\hat Y = 4080 +0.0009355X_1$ \</p><h2 id="b-1"><a href="#b-1" class="headerlink" title="b"></a>b</h2><p>The regression function in 6.10a is $Y=0.0007871X_1-13.17X_2+623.6X3+4150$</p><p>The coefficient $\beta_1$ is bigger than coefficient in 6.10a.</p><h2 id="c-1"><a href="#c-1" class="headerlink" title="c"></a>c</h2><p>No, from question 1, $SSR(X_1) = 136366,SSR(X_1|X_2)=130697$. It’s not substantial</p><h2 id="d"><a href="#d" class="headerlink" title="d"></a>d</h2><p>The correlation of $X_1,X_2$ is highest in all predictors, so the $SSR(X_1) and SSR(X_1|X_2)$ don’t have substantial difference.</p><h1 id="4"><a href="#4" class="headerlink" title="4"></a>4</h1><h2 id="a-2"><a href="#a-2" class="headerlink" title="a"></a>a</h2><p>To run a polynomial regression model on one or more predictor variables, it is advisable to first center the variables by subtracting the corresponding mean of each, in order to reduce the intercorrelation among the variables.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x1 &lt;- Data$Cases - mean(Data$Cases)</span><br><span class="line">x3 &lt;- Data$Holiday - mean(Data$Holiday)</span><br><span class="line">x1sq &lt;- x1^2</span><br><span class="line">x3sq &lt;- x3^2</span><br><span class="line">x1x3 &lt;- x1 * x3</span><br><span class="line">Grocery &lt;- cbind( Data, x1, x3, x1sq, x3sq, x1x3 )</span><br><span class="line">Poly &lt;- lm(  Hours ~ x1 + x3 + x1sq + x3sq + x1x3, data=Grocery )</span><br><span class="line">summary(Poly)</span><br></pre></td></tr></table></figure><p>So the model is $\hat Y = 4367+8.61 \times 10^{-4} X_1+623.7 X_3-1.154 \times 10^{-9}X_1^2 -8.87 \times 10^{-5} X_1 X_3$</p><h2 id="b-2"><a href="#b-2" class="headerlink" title="b"></a>b</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">anova(Poly)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Fit7 &lt;-lm(  Hours ~ x1 + x3, data=Grocery )</span><br><span class="line">anova(Fit7)</span><br><span class="line">qf(0.95,3,46)</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">H_0: \beta_3,\beta_4,\beta_5 =0, H_a: \text{not all }\beta_k in H_0 = 0\\F^* = \frac{SSR(X_1^2,X_3^2,X_1X_3|X_1,X_3)/3}{SSE(X_1^2,X_3^2,X_1X_3,X_1,X_3)/(n-6)}\\=\frac{(SSE(X_1,X_3)-SSE(X_1^2,X_3^2,X_1X_3,X_1,X_3))/3}{991173/46}\\=\frac{(992204-991173)/3}{991173/46}\\=0.01594945\\F(0.95,3,46) = 2.806845, So \ F^* < F(0.95,3,46), \text{Do not reject H_0.}</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pf(0.01594945,3,46)</span><br></pre></td></tr></table></figure><p>p-value = 0.002785933</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The seventh assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;br&gt;
    
    </summary>
    
      <category term="school work" scheme="http://james20141606.github.io/categories/school-work/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="R" scheme="http://james20141606.github.io/tags/R/"/>
    
      <category term="assignment" scheme="http://james20141606.github.io/tags/assignment/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="linear regression" scheme="http://james20141606.github.io/tags/linear-regression/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression Assignment 6</title>
    <link href="http://james20141606.github.io/2018/04/16/line1/"/>
    <id>http://james20141606.github.io/2018/04/16/line1/</id>
    <published>2018-04-16T05:59:19.000Z</published>
    <updated>2018-04-20T02:52:25.194Z</updated>
    
    <content type="html"><![CDATA[<p>The sixth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.<br><a id="more"></a><br>You may also find the <a href="https://github.com/james20141606/somethingmore/tree/master/linear_regression_pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this assignment. Which is more recommended. <strong>Or here</strong>:<br><div class="row"><iframe src="https://drive.google.com/file/d/1-lgCaX4w7FjBMdYdr330UWjqdkMCJtuf/preview" style="width:100%; height:550px"></iframe></div></p><h1 id="1"><a href="#1" class="headerlink" title="1"></a>1</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># read the data</span><br><span class="line">setwd(&apos;~/Desktop/三春/5线性回归分析/作业/HW6/&apos;)</span><br><span class="line">dat&lt;-read.csv(&quot;hw6.csv&quot;)</span><br><span class="line">cases&lt;-dat$X1</span><br><span class="line">percent&lt;-dat$X2</span><br><span class="line">holiday&lt;-dat$X3</span><br><span class="line">labor&lt;-dat$Y</span><br><span class="line"># plot stem and leaf plots</span><br><span class="line">stem(cases)</span><br><span class="line">stem(percent)</span><br></pre></td></tr></table></figure><p>The plots are above.<br>There seems to be some outliers. For example for $X_2$, the values more than 9 and lower than 5 seem to be outliers. The gaps are obvious.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># plot time plots</span><br><span class="line">time&lt;-1:52</span><br><span class="line">plot(time,dat$X1,xlab=&quot;time (weeks)&quot;,ylab=&quot;X1&quot;)</span><br><span class="line">plot(time,dat$X2,xlab=&quot;time (weeks)&quot;,ylab=&quot;X2&quot;)</span><br><span class="line">plot(time,dat$X3,xlab=&quot;time (weeks)&quot;,ylab=&quot;X3&quot;)</span><br></pre></td></tr></table></figure><p>1) $X_1$ may depent on time. it has a tendency to be larger over time<br>2) $X_2$ is independent of time<br>3) $X_3$ seems independent of time </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pairs(~cases+percent+holiday+labor,data=dat, </span><br><span class="line">   main=&quot;Simple Scatterplot Matrix&quot;)</span><br><span class="line">cor(dat[,1:4])</span><br></pre></td></tr></table></figure><p>It is obvious that $X_3$ and Y has a very strong correlation(it also makes sense). the others have no significant correlation.</p><h1 id="2"><a href="#2" class="headerlink" title="2"></a>2</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dat.fit&lt;-lm(labor~cases+percent+holiday)</span><br><span class="line">sm&lt;-summary(dat.fit)</span><br><span class="line">sm</span><br><span class="line">resid1&lt;-dat.fit$residuals</span><br><span class="line">resid1</span><br></pre></td></tr></table></figure><p>a) The regression function is <script type="math/tex">Y=0.0007871X_1-13.17X_2+623.6X3+4150</script><br>$b_1, b_2, b_3$ are unbiased estimates of <script type="math/tex">\beta_1 , \beta_2 , \beta_3</script></p><p>b)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boxplot(resid1,ylab=&quot;residuals&quot;, pch=19)</span><br></pre></td></tr></table></figure></p><p>From the boxplot, we can know the median, maximum, minimum, 25 and 75 percent quantile of the residuals.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plot(labor,resid1)</span><br><span class="line">plot(cases,resid1)</span><br><span class="line">plot(percent,resid1)</span><br><span class="line">plot(holiday,resid1)</span><br><span class="line">plot(cases*percent,resid1)</span><br><span class="line">qqnorm(resid1, main=&quot;Normal Probability Plot&quot;, pch=19)</span><br><span class="line">qqline(resid1)</span><br></pre></td></tr></table></figure><p>c) The plots show that the regression function may not be linear. The residuals change systematically as Y increases, as shown in the first plot. Also the normal probability plot shows that the residuals may not be strictly normally distributed.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot(time,resid1)</span><br></pre></td></tr></table></figure><p>d) There does not seem to be any indication that the error terms are correlated.</p><h1 id="3"><a href="#3" class="headerlink" title="3"></a>3</h1><p>a) </p><script type="math/tex; mode=display">H_0:\ \beta_1=\beta_2=\beta_3=0\;\;H_a:\ otherwise</script><script type="math/tex; mode=display">We\;reject\;H_0\;if\;F^*=\frac{MSR}{MSE}>F_{0.95,3,48}</script><p>Based on the result:”F-statistic: 35.34 on 3 and 48 DF,  p-value: 3.316e-12”, we reject H0 and conclude Ha.<br>The p value is 3.316e-12<br>The t-test result from above implies that <script type="math/tex">\beta_1 \; and\; \beta_3</script> are likely to be non-zero but $\beta_2$ may be zero.</p><p>b)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">confint(dat.fit,c(2,4),level = 1-0.05/4)</span><br></pre></td></tr></table></figure></p><p>The family confidence interval is shown above. The family  confidence coefficient means that when doing many simulations, the proportion of samples which values fall correctly in the cofifence interval.</p><p>c.Coefficient of multiple determination is 0.6883. It can be viewed as a coefficient of simple determination between the responses and the fitted values.</p><h1 id="4"><a href="#4" class="headerlink" title="4"></a>4</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot(cases, percent,ylim=c(4,11))</span><br><span class="line">points(400000,7.2,pch=2)</span><br><span class="line">points(400000,9.9,pch=3)</span><br></pre></td></tr></table></figure><p>It is a plot of the two variables: X1 and X2. The cross and triangle represent the two points where predictions are to be made. It can be seen that the triangle lies well within the joint range of the two variables, but the cross seems to be out of the scope of the model.</p><h1 id="5"><a href="#5" class="headerlink" title="5"></a>5</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">new1 &lt;- data.frame(cases=230000,percent=7.5,holiday=0)</span><br><span class="line">new2 &lt;- data.frame(cases=250000,percent=7.3,holiday=0)</span><br><span class="line">new3 &lt;- data.frame(cases=280000,percent=7.1,holiday=0)</span><br><span class="line">new4 &lt;- data.frame(cases=340000,percent=6.9,holiday=0)</span><br><span class="line">predict(dat.fit, new1, se.fit = F, interval = &quot;prediction&quot;, level = 1-0.05/8)</span><br><span class="line">predict(dat.fit, new2, se.fit = F, interval = &quot;prediction&quot;, level = 1-0.05/8)</span><br><span class="line">predict(dat.fit, new3, se.fit = F, interval = &quot;prediction&quot;, level = 1-0.05/8)</span><br><span class="line">predict(dat.fit, new4, se.fit = F, interval = &quot;prediction&quot;, level = 1-0.05/8)</span><br></pre></td></tr></table></figure><p>The intervals are presented above.</p><h1 id="6"><a href="#6" class="headerlink" title="6"></a>6</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">new &lt;- data.frame(cases=282000,percent=7.1,holiday=0)</span><br><span class="line">predict(dat.fit, new, se.fit = T, interval = &quot;prediction&quot;, level = 1-0.05)</span><br><span class="line">mse &lt;- mean(dat.fit$residuals^2)</span><br><span class="line">mse</span><br></pre></td></tr></table></figure><p>We obtained MSE and se.fit.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lwr&lt;-4278.365-qt(1-0.05/2,df=48)*sqrt(mse/3+22.83758^2)</span><br><span class="line">upr&lt;-4278.365+qt(1-0.05/2,df=48)*sqrt(mse/3+22.83758^2)</span><br><span class="line">lwr</span><br><span class="line">upr</span><br></pre></td></tr></table></figure></p><p>a. The interval is (4112.088,4444.642)<br>b. Just multiply the interval by 3. We obtain (12336.27,13333.92)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The sixth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;br&gt;
    
    </summary>
    
      <category term="school work" scheme="http://james20141606.github.io/categories/school-work/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="R" scheme="http://james20141606.github.io/tags/R/"/>
    
      <category term="assignment" scheme="http://james20141606.github.io/tags/assignment/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="linear regression" scheme="http://james20141606.github.io/tags/linear-regression/"/>
    
  </entry>
  
  <entry>
    <title>Multivariate Statistics Assignment 3</title>
    <link href="http://james20141606.github.io/2018/04/16/multi0/"/>
    <id>http://james20141606.github.io/2018/04/16/multi0/</id>
    <published>2018-04-16T04:59:19.000Z</published>
    <updated>2018-04-20T02:55:01.954Z</updated>
    
    <content type="html"><![CDATA[<p>The third assignment of Multivariate Statistics. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.<br><a id="more"></a><br>You may also find the <a href="https://github.com/james20141606/somethingmore/tree/master/linear_regression_pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this assignment. Which is more recommended. <strong>Or here</strong>:<br><div class="row"><iframe src="https://drive.google.com/file/d/128itrGhENm_IZbs-si0gkS4X5NHdDfMU/preview" style="width:100%; height:550px"></iframe></div></p><h1 id="1"><a href="#1" class="headerlink" title="1"></a>1</h1><p>density function for the multivariate normal distribution:</p><script type="math/tex; mode=display">f(x; \mu, \Sigma) =\frac{1}{(2\pi)^{p/2}|\Sigma|^{1/2}}e^{-\frac{1}{2}(x-\mu)^{'}\Sigma^{-1}(x-\mu)}</script><p>the likelihood function for the two independent sample:</p><script type="math/tex; mode=display">L(\mu_1,\mu_2,\Sigma) = \Pi_{i=1}^{n_1}f(X_i;\mu_1,\Sigma)\Pi_{j=1}^{n_2}f(X_j;\mu_2,\Sigma) \\=L(\mu_1,\Sigma)L(\mu_2,\Sigma)</script><p>So the likelihood function can be defined as:</p><script type="math/tex; mode=display">L(\mu_1,\mu_2,\Sigma) = \frac{1}{(2\pi)^{Np/2}|\Sigma|^{N/2}}exp(  -\frac{1}{2}tr[  \Sigma^{-1} (\sum_{i=1}^{n_1}\Phi_1(X_i)+\sum_{j=1}^{n_2}\Phi_2(X_j))  ]   ) \\\Phi_i(x) = (x-\mu_i)(x-\mu_i)^{'}</script><p>Using MLE, the maximum is:</p><script type="math/tex; mode=display">\hat \Sigma = \frac{1}{n_1+n_2} (\sum_{i=1}^{n_1} \Phi_1(X_i)+\sum_{j=1}^{n_2}\Phi_2(X_j)) \\=\frac{1}{n_1+n_2}[(n_1-1)S_1+(n_2-1)S_2] = \frac{n_1+n_2-1}{n_1+n_2}S_{pooled}</script><h1 id="2"><a href="#2" class="headerlink" title="2"></a>2</h1><h2 id="a"><a href="#a" class="headerlink" title="(a)"></a>(a)</h2><p>It can be calculated that:</p><script type="math/tex; mode=display">\bar x=[4.64,45.4,9.965]^{T}\\S=\left[\begin{matrix}2.879 &10.01 &-1.81 \\10.01&199.788&-5.64 \\-1.81&-5.64&3.682\end{matrix}\right]</script><p>we can calculate S’s eigen value and its respective eigen vector:</p><script type="math/tex; mode=display">value = [ 200.46209264,    1.31804876,    4.56885859]\\e_1^{'} = [-0.05084165, -0.82194341, -0.56729548] \\e_2^{'} = [-0.99828327,  0.02528569,  0.0528313 ] \\e_3^{'} = [ 0.02907988, -0.56900761,  0.82181792] \\</script><p>The axes of the region are:</p><script type="math/tex; mode=display">\sqrt \lambda_i \sqrt {\frac{p(n-1)}{n(n-p)}F_{p,n-p}(\alpha)} \\\frac{p(n-1)}{n(n-p)}F_{p,n-p}(\alpha) = \frac{19 \times 3}{17 \times 20} \times F_{3,17}(0.1) = 0.167 \times 2.44 = 0.409</script><p>so the axes’ lengths are:</p><script type="math/tex; mode=display">\sqrt {200.46209264} \times \sqrt {0.409} = 9.055 \\\sqrt {1.31804876} \times \sqrt {0.409} = 0.734 \\\sqrt {4.56885859} \times \sqrt {0.409} = 1.367</script><p>The directions of each aixs is determined by its corresponding eigen vector shown above.</p><h2 id="b"><a href="#b" class="headerlink" title="(b)"></a>(b)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># read the data</span><br><span class="line">setwd(&apos;~/Desktop/三春/3多元统计分析/作业/作业3-1,3-2/&apos;)</span><br><span class="line">dat&lt;-read.csv(&quot;data.csv&quot;)</span><br><span class="line">x1&lt;-dat$x1</span><br><span class="line">x2&lt;-dat$x2</span><br><span class="line">x3&lt;-dat$x3</span><br><span class="line">qqnorm(x1, main=&quot;Normal Probability Plot&quot;, pch=19)</span><br><span class="line">qqline(x1)</span><br><span class="line">qqnorm(x2, main=&quot;Normal Probability Plot&quot;, pch=19)</span><br><span class="line">qqline(x2)</span><br><span class="line">qqnorm(x3, main=&quot;Normal Probability Plot&quot;, pch=19)</span><br><span class="line">qqline(x3)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot(x1,x2)</span><br><span class="line">plot(x1,x3)</span><br><span class="line">plot(x2,x3)</span><br></pre></td></tr></table></figure><p>It seems that each variable’s normality is fine and they don’t have a significant relationship with each other, so the multivariate normal assumption seems justied.</p><h1 id="3"><a href="#3" class="headerlink" title="3"></a>3</h1><script type="math/tex; mode=display">T^2 = \sqrt n (\bar X -\mu_0)^{'}{(\frac{\sum_{j=1}^{n}(X_j-\bar X)(X_j-\bar X)^{'}}{n-1})^{-1}} \sqrt n (\bar X -\mu_0)\\\text{So it can be calculated that }T^2 = 9.74 \\\frac{p(n-1)}{(n-p)}F_{p,n-p}(\alpha) = \frac{19 \times 3}{17} \times F_{3,17}(0.05) = \frac{19 \times 3}{17} \times 3.20 = 10.729\</script><p>the confidence region is defined as :</p><script type="math/tex; mode=display">(\bar x_i - \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{ii}}{n}},\bar x_i + \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{ii}}{n}}) \\F_{p,n-p}(\alpha) = F_{3,17}(0.05) =3.20,  \ \bar x_1 = 4.64, \ \bar x_2 = 45.4,\ \bar x_3 =9.965 \\s_{11} = 2.879, \ s_{22} = 199.788, \  s_{33} = 3.628</script><p>so the three regions are:</p><script type="math/tex; mode=display">(\bar x_1 - \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{11}}{n}},\bar x_1 + \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{11}}{n}}) \\= [3.397, 5.882]\\(\bar x_2 - \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{22}}{n}},\bar x_2 + \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{22}}{n}}) \\= [35.047, 55.752]\\(\bar x_3 - \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{22}}{n}},\bar x_3 + \sqrt {\frac{p(n-1)}{n(n-p)} F_{p,n-p}(\alpha)} \sqrt{\frac{s_{33}}{n}}) \\= [8.569, 11.360]\\</script><h2 id="b-1"><a href="#b-1" class="headerlink" title="(b)"></a>(b)</h2><p>The Bonferroni region is defined as :</p><script type="math/tex; mode=display">[\bar x_p -t_{n-1}(\frac{\alpha}{2p})\sqrt{\frac{s_{pp}}{n}}, \ \bar x_p +t_{n-1}(\frac{\alpha}{2p})\sqrt{\frac{s_{pp}}{n}}] \\t_{19}(0.0083) = 2.625106</script><p>so the Bonferroni regions are:</p><script type="math/tex; mode=display">[3.644, 5.635] \\[37.103, 53.696] \\[8.846, 11.083]</script><p>which are smaller than $T^2$ confidence region because it focus on single confidence interval.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The third assignment of Multivariate Statistics. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;br&gt;
    
    </summary>
    
      <category term="school work" scheme="http://james20141606.github.io/categories/school-work/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="R" scheme="http://james20141606.github.io/tags/R/"/>
    
      <category term="assignment" scheme="http://james20141606.github.io/tags/assignment/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="linear regression" scheme="http://james20141606.github.io/tags/linear-regression/"/>
    
  </entry>
  
  <entry>
    <title>Linear Regression Assignment 4</title>
    <link href="http://james20141606.github.io/2018/04/16/line0/"/>
    <id>http://james20141606.github.io/2018/04/16/line0/</id>
    <published>2018-04-16T04:59:19.000Z</published>
    <updated>2018-04-20T02:51:21.420Z</updated>
    
    <content type="html"><![CDATA[<p>The fourth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.<br><a id="more"></a><br>You may also find the <a href="https://github.com/james20141606/somethingmore/tree/master/linear_regression_pdf" target="_blank" rel="noopener"><strong>PDF Version</strong></a> of this assignment. Which is more recommended. <strong>Or here</strong>:<br><div class="row"><iframe src="https://drive.google.com/file/d/1opWnMpCRo6zNydUWgrIrpeBQenV_tB04/preview" style="width:100%; height:550px"></iframe></div></p><figure class="highlight plain"><figcaption><span>setup, include</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knitr::opts_chunk$set(echo = TRUE)</span><br></pre></td></tr></table></figure><h1 id="3-6"><a href="#3-6" class="headerlink" title="3.6"></a>3.6</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hardness&lt;- read.table(&apos;CH01PR22_947709365.txt&apos;)</span><br><span class="line">names(hardness) &lt;- c(&quot;y&quot;,&quot;x&quot;)</span><br><span class="line">is.data.frame(hardness)</span><br><span class="line">hardness.fit &lt;- lm(y~x,data=hardness)</span><br><span class="line">sumtable&lt;-summary(hardness.fit)</span><br><span class="line">sumtable</span><br></pre></td></tr></table></figure><h2 id="a"><a href="#a" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">boxplot(resid(hardness.fit),main=&quot;Box Plot of Hardness Data&quot;, ylab=&quot;Residuals&quot;)</span><br></pre></td></tr></table></figure><p>The mean of residuals is zero</p><h2 id="b"><a href="#b" class="headerlink" title="b"></a>b</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yhat &lt;- fitted(hardness.fit); resid &lt;- resid(hardness.fit)</span><br><span class="line">plot(yhat,resid,main=&quot;Plot of residuals against the fitted values Yhat&quot;, </span><br><span class="line">     ylab=&quot;Residuals&quot;,xlab=&apos;yhat&apos;)</span><br></pre></td></tr></table></figure><p>There is one residual equals to 5.575 a little higher than others.</p><h2 id="c"><a href="#c" class="headerlink" title="c"></a>c</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hardness.stdres = rstandard(hardness.fit)</span><br><span class="line">qqnorm(resid, </span><br><span class="line">       ylab=&quot;Residuals&quot;, </span><br><span class="line">       xlab=&quot;Expected&quot;, </span><br><span class="line">       main=&quot; Normal Probability Plot of Residuals&quot;) </span><br><span class="line">qqline(resid)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">StdErr = summary(hardness.fit)$sigma</span><br><span class="line">n = 16</span><br><span class="line">ExpVals = sapply(1:n, function(k) StdErr * qnorm((k-.375)/(n+.25)))</span><br><span class="line">cor(ExpVals,sort(resid))</span><br></pre></td></tr></table></figure><p>With n=16, from Table B.6, the critical value for the coefficient of correlation between the ordered residuals and the expected values under normality when the distribution of error terms is normal using a 0.05 significance level is 0.941. Since 0.9916733 &gt; 0.941, the assumption of normality appeared reasonable.</p><h1 id="4-5"><a href="#4-5" class="headerlink" title="4.5"></a>4.5</h1><h2 id="a-1"><a href="#a-1" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">interval &lt;- function(dat)&#123;</span><br><span class="line">  names(dat) &lt;- c(&quot;y&quot;,&quot;x&quot;)</span><br><span class="line">  is.data.frame(dat)</span><br><span class="line">  data.fit &lt;- lm(y~x,data=dat)</span><br><span class="line">  sumtable&lt;-summary(data.fit)</span><br><span class="line">  coef &lt;- sumtable$coefficients</span><br><span class="line">  signif&lt;-1-(1-0.9)/4.0</span><br><span class="line">  tvalue &lt;-qt(signif, 14)</span><br><span class="line">  beta_0 = list(coef[1]-tvalue*coef[3],coef[1]+tvalue*coef[3])</span><br><span class="line">  beta_1 = list(coef[2]-tvalue*coef[4],coef[2]+tvalue*coef[4])</span><br><span class="line">  return(list(beta_0,beta_1))</span><br><span class="line">&#125;</span><br><span class="line">interval(hardness)</span><br></pre></td></tr></table></figure><p>From R result, $b_0 = 168.6, s(b_0)=2.65702, b_1 = 2.03438, s(b_1)=0.09039.$ Since<br>t(0.975, 14) = 2.145, Bonferroni joint confidence intervals for $β_0$ and $β_1$, using a 90% percent family confidence coefficient, are 168.6±2.145(2.65702) = [162.901, 174.299] for $β_0$ and 2.03438±2.145(0.09039) = [1.840, 2.228] for $β_1$. At least 90% of the time, both coefficients will be within the limits stated.</p><h2 id="c-1"><a href="#c-1" class="headerlink" title="c"></a>c</h2><p>The 90% joint confidence interval means that both will be in the interval at least 90% of the time.<br>Restated, at least one of them will be out of the interval no more than 10% of the time. We cannot get more specific than this.</p><h1 id="4-9"><a href="#4-9" class="headerlink" title="4.9"></a>4.9</h1><h2 id="a-2"><a href="#a-2" class="headerlink" title="a"></a>a</h2><p>For Bonferroni, use $b_0+b_1X_j±t(1−0.1/6, 14)s{\hat Y_h}$, with t(1−.10/6, 14) = 2.35982.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">meaninterval &lt;-function(X_h)&#123;</span><br><span class="line">mse &lt;- mean(sumtable$residuals^2)</span><br><span class="line">sYh &lt;- (mse * ( 1/16.0 + (X_h -ave(hardness$x)[1])**2/(sum((hardness$x - ave(hardness$x))**2)/16.0)) )**0.5</span><br><span class="line">beta_0 = coef[1]</span><br><span class="line">beta_1 = coef[3]</span><br><span class="line">list(beta_0 +beta_1*X_h - qt(1-.10/6, 14) * sYh,beta_0 +beta_1*X_h + qt(1-.10/6, 14) * sYh)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Using this function we have CI of 20,30,40 are [215.1106，228.3704], [245.9163，250.7052], [265.1384，284.6236] respectively.</p><p>The 90% joint confidence interval means that all three mean hardness will be in their respective interval at least 90% of the time.Restated, at least one of them will be out of the interval no more than 10% of the time. We cannot get more specific than this.</p><h1 id="4-12"><a href="#4-12" class="headerlink" title="4.12"></a>4.12</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">galleys.x &lt;- c(7, 12, 10, 10, 14, 25, 30, 25, 18, 10, 4, 6)</span><br><span class="line">cost.y &lt;- c(128, 213, 191, 178, 250 , 446, 540, 457, 324, 177, 75, 107)</span><br></pre></td></tr></table></figure><h2 id="a-3"><a href="#a-3" class="headerlink" title="a"></a>a</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">typos.lm &lt;- lm(cost.y~galleys.x-1)</span><br><span class="line">typos.lm</span><br></pre></td></tr></table></figure><script type="math/tex; mode=display">\hat Y_h=18.03X</script><h2 id="b-1"><a href="#b-1" class="headerlink" title="b"></a>b</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plot(galleys.x,cost.y,xlab= &quot;Galleys&quot;, ylab=&quot;Cost&quot;)</span><br><span class="line">abline(typos.lm)</span><br></pre></td></tr></table></figure><p>It appears that the model fits good</p><h2 id="c-2"><a href="#c-2" class="headerlink" title="c"></a>c</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">historical.norm &lt;- data.frame(galleys.x=1)</span><br><span class="line">alpha &lt;- 0.02</span><br><span class="line">typos.int &lt;- predict.lm(typos.lm, newdata = historical.norm , interval = &quot;confidence&quot;, level = 1-alpha)</span><br><span class="line">typos.int</span><br></pre></td></tr></table></figure><p>Alternatives: $H<em>0:E[Y]=β</em>{10}=17.50$ </p><p>$H<em>0:E[Y]≠β</em>{10}=17.50$  </p><p>CI: $17.81226≤E[Y_h]≤18.24435$ </p><p>Decision rule:</p><p>If $β_{10}$ falls within the confidence interval for $E[Y_h]$, conclude $H_0$;</p><p>If $β_{10}$ does not fall within the confidence interval for $E[Y_h]$, conclude $H_A$ </p><p>Conclusion:</p><p>Since 17.50&lt;17.81226; therefore, accept $H_A$.</p><h2 id="d"><a href="#d" class="headerlink" title="d"></a>d</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">newdata.galleys &lt;- data.frame(galleys.x=10)</span><br><span class="line">typos.pred &lt;- predict(typos.lm, newdata.galleys, level=0.98, interval = &quot;predict&quot;, se.fit = TRUE)  </span><br><span class="line">typos.pred</span><br></pre></td></tr></table></figure><p>$\hat Y_h=180.283$</p><p>s[pred]=4.506806</p><p>180.283±2.738769(4.506806)</p><p>$167.8441≤Y_{h(new)}≤192.722$</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The fourth assignment of Linear Regression. The assignment is written in Rmarkdown, a smart syntax supported by RStudio helping with formula, plot visualization and plugin codes running.&lt;br&gt;
    
    </summary>
    
      <category term="school work" scheme="http://james20141606.github.io/categories/school-work/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="R" scheme="http://james20141606.github.io/tags/R/"/>
    
      <category term="assignment" scheme="http://james20141606.github.io/tags/assignment/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="linear regression" scheme="http://james20141606.github.io/tags/linear-regression/"/>
    
  </entry>
  
  <entry>
    <title>春日の恋想</title>
    <link href="http://james20141606.github.io/2018/04/15/peomofmeng/"/>
    <id>http://james20141606.github.io/2018/04/15/peomofmeng/</id>
    <published>2018-04-15T05:54:30.000Z</published>
    <updated>2018-04-16T06:20:20.616Z</updated>
    
    <content type="html"><![CDATA[<p>就像pdf文档里所说的那样，这组诗作于2013年春⽇在郑州外国语学校就读期间，我十七岁，孟孟年方二八，正是豆蔻年华，如今看起来有些羞涩的文字却是那个时候的真情流露，并不觉得夸张。人们总是喜欢用青涩形容自己年轻的岁月，我却一直秉持着大胆地做自己想做的事情的原则，因此青春中做了很多美好的值得回味的，不落于俗套的美好事情。这一路来所做所想，都是自己所爱，能够在自己多年来心仪的学校继续和多年来心爱的姑娘经历生活的美好与平淡，实在是人生的幸运。<br><a id="more"></a><br>原诗曾记录整理于高中的电⼦词典中，并⼀⼀抄录于⼿折玫瑰中赠予孟孟。那个春天每天晚上一朵纸折的玫瑰，如今还能回忆起春风沉醉，空气温暖，眼眸明亮，笑容可人，这些是刻在记忆里了，以及这些文字，在2018 年1 ⽉30 ⽇整理旧寝室的物品的时候，发现还完好无损地躺在我的电子词典中，于是导出，重新用LaTeX排了版，如今也放在这里，希望可以和记忆一起永恒。</p><div class="row"><iframe src="https://drive.google.com/file/d/1lNCiSdpfv9scaQ1fHKt49UWHLv59rKjv/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;就像pdf文档里所说的那样，这组诗作于2013年春⽇在郑州外国语学校就读期间，我十七岁，孟孟年方二八，正是豆蔻年华，如今看起来有些羞涩的文字却是那个时候的真情流露，并不觉得夸张。人们总是喜欢用青涩形容自己年轻的岁月，我却一直秉持着大胆地做自己想做的事情的原则，因此青春中做了很多美好的值得回味的，不落于俗套的美好事情。这一路来所做所想，都是自己所爱，能够在自己多年来心仪的学校继续和多年来心爱的姑娘经历生活的美好与平淡，实在是人生的幸运。&lt;br&gt;
    
    </summary>
    
      <category term="life" scheme="http://james20141606.github.io/categories/life/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="girl friend" scheme="http://james20141606.github.io/tags/girl-friend/"/>
    
      <category term="poem" scheme="http://james20141606.github.io/tags/poem/"/>
    
  </entry>
  
  <entry>
    <title>Data Mining of Deng Era</title>
    <link href="http://james20141606.github.io/2018/04/15/datamining/"/>
    <id>http://james20141606.github.io/2018/04/15/datamining/</id>
    <published>2018-04-14T16:55:43.000Z</published>
    <updated>2018-04-15T08:26:50.362Z</updated>
    
    <content type="html"><![CDATA[<p>期中作业之一是写一篇邓小平时代的读后感，说实话这种书是实在没空读了，虽然粗略地翻了几章，十分吸引人，但是这两年真的越来越讨厌写文科式的论文，瞎胡诌凑字数曾经也是我作为理科生的优势，但是这一两年对这种风格的文章：东拼西凑，无病呻吟，迷茫又自负的写作非常地厌恶。因为就想玩点花样，做点简单的文本数据挖掘凑凑字数，虽然多花了很多时间，但是毕竟很有意思，有意思的事情就不算浪费时间对吧，没有意思的事情，哪怕一分钟也是对生命的浪费呢。<br><a id="more"></a><br>中文分词是个很好玩的事情，但是jieba和THULAC之类的工具已经把中文分词和词性标注之类的变得很简单，最折腾的，花了我很久时间的是这本中文材料。。。matplotlib本身不支持英文绘图，python的encoding方式也让我折腾了很久，竟然做了很久装卸各种包的工作，，，直到最后奇葩的matplotlib就是找不到字体，不管在本地还是在几个服务器上竟然都不行，于是只好测试好代码让斌斌帮忙在他的账户跑一下。下面简单记一下过程和代码，最后再把自己胡乱拼凑的论文也扔上。</p><p>代码也放到<a href="https://github.com/james20141606/somethingmore/datamining_dxp" target="_blank" rel="noopener">GitHub</a>上了,里面附有jupyter版本的代码和可以直接运行产生各种类型图片的代码。</p><h1 id="对邓小平时代的分词与词频统计"><a href="#对邓小平时代的分词与词频统计" class="headerlink" title="对邓小平时代的分词与词频统计"></a>对邓小平时代的分词与词频统计</h1><h2 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h2><p><strong>convert to UTF-8 format</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">file ip.txt</span><br><span class="line"><span class="comment">#use vim to change encoding format</span></span><br><span class="line">:<span class="builtin-name">set</span> <span class="attribute">fileencoding</span>=utf-8</span><br></pre></td></tr></table></figure></p><p>首先是找到txt版本的邓小平时代资源，用utf-8编码，方便后续处理。</p><h2 id="分词与词频统计"><a href="#分词与词频统计" class="headerlink" title="分词与词频统计"></a>分词与词频统计</h2><p>想做词频统计分析，就得对文本进行分词，中文和英文不同，英文单词是孤立的，而中文单词需要人工分开，这里我找了一个比较经典的分词方法，<strong>Jieba分词</strong>，对整本书进行了分词处理，把每句话都给分开，存储了各个名词，并且顺便统计了一下出现频次前10000的所有词语。因此我通过代码可以获取以下<strong>两个文件</strong>：</p><p>被分词分开的全书“词汇”，按顺序一个个存储起来，以及对各个词汇出现频次的统计文件。接下来就可以对数据进行进一步的分析。</p><p><strong>Use Jieba for Chinese words partition</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, codecs  </span><br><span class="line"><span class="keyword">import</span> jieba  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter </span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">plt.rcParams[<span class="string">'font.style'</span>] = <span class="string">u'normal'</span></span><br><span class="line">plt.rcParams[<span class="string">'font.family'</span>] = <span class="string">u'Microsoft YaHei'</span></span><br><span class="line"><span class="keyword">with</span> codecs.open(<span class="string">'output.txt'</span>, <span class="string">'r'</span>, <span class="string">'utf8'</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    txt = f.read() </span><br><span class="line">seg_list = jieba.cut(txt) </span><br><span class="line">c = Counter()  </span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> seg_list:  </span><br><span class="line">    <span class="keyword">if</span> len(x)&gt;<span class="number">1</span> <span class="keyword">and</span> x != <span class="string">'\r\n'</span>:  </span><br><span class="line">        c[x] += <span class="number">1</span></span><br><span class="line">np.savetxt(<span class="string">'count10000.txt'</span>,np.array(c.most_common(<span class="number">10000</span>)),fmt=<span class="string">'%s'</span>)</span><br><span class="line">data = np.loadtxt(<span class="string">'count10000.txt'</span>,dtype=<span class="string">'str'</span>)</span><br><span class="line"><span class="keyword">with</span> codecs.open(<span class="string">'output.txt'</span>, <span class="string">'r'</span>, <span class="string">'utf8'</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    txt = f.read() </span><br><span class="line">wordlist = np.array(txt.split(<span class="string">' '</span>))</span><br><span class="line"><span class="comment">#wordlist.shape</span></span><br><span class="line">countlist = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    countlist.append(data[i,<span class="number">0</span>]+<span class="string">': '</span>+str(data[i,<span class="number">1</span>]))</span><br><span class="line">pd.DataFrame(np.array(countlist)[:<span class="number">200</span>].reshape(<span class="number">20</span>,<span class="number">10</span>)).head()</span><br></pre></td></tr></table></figure></p><p>然后选取最靠前的200个词语制出来一张表格，从这个表格里还是可以看出一些信息量的，还是很有趣的。比如毛泽东作为中国近现代史的第一人物，是本书除了邓小平之外绕不开的第二号人物。干部一词也反复出现，在中国这是个非常重要的词语，很多东西都取决于干部之间的博弈和关系。北京作为政治中心和中国的代名词，自然也反复出现，而国家和地区层面，美国，苏联、日本和中国台湾也榜上有名，广东作为非常重要的试验地点，被提及的频率也相当的高。人物上，胡耀邦、陈云、赵紫阳、周恩来也都出现了多次。军队、学生等关键词也出现次数不少。</p><p>除此之外还有年份也引人关注，比如1975、1977、1979、1980、1989等关键节点也都帮上有名。</p><p><img src="http://i4.bvimg.com/640680/f405c02d19042f6b.png" alt="Markdown"></p><h2 id="结果可视化"><a href="#结果可视化" class="headerlink" title="结果可视化"></a>结果可视化</h2><p><strong>除此之外，我还对一些非常重要的关键词画了一些可视化的图，这里选取一些放上来。</strong></p><h3 id="bar-plot"><a href="#bar-plot" class="headerlink" title="bar plot"></a>bar plot</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">namelist = [<span class="string">u'邓小平'</span>,<span class="string">u'中国'</span>,<span class="string">u'毛泽东'</span>,<span class="string">u'工作'</span>,<span class="string">u'干部'</span>,<span class="string">u'问题'</span>,<span class="string">u'北京'</span>,<span class="string">u'美国'</span>,<span class="string">u'领导人'</span>,<span class="string">u'会议'</span>,<span class="string">u'经济'</span>,<span class="string">u'关系'</span>,<span class="string">u'香港'</span>,<span class="string">u'1975'</span>,<span class="string">u'领导'</span>,<span class="string">u'胡耀邦'</span>,<span class="string">u'苏联'</span>,<span class="string">u'政治'</span>,<span class="string">u'支持'</span>,</span><br><span class="line"><span class="string">u'军队'</span>,<span class="string">u'陈云'</span>,<span class="string">u'政策'</span>,<span class="string">u'赵紫阳'</span>,<span class="string">u'周恩'</span>,<span class="string">u'讲话'</span>,<span class="string">u'学生'</span>,<span class="string">u'华国锋'</span>,<span class="string">u'改革'</span>,<span class="string">u'日本'</span>]</span><br><span class="line">index_25 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">11</span>,<span class="number">12</span>,<span class="number">14</span>,<span class="number">16</span>,<span class="number">20</span>,<span class="number">21</span>,<span class="number">23</span>,<span class="number">26</span>,<span class="number">27</span>,<span class="number">28</span>,<span class="number">31</span>,<span class="number">33</span>,<span class="number">37</span>,<span class="number">39</span>,<span class="number">40</span>,<span class="number">42</span>,<span class="number">46</span>,<span class="number">47</span>,<span class="number">48</span>,<span class="number">49</span>]</span><br><span class="line">count = <span class="number">27</span></span><br><span class="line">fig,ax=plt.subplots(<span class="number">1</span>,figsize=(<span class="number">20</span>,<span class="number">10</span>))</span><br><span class="line">ax.bar(range(count),data[index_25,<span class="number">1</span>].astype(<span class="string">'int'</span>),color = <span class="string">'b'</span>)</span><br><span class="line"><span class="comment">#ax.bar(range(count),data[:count,1].astype('int'))</span></span><br><span class="line">ax.set_xticks(range(count))</span><br><span class="line">ax.set_xticklabels(namelist)</span><br><span class="line"><span class="comment">#plt.savefig('tst.png')</span></span><br><span class="line">ax.set_title(str(count)+<span class="string">' key words frequency in book'</span>)</span><br></pre></td></tr></table></figure><p>比如这个显示前二十个关键词的bar plot，可以发现相当有趣的现象，在一本书中的关键词分布竟然也挺像幂率分布，某两三个关键词频次非常高，然后是一堆比较重要的关键词，这个也很有趣。<br><img src="http://i4.bvimg.com/640680/9190c33461d494bd.png" alt="Markdown"></p><h3 id="fluctuation"><a href="#fluctuation" class="headerlink" title="fluctuation"></a>fluctuation</h3><p>接下来我还画了重要词汇再不同章节的变化图。这个的难点是要先获取每一章的起始和结束的位置（不是书本的页码，而是自己分割出来的“单词表”上的位置）<br><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">chapterind = <span class="built_in">np</span>.<span class="built_in">array</span>([<span class="number">16590</span>,  <span class="number">31267</span>,  <span class="number">54053</span>,<span class="number">69769</span>,  <span class="number">90171</span>, <span class="number">104745</span>,<span class="number">121010</span>, <span class="number">138136</span>,  <span class="number">147048</span>,  <span class="number">161724</span>,<span class="number">170963</span>,  <span class="number">193593</span>, <span class="number">206502</span>, <span class="number">214129</span>,<span class="number">230193</span>, </span><br><span class="line">                <span class="number">245828</span>,  <span class="number">260400</span>,<span class="number">285768</span>, <span class="number">303284</span>, <span class="number">324922</span>, <span class="number">337101</span>, <span class="number">349241</span>, <span class="number">362426</span>, <span class="number">377184</span>])-<span class="number">1</span></span><br><span class="line">def count_frequent(chap):</span><br><span class="line">    freqlist =[]</span><br><span class="line">    <span class="keyword">if</span> chap &lt;<span class="number">23</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">27</span>):</span><br><span class="line">            freqlist.<span class="built_in">append</span>(<span class="built_in">np</span>.where(wordlist[chapterind[chap]:chapterind[chap+<span class="number">1</span>]] ==namelist[i])[<span class="number">0</span>].shape[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">27</span>):</span><br><span class="line">            freqlist.<span class="built_in">append</span>(<span class="built_in">np</span>.where(wordlist[chapterind[chap]:] ==namelist[i])[<span class="number">0</span>].shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">return</span> <span class="built_in">np</span>.<span class="built_in">array</span>(freqlist)</span><br><span class="line"></span><br><span class="line">freq_var = <span class="built_in">np</span>.ndarray([<span class="number">24</span>,<span class="number">27</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">24</span>):</span><br><span class="line">    freq_var[i] = count_frequent(i)</span><br><span class="line"></span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">transformed = scaler.fit_transform(freq_var)</span><br><span class="line"></span><br><span class="line">fig,ax=plt.subplots(<span class="number">1</span>,figsize =(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">ax.matshow(transformed.T ,cmap ='jet')</span><br><span class="line">ax.set_title('<span class="number">27</span> <span class="built_in">key</span> words fluctuation <span class="keyword">in</span> <span class="number">24</span> chapters')</span><br><span class="line">ax.set_xticks(<span class="built_in">range</span>(<span class="number">24</span>))</span><br><span class="line">ax.set_yticks(<span class="built_in">range</span>(<span class="number">27</span>))</span><br><span class="line">ax.set_yticklabels(namelist)</span><br></pre></td></tr></table></figure></p><h4 id="heatmap"><a href="#heatmap" class="headerlink" title="heatmap"></a>heatmap</h4><p>经过一番折腾就可以统计出来27个关键词在24章的词频的变化，然后先画了一个<strong>heatmap热力图</strong>，这里为了避免某些关键词，比如邓小平出现频次太多影响到其他关键词的颜色，对每行做了归一化的处理（Minmaxscale）。<br><img src="http://i4.bvimg.com/640680/231ecc794e04d4d7.png" alt="Markdown"></p><p>这个图每一行是一个关键词，每一列是一章。信息量也是蛮大的，比如毛泽东在前面几章出现频次极其的高，后面由于趋势的原因，提的渐渐少了很多，变化相当明显。再比如支持一词，在后面的章节出现很多，可以推理强调邓小平受到他人支持以及支持他人推进改革的次数不少。学生这个关键词在19-21章出现非常多，闭着眼睛也知道这几张在讲什么（政治的潮起潮落、北京之春和天安门事件）。总之用heatmap图的方法也可以粗略地对关键词，尤其是关键词在每章中的变化做一些分析，更加细致的分析可以通过索引回一开始产生的全书词汇找到前后文再仔细看。</p><h4 id="折线图"><a href="#折线图" class="headerlink" title="折线图"></a>折线图</h4><p>接下来又绘制了一个更加直观的折线图，展示不同关键词在不同章节的变化情况，但是由于混杂在一起，可能不如热力图易读。<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(1,figsize =(20,10))</span><br><span class="line">#ax.<span class="keyword">plot</span>(freq_var[:,:10])</span><br><span class="line"><span class="keyword">count</span> =10</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> <span class="keyword">zip</span>(freq_var[:,:<span class="keyword">count</span>].T,namelist[:<span class="keyword">count</span>]):</span><br><span class="line">    plt.<span class="keyword">plot</span>(x,<span class="keyword">label</span> =y)</span><br><span class="line">plt.title(str(<span class="keyword">count</span>)+' key words fluctuation <span class="keyword">in</span> 24 chapters')</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="http://i4.bvimg.com/640680/c79d691ce875618e.png" alt="Markdown"></p><h2 id="进一步分析"><a href="#进一步分析" class="headerlink" title="进一步分析"></a>进一步分析</h2><h3 id="定义关键词之间的关系"><a href="#定义关键词之间的关系" class="headerlink" title="定义关键词之间的关系"></a>定义关键词之间的关系</h3><p>之前做的是一些基本的分析，我又思考了一下，能不能怎样表示一下两个关键词之间的关系呢？因为时间仓促，我也没有查找资料，就自己定义了某种衡量方法：</p><p>想衡量两个关键词的关系，以邓小平和毛泽东为例，他们分别出现了四千多次和两千多次，分布在全书中的各个位置，我想看他们的关系，就是看他们是否会出现的比较近，或者很多时候没有什么关系。于是我考虑去计算两个关键词的“<strong>最近邻距离</strong>”。接下来就是如何定义这个最近邻距离。因为两个关键词的数量不一致，以个数少的作为基准，已经可以知道这个词语在我生成的词汇表的具体位置，因此我分别找到毛泽东出现的两千多个位置，然后搜索每个位置最近的邓小平这个词汇出现的位置，然后获得他们的距离。这样就可以衡量出两个关键词在每个位置的最近距离了。</p><p>虽然听起来这个过程十分的繁琐，需要大量的搜索，但是通过把循环和搜索问题变成矩阵的运算（反正位置都是数字），就可以非常快地计算出任意两个关键词的距离分布了，我给定义成了<strong>calculate_distance</strong>函数。</p><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">def calculate_distance(ind1,ind2):</span><br><span class="line">    <span class="attr">pos1</span> = np.where(<span class="attr">wordlist==namelist[ind1])[0]</span></span><br><span class="line">    <span class="attr">pos2</span> = np.where(<span class="attr">wordlist==namelist[ind2])[0]</span></span><br><span class="line">    num1 ,<span class="attr">num2</span> = pos1.shape[<span class="number">0</span>],pos2.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> num1&gt;num2:</span><br><span class="line">        <span class="attr">small</span> = num2</span><br><span class="line">        <span class="attr">large</span> = num1</span><br><span class="line">        <span class="attr">lararr</span> = pos1</span><br><span class="line">        <span class="attr">smarr</span> = pos2</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="attr">small</span> = num1</span><br><span class="line">        <span class="attr">large</span> = num2</span><br><span class="line">        <span class="attr">lararr</span> = pos2</span><br><span class="line">        <span class="attr">smarr</span> = pos1</span><br><span class="line">    <span class="attr">disarr</span> = np.ndarray([small,large])  <span class="comment">#each line calculate the small set's ith word's and large set's every words distance</span></span><br><span class="line">    <span class="attr">arr1=</span> np.repeat(smarr,large).reshape(-<span class="number">1</span>,large)</span><br><span class="line">    <span class="attr">arr2=</span> np.repeat(lararr,small).reshape(-<span class="number">1</span>,small).T</span><br><span class="line">    <span class="attr">mindis</span> = np.min(np.abs(arr2-arr1),<span class="attr">axis=1)</span></span><br><span class="line">    return mindis</span><br><span class="line"></span><br><span class="line">def draw_dist_count(ind1,ind2):</span><br><span class="line">    fig,<span class="attr">ax=plt.subplots(1,figsize=(20,10))</span></span><br><span class="line">    ax.bar(range(calculate_distance(<span class="number">0</span>,<span class="number">1</span>).shape[<span class="number">0</span>]),calculate_distance(<span class="number">0</span>,<span class="number">1</span>),<span class="attr">color='g')</span></span><br><span class="line">    ax.set_title('Minimum Distance of '+namelist[ind1]+<span class="string">" and "</span>+namelist[ind2])</span><br><span class="line">draw_dist_count(<span class="number">0</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h4><p>这里就拿邓小平和毛泽东两个关键词举例，我按照顺序画了出来，毛泽东出现的两千多次里，每个毛泽东与最近的一个邓小平的位置距离。值越小说明这两个关键词越靠近，要是值为1的话就说明他们挨着（不过对于名词来说一般中间至少隔着一个介词）。<strong>这样就可以看到任意两个关键词的关系随书的文字的紧张的变化情况。</strong></p><p>可以看到700到1400左右，两个词的距离明显较近，说明在这部分文字中，两人发生了更为密切的联系，而500左右的距离有的非常远，说明这部分是各讲各的故事，两个人还没有交集。</p><p><img src="http://i4.bvimg.com/640680/a421383dc7da2619.png" alt="Markdown"></p><p>同样的调用计算距离和绘图的函数，可以查看任意两个关键词的距离并按顺序绘制其值。</p><p>下面一次性展示了同一个关键词和其他好几个关键词的距离图。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(<span class="number">4</span>,<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].bar(range(calculate_distance(<span class="number">0</span>,<span class="number">1</span>+<span class="number">2</span>*i+j)<span class="selector-class">.shape</span>[<span class="number">0</span>]),calculate_distance(<span class="number">0</span>,<span class="number">1</span>+<span class="number">2</span>*i+j))</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].set_title(<span class="string">'Minimum Distance of '</span>+namelist[<span class="number">0</span>]+<span class="string">" and "</span>+namelist[<span class="number">1</span>+<span class="number">2</span>*i+j])</span><br></pre></td></tr></table></figure><p><img src="http://i4.bvimg.com/640680/4414d03a5b228e77.png" alt="Markdown"></p><h4 id="hist-plot"><a href="#hist-plot" class="headerlink" title="hist plot"></a>hist plot</h4><p>接下来还画了一下距离的<strong>分布图</strong>，就是把上面的图中的距离统计一下他们的分布。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig,ax=plt.subplots(<span class="number">4</span>,<span class="number">2</span>,figsize=(<span class="number">20</span>,<span class="number">20</span>))</span><br><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span> <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].hist(calculate_distance(<span class="number">0</span>,<span class="number">1</span>+<span class="number">2</span>*i+j),bins =<span class="number">50</span>,<span class="attribute">color</span>=<span class="string">'b'</span>,alpha=<span class="number">0.4</span>)</span><br><span class="line">        ax[<span class="selector-tag">i</span>,j].set_title(<span class="string">'Minimum Distance of '</span>+namelist[<span class="number">0</span>]+<span class="string">" and "</span>+namelist[<span class="number">1</span>+<span class="number">2</span>*i+j])</span><br></pre></td></tr></table></figure><p><img src="http://i4.bvimg.com/640680/3c6048942654bc2c.png" alt="Markdown"></p><p>这种图感觉就丢失很多信息了，看不出来随着书籍的发展，两个名词的关系的变化。当然如果做得更细致，可以用某些指标刻画一下这种距离图，更好地衡量两个指标的关系，用可视化的方法当然是更直观的。</p><h4 id="boxplot"><a href="#boxplot" class="headerlink" title="boxplot"></a>boxplot</h4><p>最后是<strong>Boxplot</strong>，这是另一种直观显示距离分布的图。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dist_data = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>,<span class="number">20</span>):</span><br><span class="line">    dist_data[i] = calculate_distance(<span class="number">0</span>,i)</span><br><span class="line">dataframe_dxp = pd.concat((pd.DataFrame(&#123;namelist[i]:dist_data[i]&#125;) <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>,<span class="number">20</span>)),axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">100</span>,<span class="number">20</span>))</span><br><span class="line">sns.boxplot(data =dataframe_dxp,ax=ax,boxprops=dict(alpha=<span class="number">.5</span>),color=<span class="string">'g'</span>)</span><br><span class="line">ax.set_title(<span class="string">u'Dengxiaoping and others'</span>,fontsize=<span class="number">80</span>)</span><br><span class="line">ax.set_xticks(range(<span class="number">19</span>))</span><br><span class="line">ax.set_xticklabels(namelist[<span class="number">1</span>:<span class="number">20</span>],fontsize=<span class="number">80</span>)</span><br><span class="line">fig.savefig(<span class="string">'boxplot.png'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="http://i4.bvimg.com/640680/5ef0af735a848eca.png" alt="Markdown"></p><p>可以看到邓小平和好几个关键词的距离的分布，每一个box就是一个分布的统计，当然也和分布图一样，这样一画就<strong>拉平了</strong>不同关键词之间的差异了。</p><p>其实对文本挖掘还有<strong>词性标注、情感分析</strong>等更多方法，包括归纳段落或篇章的主题等等，目前都有很多统计模型和机器学习方法可以做。不过在尝试的过程中，我还是感觉到这只是很基本的辅助方法，更重要的还在于人文历史政治学科的专家们对书籍做仔细的解读，<strong>挖掘历史细节中的关键信息是人最擅长的</strong>，比机器强大的多的地方，不过在卷帙浩繁的历史典籍中，面对成千上万的书籍时，快速挖掘书籍的要点，分析出来一些有趣的东西，也许机器能够帮上大忙。</p><h1 id="附：读后感"><a href="#附：读后感" class="headerlink" title="附：读后感"></a>附：读后感</h1><p>这部分明显能感觉到自己笔触的迟滞和笨重，真的是很久不写这种风格的论文，表达得略显凌乱，也有可能是最近总是熬夜，写的时间也正是脑子乱乱的时候，又没有一个规范约束自己，因此写的相当不守规矩。</p><p>这次读后感分成两个部分，一个是常规的读后感想，另一部分是出于兴趣所做的一些对邓小平时代一书的基本的文本挖掘。</p><p>第一部分是我在读书时的一些感悟，尤其是比较了一些香港版和大陆版的不同之后，也产生了一些感悟。</p><p>经过查询，我发现大陆版正文较港版删节约5.3万字，其中包括“邓小平时代的关键人物”一文约2.6万字。这部分其实还相当有趣，我还专门仔细找了其中提到的几个人物的一些更多的史料，发现能读到很多令人震惊的，被有意掩盖的历史。大陆版的几个大篇幅忽略的内容包括天安门事件、邓小平南巡前后对改革停滞的不满、邓小平子女的腐败传闻等敏感话题并未避而不谈。其实这几部分也不是秘密了，我想有一些想法的民众也都能从各种地方搜集来蛛丝马迹，但是从删节中还是能感觉到一条清晰的审查红线。如果删除的内容更真实、接近历史的真相的话，确实相当让人开阔眼界，比如叶剑英病重，邓小平并未去看望，毛泽东对周恩来的打压讨厌却又离不开，在其死后冷漠的态度。这就很颠覆大家的“被培养起来的观念”，还有比如印象中对陈云和邓小平在经济问题上很好地合作的观念，也被作者纠正：陈云比起邓小平的大刀阔斧，要保守稳健很多，因此产生很多分歧，比如不去广东视察。另一个肯定被删（没有核实）的就是南巡时候的珠海会议，不留情面地批评了有点向往毛泽东的观念的江泽民，甚至威胁要取代他。这种分歧的事情大陆版应该也不会保留的。至于89年的风波，就没有什么可讨论的啦。</p><p>我总感觉，一字之差可能一篇文章意义就全变了，中国人最懂笔义春秋之法，也就格外注意这点。邓小平时代确实披露了很多史料，让中国人有机会了解自己的事情（听起来有点滑稽），但是在搜索的过程中，还是难免注意到，香港版的邓小平时代在好几个网站被列为“大陆禁书”。可想而之其中的一些关键问题，可能被隐去了。为什么会被隐去呢，我想我自己有些体会，当我初中读到上上任领导人的传记中的部分内容，感到一阵阵的震惊、震撼、深思、迷茫和一种成长成熟的不愉悦感的时候，以及日后有意无意读到搜到的各种真假故事的时候，都会隐隐体会到为什么有些历史和真实被隐去了。</p><p>读历史和任务传记，尤其是夹杂在历史洪流中的人物群像时，最让人不适的阅读体验之一就是作者对任务的评价不得不因为篇幅所限而显得相当“专断”，比如“雖然趙紫陽做人和藹可親，但一些同事認為他有點兒不合群，喜歡為自己著想。文革開始時趙紫陽讓他的部下抵抗紅衛兵，可是令部下氣憤的是，趙本人很快就把自己辦公室的鑰匙交給了紅衛兵。”这样的话语，让人很难真正对赵紫阳这样一个略显神秘的人物有更多的了解和判断，读起来还是一团历史的迷雾，当然对历史做价值判断本来就是危险且未必能断得清楚的，而如果能尽可能多得了解到公正的史料，也许就能想的更清楚一点，更全面一点，更多地祛除个人的感情，比如作者就并没有站在自由派的立场上一边倒地吹捧赵紫阳，而是指出了他自私自我的一面，这样的词语可能还是可以甚至有点受到大陆的欢迎的，而相反的，喜欢报复、邪恶狡猾之类很难见到的形容毛泽东的词语当然被删除干净。我相信人是无比复杂的，也绝不是多么高尚的，无私的，一个忘我的奉献一切的无私的人就真的是像神一样的所有人应该努力追逐的样子吗，我觉得不是，要说刨去了物质欲望，无私的奉献、为祖国的奉献、也无非是精神上的享受而已，不同类型的人难以体会另外的人的享受和愉悦的点，把事情渲染地极端又美好真的是件好事吗，需要的时候就圣洁如神明，一旦出事了一个个都不干净，这样的过程一再出现的话，恐怕就得不断填补一个巨大的漏洞，或者封住所有的缺口，封住所有信息的渠道，这样好吗。</p><p>从这里想到的东西绝不是在批评当权者和领导层，而是感到作为自私的利己的人类而言也许会永远存在的现象，我们当然不会承认自己的自私，也都指责别人的自私，在这个过程中有心照不宣也有大声互斥，我想共产党有的时候让世界上的很多人抵触和担忧就在于，一定要极端地宣称某些事情，有的时候大家都心照不宣的事情，可以揭露的事情，一定要坚持极端地说出来，这样未必是好的。然而反过来想，就算允许人们议论，揭短，又有何意义呢，对国家发展、经济增长、人民福利有什么意义呢？一下子也许还有很多负面的例子，也许很多时候我们就是这样安慰自己来进行善意的谎言的过程吧。有的时候一次性揭开历史的各种真相也未必是好事，对大多数人来说会是一个失去信仰的，难以接受的过程，就看美国也不过是借着民主自由人权的外衣干了很多坏事，包括这两天的叙利亚的空袭，为了自己的自私和利益，一套冠冕堂皇的理由好像自己也愿意相信，当然中国不信，中国说自己和平崛起不愿战争的说法，外国也不信，所以我们是否真的要探讨一下，话题开放的尺度究竟在哪里，“见过世面”、书读的多一点的人总是嚷嚷着开放，讲出真相，但是真的好吗，我记得也许是毛泽东曾经说过，知识分子什么都懂，就是不懂两点，吃不饱会饿，打仗会死人，我想书读得多了，很多道理也未必想的清楚，也只有毛泽东邓小平这样的人物，也许才能做一个比较好的决断？也许一个自诩读书万卷的知识分子人类良心真正有机会去管理人民的时候，也会发现这套管理是尽量好的办法？虽然也会有很多问题：我们避免不了伟人的错误，比如邓小平的全面物价改革可能造成的问题，我们避免不了无外部监督的权力带来的严重腐败，但这都源于每个人本身的缺点，虽然中国历史数千年来都因为通行一套文字而拥有巨量的经验，但是看起来还是很难解决好这样的问题。</p><p>本书让我感触颇深的另一点在于英雄人物的复杂性，这两段话让我感触极深：<br>~“基辛格11月訪華後，毛澤東為了與美國打交道，轉而依靠鄧小平這個在對抗蘇聯時十分堅定的人。1973年12月，鄧小平遵照指示參加了政治局批周的會議。無論在法國、在上海做地下工作期間還是1950年代初在北京一起工作時，周恩來就像鄧小平的兄長。但是毛澤東有理由希望鄧小平會和自己而不是周恩來站在一起。鄧小平在1940年代的整風運動中就站在毛澤東的一邊，周恩來卻沒有。自從1931年鄧小平被批為「毛派頭子」後，他就一直緊跟毛澤東，並在1950年代得到了毛的重用。1956年以後鄧小平成了黨的總書記，他和周恩來的關係在黨內事務上有時變得很尷尬：周恩來在黨內排名上高於鄧小平，可是他要向負責黨內日常事務的鄧小平彙報工作和接受指示。[2-82]周恩來在文革期間也沒有保護鄧小平。[2-83]~<br>~鄧小平心裏很清楚，「兩位小姐」會把他在批周會議上的發言彙報給毛主席。會議臨近結束時，鄧小平對周恩來說：「你現在的位置離主席只有一步之遙，別人都是可望而不可即，而你卻是『可望而可即』，希望你自己能夠十分警惕這一點。」[2-84]這些話表面上並不惡毒，卻暗藏殺機。鄧小平實際上是在暗示，周恩來想架空毛澤東，篡奪毛的地位。「兩位小姐」把鄧小平的發言和態度彙報給毛澤東後，毛非常興奮，立刻把鄧小平叫去談話。”~</p><p>我印象很深，小时候喜欢问父亲，这个人是好人还是坏人，父亲总会告诫我，不要用好坏去区分一个人。但是不用好坏去区分总会很头疼，很费脑子，让人很难受。毛泽东这个人的复杂性，很多历史事实和资料都能让人们略知一二，邓小平时代一书让我体会的更加深切，尤其是邓小平文革后期找到机会重新拾起权力阶段的故事，顺带让我了解到周恩来与毛泽东的分歧，而按顺序读起来，总是让人感慨颇深，一会儿对某人充满同情，一会儿又更加深切地感受到人物关系的复杂，让人对这些历史巨人产生了掺杂的混合的情绪，不知道同情谁好，不知道支持谁好，更别说谁是好人谁是坏人。可见评价历史真是件十分难的事情，如果客观地叙述事实，就只是记录罢了，而历史终归要掺入主观的观念，从这点上看，我反而觉得不要删节，让有心的读者多读读更好，为什么要把人维护得如此正面而甚至虚假呢，让人更加深切地体会到人性、人生和历史的复杂，更加谨慎地获取和得到自己的观点，岂不是更好？</p><p>大陆版删除的关键人物一章，读起来相当有意思，虽然在我看来这一章里篇幅所限也并没有很细致的描述，可能是不希望人们太多的关注人物背后的交情以及过多思考人性的复杂，故而这章也被删除了，我觉得其中一些写的不错，包括读到了赵紫阳的个人性格和可能带来的局限性，比如过分自爱，性格较为保守，对于管理经济倒是非常擅长。从很多人物和邓小平的关系看来，邓小平确实在管理人，尤其是管理领袖级人物上非常有一套，虽然不及毛泽东的本事，把开国功臣们掌握得牢牢的，但是也能不需要居于最前方就可以实际掌控大局，我觉得邓小平在很多地方上是借鉴了毛泽东的，而且去除了一些掌控欲，也有可能是由于一代英雄们都已经谢幕，相对掌控起来也更加容易，让邓小平有机会居于稍微靠后的位置，就牢牢掌控着一切局势，而且我感觉他和毛泽东后期一样，在挑人上都有意选择一些并未在权力中心浸染很久的人，比如王洪文、华国锋、赵紫阳和江泽民等等，赵紫阳是他出访尼泊尔路过四川一番交谈最终调到北京，而江泽民，我记得在各处看到，大概是邓小平喜欢春节在上海度过，加上八九年的风波，江泽民处理得很好，就空降到政治局成了领导者。这种选人的风格给邓小平带来了很多主动性，也许也有未来避免在历史上少背点锅的可能也说不好。做实验的过程中，都特别强调试探，邓小平可以多一些试探的余地，更多地观察再做决定，加上自己实际的军队和政治上的掌控权和表面领导人的生疏，可以让自己牢牢地掌管真正的核心决策。我记得江泽民曾经对毛泽东的一套更加喜欢，对市场化的进程感到过快，邓小平于是南下巡防，声称反对改革开放就是反对社会主义，由此压制了另一套想法的滋生。</p><p>但是这种掌管权力的方法也未必是完全好的，想想邓小平其实在一个相当“美好”的历史时期，活到最后的就是胜利者，邓小平73年说自己还能干二十年，结果真的干到十四大退到幕后，这种后发优势熬倒了很多元老，导致在大清洗之后的权力真空期获得了很多权力，恐怕接下来的两任都在某些时间段并不舒服，有很多桎梏，到这一任才有了更加集中的权力。这里面有的时候也可以看出人性的有趣之处。干部在反对个人集权的时候又希望自己能够有更多的权力，当年反对个人集权，是反对毛泽东权力过大，随意分配权力，两位小姐、造反派头头竟然能高过周恩来，反对的是权力危害到了我，而当自己可以有权力的时候，有人会愿意不要吗，恐怕也是很少见的。所以我觉得人们在意的可能更多的是权力能不能更多地为自己所用，以及其他的权力不要危害到自己，最好在一种比较好的平衡中，但是平衡也未必会永远存在，也未必是好事。看起来邓小平用权力的集中做了很多伟大的改革，毛泽东也做出了一系列彪炳千秋的伟业和载入史册的糊涂事，如今权力也更加集中起来，如果思路明晰的话，我觉得权力集中是能够做大事的，否则光是吵吵嚷嚷争论不休就什么都做不了了。只是权力集中虽然有可能带来很多的回报，也有更大的风险，争吵不休而止步不前面临的是缓慢的毁灭，一意孤行地推进则有走向荣光和加速衰败两种更加极端的选择。</p><p>这本书讲了很多改革和开放的故事，看起来是讲述了一个政党的领导人如何自我改革，把自己变得更加兼容并包，在术的层面不断学习进步的过程，但是大胆地一说，总是能感觉到在政治和管理问题上，管理者有极其强烈的控制欲，这当然很重要，必须承认，如果不是这样，也许我们已经几次陷入严重到可以亡国的风险，这种经验教训可能也让共产党更加谨慎小心，让改革开放这个词语显得更加多面性：从西方的角度，我们的所谓改革开放，也就是做到人家常规的程度，甚至都远远不够，而共产党在这个过程中要不断地审视各种局势，更加小心翼翼。我的感觉是，共产党相比于其他政党，更喜欢和强调管教，但是又不是喜欢按照法律管理，而是希望有更大的自由裁定权，记得一位高层曾经说过，法律不要立的太细致，这样才有解释的空间。管制与压抑的原理是什么？这恐怕是很多人心中的无法言说的疑问，不管会乱，有很多例子，所以我们就愿意并满足于上交更多的权利？比如自由获取信息、翻阅墙壁、表达言论的权利。某些做法使人很容易往不好的一面联想，虽然这也许并非管理者与人民的本意，但是实在是与神圣纯洁的宣传所矛盾。</p><p>最近对快手、抖音、内涵段子等的查封，以及其“段友”、“抖友”发展出来的有一定结构的组织，让管理者更加紧绷，很多人说这些地方都是垃圾，价值观歪曲，封的好，但是也有人心中充满了疑问，以及经典的“他们向…发难，而我没有发声，最终他们向我而来，没有人替我说话了”的担忧。管理者的这种一贯的，一刀切的、有点精神洁癖和完美主义者喜欢的掌控感与清净感让人赞许又害怕，让包括我在内的很多人处于矛盾：激动并自豪于中国人的成就、又觉得这来源于中国人传统的吃苦与奋进，又觉得这是对自己大大压抑和压榨的结果，觉得我们并没有跳出某种循环，让人迷茫于很多事情和自己的意义，感慨于人类历史和经验的复杂和不足够：看不清楚究竟什么是正确的路，估计不出来自己和国人和世界所处的情况、条件等等。</p><p>以上已经做了很多带有敏感词的评论，在我看来邓小平无疑是个奇人，尤其是作为开国领袖级人物，在分割明显的76年之后，又在领袖群体凋落的时代支撑并扭转了中国的大势，这是千秋功业，邓小平在73年的时候说出自己还能再干二十年，实在是几代人的幸运。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;期中作业之一是写一篇邓小平时代的读后感，说实话这种书是实在没空读了，虽然粗略地翻了几章，十分吸引人，但是这两年真的越来越讨厌写文科式的论文，瞎胡诌凑字数曾经也是我作为理科生的优势，但是这一两年对这种风格的文章：东拼西凑，无病呻吟，迷茫又自负的写作非常地厌恶。因为就想玩点花样，做点简单的文本数据挖掘凑凑字数，虽然多花了很多时间，但是毕竟很有意思，有意思的事情就不算浪费时间对吧，没有意思的事情，哪怕一分钟也是对生命的浪费呢。&lt;br&gt;
    
    </summary>
    
      <category term="techniques" scheme="http://james20141606.github.io/categories/techniques/"/>
    
      <category term="data science" scheme="http://james20141606.github.io/categories/techniques/data-science/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="data mining" scheme="http://james20141606.github.io/tags/data-mining/"/>
    
      <category term="matplotlib" scheme="http://james20141606.github.io/tags/matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>Extract Countries&#39; Commercial Data</title>
    <link href="http://james20141606.github.io/2018/04/12/economics/"/>
    <id>http://james20141606.github.io/2018/04/12/economics/</id>
    <published>2018-04-12T15:49:57.000Z</published>
    <updated>2018-04-12T16:10:43.156Z</updated>
    
    <content type="html"><![CDATA[<p>It is a brief pipeline to extract data from datasets in <a href="http://139.129.209.66:8000/d/daedafb854/" target="_blank" rel="noopener">here</a></p><p>The work is from my cute girl friend, who know nothing about code but brag to her mentor she can do it.</p><p>In this work, I use R, Bash and Python to extract different countries different indicators in different years. The data have some property: big, not unified(.RData or .csv), some have mistakes. It is very sparse so it waste many storage. And the conversion of Rdata to csv leads some mistakes, so it needs very careful examination and check work. At first I want to store all of them in HDF5 for better IO, but people in my girl friend’s working team are’t familiar with codes, so I store them in csv. I also think about later work(for example, basic statistical work, model the interaction and time series, maybe a hierarchical time series machine learning model), but I am too busy to help my little bragger to do all kinds of things.<br><a id="more"></a><br>Here are codes I wrote to extract and organize data: <a href="https://github.com/james20141606/economics" target="_blank" rel="noopener">https://github.com/james20141606/economics</a></p><h4 id="wget-to-extract-data"><a href="#wget-to-extract-data" class="headerlink" title="wget to extract data"></a>wget to extract data</h4><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">getdata</span><span class="selector-class">.sh</span></span><br></pre></td></tr></table></figure><h4 id="check-row-and-col-names-for-further-extraction"><a href="#check-row-and-col-names-for-further-extraction" class="headerlink" title="check row and col names for further extraction"></a>check row and col names for further extraction</h4><h5 id="before-2001"><a href="#before-2001" class="headerlink" title="before 2001"></a>before 2001</h5><p>use awk to read row and columns in csv, then compare them with std names<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#first</span><br><span class="line">extractnames.sh</span><br><span class="line">#second</span><br><span class="line">refer to codes <span class="keyword">in</span> analyze_dim_name<span class="selector-class">.ipynb</span>:检查<span class="number">1995</span>-<span class="number">2000</span>年的行和列名</span><br><span class="line"><span class="selector-id">#run</span> and check</span><br></pre></td></tr></table></figure></p><p><strong>There are some wrong files, need to examine them later</strong></p><h5 id="after-2001"><a href="#after-2001" class="headerlink" title="after 2001"></a>after 2001</h5><p>Use R to extract row and columns and compare<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-id">#first</span> run Rscript to get row and <span class="attribute">columns</span></span><br><span class="line">run extractrowandcol.R</span><br><span class="line">#second</span><br><span class="line">refer to codes <span class="keyword">in</span> analyze_dim_name<span class="selector-class">.ipynb</span>:<span class="number">2001</span>以后的，用R脚本转出来csv，同样的方式读取并判断</span><br><span class="line"><span class="selector-id">#run</span> and check</span><br></pre></td></tr></table></figure></p><p><strong>All the files have exactly the same structure</strong></p><h2 id="extract-data-concerning-CHINA"><a href="#extract-data-concerning-CHINA" class="headerlink" title="extract data concerning CHINA"></a>extract data concerning CHINA</h2><h3 id="analysis"><a href="#analysis" class="headerlink" title="analysis"></a>analysis</h3><p><strong>The data dimension is: </strong> 1435<em>1435</em>41<br>If use RData to extract some matrix to analyze its row and column names,  the  automatically saved names have mistakes. So we use the previous plot to inspire us and find the true data structure:</p><p><img src="http://i1.bvimg.com/640680/0ba5f17f200bc207.png" alt="Markdown"></p><p>The first big block is <strong>to</strong> the first country(AUS)</p><p>So the column names in first big block are:   X&gt;AUS</p><p>When row and columns names match there are values, so there are only values in diagonal. </p><p><strong>(That’s the main reason the R data file is big: the minimum number is :41<em>41</em>35<em>35, but RData have 1435</em>1435*41, 41 fold redundancy)</strong></p><h3 id="How-to-find-a-country"><a href="#How-to-find-a-country" class="headerlink" title="How to find a country"></a>How to find a country</h3><h4 id="after-2001-1"><a href="#after-2001-1" class="headerlink" title="after 2001"></a>after 2001</h4><p>The data we use is RData, use Rscript to extract data</p><h5 id="to-CHINA"><a href="#to-CHINA" class="headerlink" title="to CHINA"></a>to CHINA</h5><p>Locate the country，<strong>CHN is 7th</strong></p><p><strong>The seventh block are all countries to CHINA</strong><br><strong>dat[,,7]</strong>  the matrix dimension is 1435*1435<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">datt&lt;-dat[,,7]</span><br><span class="line">datt[1<span class="string">+35</span>*(i<span class="string">-1</span>):35*i,1<span class="string">+35</span>*(i<span class="string">-1</span>):35*i]</span><br></pre></td></tr></table></figure></p><p>Use for loop, <strong>use a array:35<em>（35</em>41）</strong> to store<br>save to <strong>tochn.csv</strong><br>Rows:c1-c35<br>Columns: every 35 columns are a same country<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Run extract2001.R</span><br><span class="line"><span class="selector-id">#output</span> <span class="keyword">in</span> out directory</span><br></pre></td></tr></table></figure></p><h5 id="CHINA-to"><a href="#CHINA-to" class="headerlink" title="CHINA to"></a>CHINA to</h5><p><strong>each 1435*1435 block’s seventh mini block is China to another country</strong><br><strong>dat[211:245,211:245,i]</strong><br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Run</span><span class="bash"> extract2001.R</span></span><br></pre></td></tr></table></figure></p><p>Use for loop, <strong>use a array:35<em>（35</em>41）</strong>to store<br><strong>save to chnto.csv</strong></p><p>Rows:c1-c35</p><p>Columns: every 35 columns are a same country</p><h4 id="before-2001-1"><a href="#before-2001-1" class="headerlink" title="before 2001"></a>before 2001</h4><p>There are some exceptions we do not deal with at first</p><p>The data we use only has csv, so use python to extract</p><h5 id="to-CHINA-1"><a href="#to-CHINA-1" class="headerlink" title="to CHINA"></a>to CHINA</h5><p>The principle is similar to after 2001</p><p>But the data is just the transpose: (1435<em>41)</em>1435</p><p><strong>The seventh block are all countries to CHINA</strong></p><p><strong>Run extract1995.py</strong><br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datt = dat[<span class="number">1435</span>*<span class="number">6</span>:<span class="number">1435</span>*<span class="number">7</span>,:]   <span class="number">#143</span>5*<span class="number">1435</span>datt[<span class="number">35</span>*<span class="selector-tag">i</span>:<span class="number">35</span>*(i+<span class="number">1</span>),<span class="number">35</span>*<span class="selector-tag">i</span>:<span class="number">35</span>*(i+<span class="number">1</span>)]  #loop</span><br></pre></td></tr></table></figure></p><p>Use for loop, <strong>use a array:35<em>（35</em>41）</strong>to store<br><strong>save to chnto.csv</strong></p><h5 id="CHINA-to-1"><a href="#CHINA-to-1" class="headerlink" title="CHINA to"></a>CHINA to</h5><p><strong>each 1435*1435 block’ seventh mini block is China to another country</strong><br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dattt =dat[1435*i:1435*(i+1),:]  <span class="comment">#the ith country 1435*1435</span></span><br><span class="line"><span class="section">dattt[35*6:35*(6+1),35*6:35*(6+1)]</span></span><br></pre></td></tr></table></figure></p><p>Save to <strong>chnto.csv</strong></p><h2 id="To-do"><a href="#To-do" class="headerlink" title="To do"></a>To do</h2><h3 id="Exception-dealing"><a href="#Exception-dealing" class="headerlink" title="Exception dealing"></a>Exception dealing</h3><ul><li>[ ] before 2001 there are some files not in standard form, needs more examine to extract. Maybe case by case<h3 id="analyze-data"><a href="#analyze-data" class="headerlink" title="analyze data"></a>analyze data</h3><h4 id="plot-the-change"><a href="#plot-the-change" class="headerlink" title="plot the change,"></a>plot the change,</h4>for example, heat map, line chart, animation …</li></ul><p><img src="http://i1.bvimg.com/640680/0ce616088c435eae.gif" alt="Markdown"></p><h4 id="do-simple-statistics"><a href="#do-simple-statistics" class="headerlink" title="do simple statistics"></a>do simple statistics</h4><h4 id="model-the-change"><a href="#model-the-change" class="headerlink" title="model the change"></a>model the change</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;It is a brief pipeline to extract data from datasets in &lt;a href=&quot;http://139.129.209.66:8000/d/daedafb854/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The work is from my cute girl friend, who know nothing about code but brag to her mentor she can do it.&lt;/p&gt;
&lt;p&gt;In this work, I use R, Bash and Python to extract different countries different indicators in different years. The data have some property: big, not unified(.RData or .csv), some have mistakes. It is very sparse so it waste many storage. And the conversion of Rdata to csv leads some mistakes, so it needs very careful examination and check work. At first I want to store all of them in HDF5 for better IO, but people in my girl friend’s working team are’t familiar with codes, so I store them in csv. I also think about later work(for example, basic statistical work, model the interaction and time series, maybe a hierarchical time series machine learning model), but I am too busy to help my little bragger to do all kinds of things.&lt;br&gt;
    
    </summary>
    
      <category term="interestings" scheme="http://james20141606.github.io/categories/interestings/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="economics" scheme="http://james20141606.github.io/tags/economics/"/>
    
      <category term="girl friend" scheme="http://james20141606.github.io/tags/girl-friend/"/>
    
  </entry>
  
  <entry>
    <title>Setup and Linux</title>
    <link href="http://james20141606.github.io/2018/04/12/setup/"/>
    <id>http://james20141606.github.io/2018/04/12/setup/</id>
    <published>2018-04-12T15:39:17.000Z</published>
    <updated>2018-04-14T17:20:41.471Z</updated>
    
    <content type="html"><![CDATA[<p>分享一点setup和linux的东西，包括使用git，使用支持markdown的笔记软件Bear，Anaconda的一些使用技巧以及jupyter在服务器上的设置。也可以在<a href="https://legacy.gitbook.com/book/lulab/bioinfo-training-2018/details" target="_blank" rel="noopener">这里</a>找到更多分享<br><a id="more"></a></p><h1 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h1><h2 id="版本控制与GitHub管理"><a href="#版本控制与GitHub管理" class="headerlink" title="版本控制与GitHub管理"></a>版本控制与GitHub管理</h2><h3 id="Git简介"><a href="#Git简介" class="headerlink" title="Git简介"></a>Git简介</h3><h4 id="Git是目前世界上最先进的分布式版本控制系统。"><a href="#Git是目前世界上最先进的分布式版本控制系统。" class="headerlink" title="Git是目前世界上最先进的分布式版本控制系统。"></a>Git是目前世界上最先进的分布式版本控制系统。</h4><h5 id="没有版本控制系统会遇到什么困难："><a href="#没有版本控制系统会遇到什么困难：" class="headerlink" title="没有版本控制系统会遇到什么困难："></a>没有版本控制系统会遇到什么困难：</h5><ul><li>版本更新的困难：如果你用Microsoft Word写过长篇大论，那你一定有这样的经历：想删除一个段落，又怕将来想恢复找不回来怎么办？于是只好先把当前文件“另存为”一个新的Word文件，再接着改，改到一定程度，再“另存为”一个新文件，这样一直改下去，最后你的Word文档可能会有几十个不同版本的备份。过了一周，你想找回被删除的文字，但是已经记不清删除前保存在哪个文件里了，只好一个一个文件回去找，非常麻烦。如果是代码的话，来回的更改就更频繁了，如果想找到之前某个版本的代码，很有可能已经被删除了，对于稍微大一点的工程来说可能麻烦就大了。</li><li>合作时的困难：有些部分需要你的合作者帮助写，于是你把文件Copy到U盘里给她（也可能通过Email发送一份给她），然后，你继续修改文件。一段时间后你的合作者把改动后的文件给你，此时，文件的合并就是一件麻烦事了，你要不然得问她一个一个指出她的改动，或者你就要记录自己的改动，和她的文件合并。<br><br></li></ul><p>如果有一个软件，不但能自动帮我记录每次文件的改动，还可以让同事协作编辑，这样就不用自己管理一堆类似的文件了，也不需要把文件传来传去。如果想查看某次改动，只需要在软件里看一眼就可以看到改动的日期和内容，岂不是很方便？</p><h5 id="这就是21世纪的版本控制系统，Git。"><a href="#这就是21世纪的版本控制系统，Git。" class="headerlink" title="这就是21世纪的版本控制系统，Git。"></a>这就是21世纪的版本控制系统，Git。</h5><h4 id="Git诞生"><a href="#Git诞生" class="headerlink" title="Git诞生"></a>Git诞生</h4><p>Git是Linus (Linux之父)花了两周时间用C写的，在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码，Linux反对集中式的，需要联网的版本控制系统，也反对商业版的版本控制系统，于是创造了Git，一个月之内，Linux系统的源码已经由Git管理了。<br>Git迅速成为最流行的分布式版本控制系统，尤其是2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub，这就是程序员最爱的Git和Github的诞生史。</p><h3 id="安装与使用Git"><a href="#安装与使用Git" class="headerlink" title="安装与使用Git"></a>安装与使用Git</h3><h4 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h4><p>只介绍Mac OS系统安装方法</p><ul><li><p>方法一：先安装homebrew，然后通过homebrew安装Git。安装homebrew可查看<a href="http://brew.sh/" target="_blank" rel="noopener">http://brew.sh/</a></p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">brew </span><span class="keyword">install </span>git</span><br></pre></td></tr></table></figure></li><li><p>方法二：<br>第二种方法更简单，也是推荐的方法，就是用Xcode，Xcode集成了Git，不过默认没有安装，在终端输入命令安装command line tools，即可安装git。</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcode-<span class="keyword">select</span> <span class="comment">--install</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="使用git"><a href="#使用git" class="headerlink" title="使用git"></a>使用git</h4><h5 id="创建或使用文件夹作为需要管理的仓库"><a href="#创建或使用文件夹作为需要管理的仓库" class="headerlink" title="创建或使用文件夹作为需要管理的仓库"></a>创建或使用文件夹作为需要管理的仓库</h5><p>在本地建立项目文件夹，或者使用已存在的项目文件夹，如helloworld<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> helloworld</span><br><span class="line">git init <span class="comment">#通过git init命令把这个目录变成Git可以管理的仓库</span></span><br></pre></td></tr></table></figure></p><h5 id="添加或更改文件"><a href="#添加或更改文件" class="headerlink" title="添加或更改文件"></a>添加或更改文件</h5><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi README.md <span class="comment">#创建一个新文件README.md，添加内容并保存</span></span><br><span class="line">git <span class="keyword">add</span><span class="bash"> README.md</span></span><br><span class="line"><span class="bash"><span class="comment">#用命令git add告诉Git，把文件README.md添加到仓库</span></span></span><br><span class="line"><span class="bash"><span class="comment">#如果一次性添加了多个文件，可以使用git add . git会自己判别哪些是新文件。</span></span></span><br></pre></td></tr></table></figure><p>所有的版本控制系统只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，只知道大小的改动，但更改的内容版本控制系统无法知道。</p><h5 id="添加更改信息"><a href="#添加更改信息" class="headerlink" title="添加更改信息"></a>添加更改信息</h5><p>下面可以告诉git你本次更改的内容，如果一次add了多个文件，则所有的文件都会被标注同样的更改信息。比如：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">commit</span> -m <span class="string">"first commit"</span></span><br><span class="line">git <span class="keyword">commit</span> -m <span class="string">"add README.md"</span></span><br></pre></td></tr></table></figure></p><h5 id="上传至GitHub"><a href="#上传至GitHub" class="headerlink" title="上传至GitHub"></a>上传至GitHub</h5><p>首先在github上新建一个repository，如helloworld，你将会看到跳转页面上提示你需要推送到的HTTPS地址<a href="https://github.com/accountname/repositoryname.git" target="_blank" rel="noopener">https://github.com/accountname/repositoryname.git</a><br>接下来使用<br><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git remote <span class="keyword">add</span><span class="bash"> origin https://github.com/accountname/repositoryname.git</span></span><br><span class="line"><span class="bash">git push -u origin master</span></span><br></pre></td></tr></table></figure></p><p>即可把自己的本地仓库推送到github上，速度很快。<br>注意如果第一次把远程地址输入错误，可以用以下命令更正地址<br><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">git </span><span class="string">remote </span><span class="built_in">set-url</span> <span class="string">origin </span><span class="string">https:</span>//<span class="string">github.</span><span class="string">com/</span><span class="string">accountname/</span><span class="string">repositoryname.</span><span class="string">git</span></span><br></pre></td></tr></table></figure></p><h4 id="使用ssh-key-免账户与密码推送方法："><a href="#使用ssh-key-免账户与密码推送方法：" class="headerlink" title="使用ssh key 免账户与密码推送方法："></a>使用ssh key 免账户与密码推送方法：</h4><h5 id="在终端输入"><a href="#在终端输入" class="headerlink" title="在终端输入"></a>在终端输入</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git<span class="built_in"> config </span>--global user.name <span class="string">"yourgithubname"</span></span><br><span class="line">git<span class="built_in"> config </span>--global user.email <span class="string">"yourgithubaccountmail"</span></span><br></pre></td></tr></table></figure><h5 id="生成ssh-key"><a href="#生成ssh-key" class="headerlink" title="生成ssh key"></a>生成ssh key</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ssh-keygen</span></span><br></pre></td></tr></table></figure><p>生成的密钥在~/.ssh/id_rsa.pub位置。</p><h5 id="配置git-的ssh-key"><a href="#配置git-的ssh-key" class="headerlink" title="配置git 的ssh key"></a>配置git 的ssh key</h5><ul><li>登录github 点击头像选择settings</li><li>选择左侧菜单SSH and GPG keys ；点击右上角的NEW SSH key</li><li>新建ssh 链接。</li><li>title 可随意填写</li><li>Key 将上一步生成的 id_rsa.pub文件 的内容全部复制到此处</li></ul><p>参考链接：<br><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">Git教程</a><br><a href="http://blog.csdn.net/u012373815/article/details/53575362" target="_blank" rel="noopener">SSH连接GitHub、GitHub配置ssh key</a><br><a href="https://peerj.com/preprints/3159/" target="_blank" rel="noopener">version control</a></p><h2 id="支持markdown的轻量笔记软件-Bear"><a href="#支持markdown的轻量笔记软件-Bear" class="headerlink" title="支持markdown的轻量笔记软件 Bear"></a>支持markdown的轻量笔记软件 Bear</h2><p>推荐一款Mac下的非常好用额轻量级笔记软件Bear</p><h5 id="它的优点包括："><a href="#它的优点包括：" class="headerlink" title="它的优点包括："></a>它的优点包括：</h5><ul><li>轻量级，非常顺滑，无任何延迟</li><li>快捷键/markdown支持，符合程序员思维</li><li>加粗，下划线，项目列举，待办方块，代码块，多级标题，均有键盘快捷键以及markdown格式下的快捷键</li><li>网页链接、文件可拖拽至笔记，并显示内容概要。</li><li>内容可无缝衔接至gitbook等支持markdown格式的场合。（比如这些tips都可以直接在Bear编辑好，复制粘贴来就可以。）</li><li>可以快速通过# 加入标签，对笔记进行分类</li></ul><h1 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h1><h5 id="Edited-by-19’-Under-Xupeng-Chen"><a href="#Edited-by-19’-Under-Xupeng-Chen" class="headerlink" title="Edited by 19’ Under Xupeng Chen"></a>Edited by 19’ Under Xupeng Chen</h5><h2 id="Conda-amp-Bioconda"><a href="#Conda-amp-Bioconda" class="headerlink" title="Conda &amp; Bioconda"></a>Conda &amp; Bioconda</h2><p>Conda是一个包管理软件，可以帮助方便地下载各种软件而不需要编译。尤其是Bioconda可以用来管理linux系统上的生信相关的软件，是解决安装权限不够的问题的好工具。</p><h3 id="Conda"><a href="#Conda" class="headerlink" title="Conda"></a>Conda</h3><p>conda是一个包，依赖和环境管理工具，适用于多种语言，如: Python, R, Scala, Java, Javascript, C/ C++, FORTRAN</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>Anaconda安装可以去官方下载，但是强烈推荐使用tuna镜像，免流量，而且速度极快。<br><a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">下载地址</a>，下载.sh文件后运行，按照提示一步一步往下运行即可。<br>下载Anaconda后，很多python的常用库都会被自动安装好，另外建议运行以下命令</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --<span class="built_in">add</span> channels http<span class="variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="keyword">cn</span>/anaconda/pkgs/free/</span><br><span class="line">conda config --<span class="built_in">add</span> channels http<span class="variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="keyword">cn</span>/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="keyword">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>这样以后使用conda install packages命令下载需要的包的时候，会自动从tuna镜像下载，速度会非常快。</p><h3 id="Bioconda"><a href="#Bioconda" class="headerlink" title="Bioconda"></a>Bioconda</h3><p>Bioconda是conda上一个分发生物信息软件的频道，使用它的最大好处是，你不用自己编译软件了。<br>Conda tuna 安装 conda设置 从tuna下载免流量，快<br>目前Bioconda有超过130个添加、更新和维护生物信息软件的贡献者，他们为这个频道发布了1500多个软件包。总结起来，bioconda有以下几个特点：</p><ul><li>软件是编译好的，无需自己编译</li><li>跨平台，支持Linux和Mac OS（本身conda还支持Windows）</li><li>支持多种语言，Python/Perl/R/Java/Go等</li><li>兼容多种语言的包管理器，如pip，CRAN，CPAN，Bioconductor，apt-get以及 homebrew<br>针对Python来说，使用conda相比pip的很大优势，就是不用自己编译。安装软件最头疼的问题，就是解决编译报错，很多时候忙活一天就为了把一个软件装好。</li></ul><h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><p>先添加Bioconda频道</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda<span class="built_in"> config </span>--<span class="builtin-name">add</span> channels defaults</span><br><span class="line">conda<span class="built_in"> config </span>--<span class="builtin-name">add</span> channels conda-forge</span><br><span class="line">conda<span class="built_in"> config </span>--<span class="builtin-name">add</span> channels bioconda</span><br></pre></td></tr></table></figure><p>然后即可用conda安装各种需要的软件，可以先去bioconda channel看看自己需要的软件在不在列表内。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="keyword">install </span><span class="keyword">bowtie</span></span><br><span class="line"><span class="keyword">conda </span>create -n myenv <span class="keyword">bwa </span><span class="keyword">bowtie </span>hisat star <span class="comment">#a new environment can be created</span></span><br><span class="line">source activate myenv <span class="comment">#activate the environment</span></span><br></pre></td></tr></table></figure><p>参考资料：<br><a href="https://bioconda.github.io/" target="_blank" rel="noopener">Using Bioconda — Bioconda documentation</a><br><a href="https://bioconda.github.io/recipes.html" target="_blank" rel="noopener">packages list</a></p><h2 id="在服务器上运行jupyter-notebook并在本地浏览器使用"><a href="#在服务器上运行jupyter-notebook并在本地浏览器使用" class="headerlink" title="在服务器上运行jupyter notebook并在本地浏览器使用"></a>在服务器上运行jupyter notebook并在本地浏览器使用</h2><p>Jupyter Notebook是基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写（markdown）、运行代码和展示结果。</p><ul><li><p>jupyter适合课题的早期尝试、绘图等非常便利，代码重复运行和复制粘贴方便，方便反复调试，尤其适合尚未工程化，需要大量尝试的阶段。</p></li><li><p>jupyter非常适合教学，交互效果非常好，github上有大量的教学项目是用jupyter notebook展示的，方便查看结果，查看相关说明、公式，方便学习者进行反复实验。</p></li></ul><h4 id="本地设置服务器信息"><a href="#本地设置服务器信息" class="headerlink" title="本地设置服务器信息"></a>本地设置服务器信息</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi .ssh/config</span><br><span class="line">Host ibme</span><br><span class="line">HostName 166.111.152.116 #ibme的ip</span><br><span class="line">ControlPersist <span class="literal">yes</span></span><br><span class="line">ControlMaster auto</span><br><span class="line">User chenxupeng</span><br><span class="line">DynamicForward 127.0.0.1:32987 #最后的port（如32987）要自己设置，不能与他人冲突</span><br></pre></td></tr></table></figure><h4 id="使用SwitchOmega在本地浏览器设置代理"><a href="#使用SwitchOmega在本地浏览器设置代理" class="headerlink" title="使用SwitchOmega在本地浏览器设置代理"></a>使用SwitchOmega在本地浏览器设置代理</h4><h5 id="添加情景模式，如ibme"><a href="#添加情景模式，如ibme" class="headerlink" title="添加情景模式，如ibme"></a>添加情景模式，如ibme</h5><p>代理协议SOCKS5，代理服务器127.0.0.1，代理端口填写自己设置的port。</p><h5 id="在auto-switch页面添加规则"><a href="#在auto-switch页面添加规则" class="headerlink" title="在auto switch页面添加规则"></a>在auto switch页面添加规则</h5><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">172<span class="selector-class">.235</span><span class="selector-class">.0</span>.*，192<span class="selector-class">.235</span><span class="selector-class">.0</span>.*，<span class="selector-tag">node50</span>*等，情景模式选择<span class="selector-tag">ibme</span></span><br></pre></td></tr></table></figure><p>点击应用选项</p><h5 id="在服务器上设置start-jupyter文件"><a href="#在服务器上设置start-jupyter文件" class="headerlink" title="在服务器上设置start-jupyter文件"></a>在服务器上设置start-jupyter文件</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi ~/bin/start-jupyter</span><br><span class="line">填写：</span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">bsub &lt;&lt;EOF</span><br><span class="line"><span class="comment">#BSUB -J jupyter</span></span><br><span class="line"><span class="comment">#BSUB -R span[hosts=1]</span></span><br><span class="line"><span class="comment">#BSUB -q Z-LU</span></span><br><span class="line"><span class="built_in">cd</span></span><br><span class="line">jupyter notebook --no-browser --ip=0.0.0.0 --port=10087 <span class="comment">#port自己设置一个，不要冲突</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>(也可以使用#BSUB -q Z-BNODE)</p><h4 id="start-jupyter"><a href="#start-jupyter" class="headerlink" title="start jupyter"></a>start jupyter</h4><p>首先start-jupyter启动，会自动提交一个任务到某个节点</p><h5 id="使用节点名称连接"><a href="#使用节点名称连接" class="headerlink" title="使用节点名称连接"></a>使用节点名称连接</h5><p>接下来可以用bjobs看到jupyter被提交到了哪个节点。接下来打开本地浏览器，输入</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node5<span class="number">0</span>*<span class="symbol">:port</span> <span class="comment">#如node504/10087</span></span><br></pre></td></tr></table></figure><p>若使用Z-BNODE，可在浏览器填写</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">zbnode01</span><span class="selector-class">.cluster</span><span class="selector-class">.com</span><span class="selector-pseudo">:port</span></span><br></pre></td></tr></table></figure><h5 id="使用ip连接"><a href="#使用ip连接" class="headerlink" title="使用ip连接"></a>使用ip连接</h5><p>用nslookup获得节点的ip，在本地浏览器输入：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ip</span><span class="selector-pseudo">:port</span> #如192<span class="selector-class">.235</span><span class="selector-class">.5</span><span class="selector-class">.48</span><span class="selector-pseudo">:10087</span></span><br><span class="line">#获得<span class="selector-tag">ip</span>方法</span><br><span class="line"><span class="selector-tag">nslookup</span> <span class="selector-tag">node504</span><span class="selector-class">.cluster</span><span class="selector-class">.com</span></span><br><span class="line"><span class="selector-tag">nslookup</span> <span class="selector-tag">zbnode01</span><span class="selector-class">.cluster</span><span class="selector-class">.com</span></span><br></pre></td></tr></table></figure><p>第一次登陆需要密码，用bpeek查看任务输出，即可看到token，复制至浏览器即可使用jupyter notebook进行编程了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分享一点setup和linux的东西，包括使用git，使用支持markdown的笔记软件Bear，Anaconda的一些使用技巧以及jupyter在服务器上的设置。也可以在&lt;a href=&quot;https://legacy.gitbook.com/book/lulab/bioinfo-training-2018/details&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;找到更多分享&lt;br&gt;
    
    </summary>
    
      <category term="techniques" scheme="http://james20141606.github.io/categories/techniques/"/>
    
      <category term="linux" scheme="http://james20141606.github.io/categories/techniques/linux/"/>
    
    
      <category term="techniques" scheme="http://james20141606.github.io/tags/techniques/"/>
    
      <category term="bioinformatics" scheme="http://james20141606.github.io/tags/bioinformatics/"/>
    
  </entry>
  
  <entry>
    <title>eMaize_Tutorial</title>
    <link href="http://james20141606.github.io/2018/04/12/emaize-tutorial/"/>
    <id>http://james20141606.github.io/2018/04/12/emaize-tutorial/</id>
    <published>2018-04-12T15:30:17.000Z</published>
    <updated>2018-04-16T12:30:23.114Z</updated>
    
    <content type="html"><![CDATA[<p>这是为实验室写的，借由eMaize问题帮助大家简单了解机器学习基本方法和基础代码的教程。也可以在<a href="https://lulab.gitbooks.io/bioinfo/content/5%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B4%E5%90%88----%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/51.html" target="_blank" rel="noopener">这里</a>看到</p><p>由于jupyter notebook的强大的展示功能，本教程还用jupyter notebook组织且运行，可以获得更好的学习效果，代码在<a href="https://github.com/james20141606/somethingmore/blob/master/bioinfo.ipynb" target="_blank" rel="noopener">这里</a>,欢迎取用。<a href="http://localhost:4000/2018/04/12/setup/" target="_blank" rel="noopener">在这里</a>我简单介绍了如何配置jupyter，在<a href="https://james20141606.github.io/2018/04/10/Deep-Learning-Practice/">Deep Learning tutorial</a>中我也强烈推荐了jupyter，并且介绍了很多基于jupyter的资源，强烈建议尝试一下。<br><a id="more"></a></p><h2 id="0-背景简介"><a href="#0-背景简介" class="headerlink" title="0.背景简介"></a>0.背景简介</h2><p>该通过基因型预测表型的实例来自<a href="http://emaize.imaze.org" target="_blank" rel="noopener">eMaize challenge</a>:<br>eMaize问题要求我们以SNP作为特征，通过训练一个模型，对玉米的三个性状进行预测。<br>接下来的教程会展示从原始数据开始，如何对数据进行转换，存取，特征选择以及回归和后续分析的整个过程。本问题最基本的目标是使用6210个样本中的前4754个样本作为训练集，预测其他样本的性状<br></p><h2 id="I-上机指南"><a href="#I-上机指南" class="headerlink" title="I.上机指南"></a>I.上机指南</h2><p>本任务依赖于python语言及jupyter notebook，所需工具已安装到虚拟机。以下指南的所有代码均可在4.Emaize/jupyter_notebook/basic_tutorial.ipynb 中找到。</p><p>使用方法：</p><ul><li><p>打开终端，进入Bioinfo_Lab/4.Emaize/ 文件夹</p></li><li><p>输入jupyter notebook，等待弹出窗口，或者手动复制粘贴终端显示的网址到浏览器。</p></li><li><p>点击jupyter_notebook,再点击basic_tutorial.ipynb,即可看到本部分的教程。按照相关指南一步一步运行即可。本部分接下来的内容与basic_tutorial.ipynb中的内容一致。</p></li></ul><h4 id="jupyter-notebook基本使用指南："><a href="#jupyter-notebook基本使用指南：" class="headerlink" title="jupyter notebook基本使用指南："></a>jupyter notebook基本使用指南：</h4><p>本教程使用jupyter notebook，可以让使用者获得更好的体验，方便对代码进行修改，以及对结果进行查看和分析</p><ul><li>一段相关的代码在同一个代码框中书写 <br></li><li>同时按住shift与enter即可运行选中的代码框的代码<br></li><li>仅仅按enter键具有回车的效果</li><li><h5 id="使用上方的编辑栏："><a href="#使用上方的编辑栏：" class="headerlink" title="使用上方的编辑栏："></a>使用上方的编辑栏：</h5>点击加号在两个代码框中间插入新的代码框，删除代码框点击剪刀，中止程序点击方框</li></ul><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#导入必需的库</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">from sklearn.random_projection <span class="keyword">import</span> SparseRandomProjection</span><br><span class="line">from scipy.sparse <span class="keyword">import</span> load_npz, save_npz</span><br><span class="line"><span class="keyword">import</span> scipy.stats</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> h5py</span><br><span class="line">from sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">from scipy.stats.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">from sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">#<span class="keyword">import</span> xgboost</span><br><span class="line">#from xgboost.sklearn <span class="keyword">import</span> XGBRegressor</span><br><span class="line">from sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">from sklearn.kernel_ridge <span class="keyword">import</span> KernelRidge</span><br><span class="line">from sklearn <span class="keyword">import</span> neighbors</span><br><span class="line">from sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">from sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessRegressor</span><br><span class="line">from sklearn.gaussian_process.kernels <span class="keyword">import</span> DotProduct</span><br><span class="line">from tqdm <span class="keyword">import</span> tqdm_notebook <span class="keyword">as</span> tqdm</span><br><span class="line">from IPython.display <span class="keyword">import</span> display, Image</span><br><span class="line">%pylab inline</span><br></pre></td></tr></table></figure><h3 id="1-查看原始数据"><a href="#1-查看原始数据" class="headerlink" title="1.查看原始数据"></a>1.查看原始数据</h3><h4 id="1-1-数据种类"><a href="#1-1-数据种类" class="headerlink" title="1.1 数据种类"></a>1.1 数据种类</h4><ul><li>genotype：SNP数据，每个位点可能有三种情况，如AA，AT，TT <br></li><li>trait：共三种，trait1开花期，trait2株高，trait3产量，为连续值 <br></li><li>原始数据中有6210个样本，每个样本SNP位点约为190万个,<br>因为计算资源的原因，这里仅仅选取其中的5000个SNP作为示例,因为数据量的原因，结果肯定不够理想</li></ul><h4 id="1-2-数据格式"><a href="#1-2-数据格式" class="headerlink" title="1.2 数据格式"></a>1.2 数据格式</h4><p>txt存储格式不适合大数据读取的问题，对内存的占用过多。对于结构化的、能够存储为矩阵的数据，可以使用HDF5格式存取，内存占用小，读取速度快</p><h5 id="读取SNP数据"><a href="#读取SNP数据" class="headerlink" title="读取SNP数据"></a>读取SNP数据</h5><p>数据格式为HDF5</p><h5 id="在命令行查看数据shape"><a href="#在命令行查看数据shape" class="headerlink" title="在命令行查看数据shape"></a>在命令行查看数据shape</h5><p>方法为：</p><ul><li>cd至文件路径下，输入：h5ls snp_5000 <br></li><li>若使用了新版h5py，可能出现无法打开的情况，此时输入HDF5_USE_FILE_LOCKING=FALSE h5ls snp_5000</li></ul><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">#使用h5py读取5000个SNP：</span></span><br><span class="line">with h5py.File('data/snp_5000') as f:</span><br><span class="line">snps = f[<span class="string">'snp'</span>][<span class="symbol">:</span>]</span><br><span class="line"><span class="section">#查看数据shape,h5py读取出的snps是一个矩阵，可以用.shape查看其shape</span></span><br><span class="line">snps.shape</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看数据内容</span></span><br><span class="line">snps</span><br></pre></td></tr></table></figure><h5 id="读取性状数据"><a href="#读取性状数据" class="headerlink" title="读取性状数据"></a>读取性状数据</h5><p>使用numpy/pandas均可读取性状数据并显示，这里用pandas展示，真正计算时一般用numpy</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">traits</span> = pd.read_csv(<span class="string">'data/pheno_emaize.txt'</span>,delimiter=<span class="string">'\t'</span>)</span><br><span class="line"><span class="comment">#仅显示前五个,4754之后的样本的性状是未知的</span></span><br><span class="line">traits.head()</span><br></pre></td></tr></table></figure><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#pandas dataframe也可查看<span class="built_in">shape</span></span><br><span class="line"><span class="built_in">print</span> traits.<span class="built_in">shape</span></span><br></pre></td></tr></table></figure><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#查看性状的分布情况</span><br><span class="line">trait1 = np.array(traits[<span class="string">'trait1'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait2 = np.array(traits[<span class="string">'trait2'</span>])[:<span class="number">4754</span>]</span><br><span class="line">trait3 = np.array(traits[<span class="string">'trait3'</span>])[:<span class="number">4754</span>]</span><br><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">ax[<span class="number">0</span>].hist(trait1,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'normalized trait1 value distribution'</span>)</span><br><span class="line">ax[<span class="number">1</span>].hist(trait2,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'normalized trait2 value distribution'</span>)</span><br><span class="line">ax[<span class="number">2</span>].hist(trait3,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title(<span class="string">'normalized trait3 value distribution'</span>)</span><br></pre></td></tr></table></figure><p><img src="http://i1.bvimg.com/640680/30af897795c31338.png" alt="Markdown"></p><h5 id="查看训练集与测试集的划分"><a href="#查看训练集与测试集的划分" class="headerlink" title="查看训练集与测试集的划分"></a>查看训练集与测试集的划分</h5><p>下图中彩色部分为训练集性状，白色部分为待预测性状 <br><br>可以发现其划分方式并不随机，这会导致常规的机器学习方法出现一些问题，由于是基础介绍，这里不讨论如何解决这个问题。</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def generate_parent_table(phenotype_file):</span><br><span class="line">phenotypes = pd.read_table(phenotype_file)</span><br><span class="line">pedigree = phenotypes[<span class="string">'pedigree'</span>].str.split(<span class="string">'_'</span>, expand=<span class="symbol">True</span>)</span><br><span class="line">pedigree.columns = [<span class="string">'f'</span>, <span class="string">'X'</span>, <span class="string">'m'</span>]</span><br><span class="line">phenotypes = pd.concat([phenotypes, pedigree], axis=<span class="number">1</span>)</span><br><span class="line">phenotypes[<span class="string">'number'</span>] = np.arange(phenotypes.shape[<span class="number">0</span>])</span><br><span class="line">parent_table = phenotypes.pivot_table(values=<span class="string">'number'</span>, index=[<span class="string">'m'</span>], columns=[<span class="string">'f'</span>], dropna=<span class="symbol">False</span>)</span><br><span class="line">male_ids = [<span class="string">'m%d'</span> <span class="comment">% i for i in range(1, parent_table.shape[0] + 1)]</span></span><br><span class="line">female_ids = [<span class="string">'f%d'</span> <span class="comment">% i for i in range(1, parent_table.shape[1] + 1)]</span></span><br><span class="line">parent_table = parent_table.loc[male_ids, female_ids]</span><br><span class="line">return parent_table</span><br><span class="line">phenotype_file = <span class="string">'data/pheno_emaize.txt'</span></span><br><span class="line">parent_table = generate_parent_table(phenotype_file)</span><br><span class="line">phenotypes = pd.read_table(<span class="string">'data/pheno_emaize.txt'</span>)</span><br><span class="line">fig, ax = subplots(<span class="number">3</span>,<span class="number">1</span>, figsize=(<span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">for i in range(<span class="number">3</span>):</span><br><span class="line">trait = [<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>][i]</span><br><span class="line">ax[i].matshow(np.take(np.ravel(phenotypes[trait].values), parent_table), cmap=cm.<span class="symbol">RdBu</span>)</span><br><span class="line">ax[i].set_title(<span class="string">'Phenotypes of training data (%s)'</span><span class="comment">%trait)</span></span><br></pre></td></tr></table></figure><h3 id="2-将SNP数据编码为向量"><a href="#2-将SNP数据编码为向量" class="headerlink" title="2. 将SNP数据编码为向量"></a>2. 将SNP数据编码为向量</h3><p>每个位点的碱基只有三种情况，不会出现更多碱基组合的可能，比如某位点仅有AA，AT，TT三种可能的情况<br><br>我们可以采取三种方式对其编码：</p><ul><li>转化为0、1、2。找到minor allele frequency（MAF），即两种碱基（如A、T）中出现频率低的那个，以A作为MAF为例，则TT为0，AT为1，AA为2，这样可以突出MAF</li><li>转化为3-bit one hot vector,$[1,0,0]^T,[0,1,0]^T,[0,0,1]^T$这样可以保持三种向量在空间距离的一致</li><li>转化为2-bit vector,则AA，AT，TT分别编为$[1,0]^T,[1,1]^T,[0,1]^T$,不需要考虑MAF<br>我们采取第三种方式<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def convert_2bit(seq):</span><br><span class="line">genotypes = np.zeros([6210,2])</span><br><span class="line">a = seq[1].split('/')</span><br><span class="line">for i in range(6210):</span><br><span class="line">if seq[<span class="string">4:</span>][<span class="symbol">i</span>] == a[0] + a[0]:</span><br><span class="line">genotypes[i] = np.array([0,1])</span><br><span class="line">if seq[<span class="string">4:</span>][<span class="symbol">i</span>] == a[0] + a[1]:</span><br><span class="line">genotypes[i] = np.array([1,0])</span><br><span class="line">if seq[<span class="string">4:</span>][<span class="symbol">i</span>] == a[1] + a[1]:</span><br><span class="line">genotypes[i] = np.array([1,1])</span><br><span class="line">genotypes = genotypes.astype('int').T</span><br><span class="line">return genotypes</span><br></pre></td></tr></table></figure></li></ul><p><strong>注意，接下来的步骤耗时14min</strong><br>真实计算时此步骤使用C加速计算，这里为了连贯性仅仅展示python的方法 <br><br>可以跳过接下来的代码框步骤，直接使用处理好的结果，结果放在 /data/2bit_geno<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#该代码框可跳过以节约时间，直接运行下一个代码框</span></span><br><span class="line">geno_conv = convert_2bit(snps[1])</span><br><span class="line">for i in tqdm(range(4999)):</span><br><span class="line">geno_conv = np.concatenate((geno_conv,convert_2bit(snps[i+2])),axis =0)</span><br></pre></td></tr></table></figure></p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">#读取处理成2bit格式的SNP</span></span><br><span class="line">with h5py.File('data/2bit_geno') as f:</span><br><span class="line">geno_conv = f[<span class="string">'data'</span>][<span class="symbol">:</span>]</span><br></pre></td></tr></table></figure><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看SNP的大致情况</span></span><br><span class="line">fig, <span class="attr">ax</span> = plt.subplots(<span class="attr">figsize=(5,10))</span></span><br><span class="line">ax.matshow(geno_conv[:<span class="number">300</span>,:<span class="number">200</span>],<span class="attr">cmap</span> = cm.binary_r)</span><br></pre></td></tr></table></figure><h3 id="3-特征提取与降维"><a href="#3-特征提取与降维" class="headerlink" title="3. 特征提取与降维"></a>3. 特征提取与降维</h3><ul><li>原数据每个样本有190万个SNP，转化为2bit coding后有大约380万个feature，大多数的feature可能是冗余的 <br></li><li>过多的feature使得机器学习模型无法承受，一个考虑时间开销及效果的feature数量应该在几千至几万量级 <br></li></ul><h4 id="特征选择："><a href="#特征选择：" class="headerlink" title="特征选择："></a>特征选择：</h4><p>特征选择的方法包括filter，wrapper和embedding三大类 <br><br>我们使用过如下方法： <br></p><ul><li>Mutual information:劣势在于需要将连续的性状值离散化，损失信息<br></li><li>ANOVA:通过p-value筛选feature，速度较慢，我们设计了加速ANOVA计算的算法。<br></li><li>基于模型的方法:基于广义线性模型或其他带有feature权重的机器学习模型，根据权重挑选feature<br></li></ul><h4 id="降维："><a href="#降维：" class="headerlink" title="降维："></a>降维：</h4><ul><li>PCA、SVD：劣势在于降维后的feature数量不能超过样本数量，一次性损失的feature过多<br></li><li>Random projection:基于LSH的降维方式，速度较快<br></li></ul><p>通过对问题的后续分析，我们发现对于预测绝大多数样本，基本的降维方法就已经够用<br><br>但是对于部分很难预测的样本，简单的特征选择方法也无法取得好的效果<br><br>我们根据后续开发的针对性的模型，设计了基于模型的特征选择方法，因为内容限制，不在这里使用。</p><p><strong>接下来分别使用ANOVA和Random projection演示特征选择和降维，对于后续的计算来说，选择其中一种就可以，也可以把不同的方法拼起来使用</strong></p><p><strong>我们会提供ANOVA、Random projection处理上面5000个snps后的数据，以及在完整数据集上用Random projection降维至10000个feature的数据。用于送入下一部分的回归模型。下面的三种方法的处理后的数据可以在feature_selection文件夹下找到，存储格式为HDF5，可用h5py打开</strong></p><h5 id="ANOVA数据："><a href="#ANOVA数据：" class="headerlink" title="ANOVA数据："></a>ANOVA数据：</h5><p>feature_selection/anova 包含三个性状各自的feature，大小为4000*6210</p><h5 id="Random-projection-5000-数据："><a href="#Random-projection-5000-数据：" class="headerlink" title="Random projection(5000)数据："></a>Random projection(5000)数据：</h5><p>feature_selection/randomproj_5000 从5000个SNPs降维得到，三个性状使用同一组feature,大小为1000*6210</p><h5 id="Random-projection-whole-SNPs-数据："><a href="#Random-projection-whole-SNPs-数据：" class="headerlink" title="Random projection(whole SNPs)数据："></a>Random projection(whole SNPs)数据：</h5><p>feature_selection/randomproj_whole 从所有SNPs降维得到，三个性状使用同一组feature，大小为10000*6210</p><h4 id="3-1-ANOVA"><a href="#3-1-ANOVA" class="headerlink" title="3.1 ANOVA"></a>3.1 ANOVA</h4><p>方差分析方法可以利用p值挑选feature <br><br>调用scipy.stats.f_oneway,利用SNPs和性状可以很容易地计算出p-value，但是对于大量数据来说速度较慢 <br><br>这里我们使用一种加速ANOVA计算的方法完成计算，相比于scipy.stats的方法可以提升计算速度数百倍。<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加速ANOVA算法</span></span><br><span class="line">def fast_anova_2bit(X, y):</span><br><span class="line">y = y - y.mean()</span><br><span class="line">y2 = y*y</span><br><span class="line">N = X.shape[0]</span><br><span class="line">SS_tot = np.sum(y2)</span><br><span class="line"><span class="comment"># 10, 01, 11</span></span><br><span class="line">masks = [np.logical_and(X[:, 0::2], np.logical_not(X[:, 1::2])),</span><br><span class="line"><span class="section">np.logical_and(np.logical_not(X[:, 0::2]), X[:, 1::2]),</span></span><br><span class="line"><span class="section">np.logical_and(X[:, 0::2], X[:, 1::2])]</span></span><br><span class="line">Ni = np.concatenate([np.sum(mask, axis=0) for mask in masks]).reshape((3, -1))</span><br><span class="line">at_least_one = Ni &gt; 0</span><br><span class="line">SS_bn = [np.sum(y.reshape((-1, 1))*mask, axis=0) for mask in masks]</span><br><span class="line">SS_bn = np.concatenate(SS_bn).reshape((3, -1))</span><br><span class="line">SS_bn **= 2</span><br><span class="line">SS_bn = np.where(at_least_one, SS_bn/Ni, 0)</span><br><span class="line">SS_bn = np.sum(SS_bn, axis=0)</span><br><span class="line">SS_wn = SS_tot - SS_bn</span><br><span class="line">M = np.sum(at_least_one, axis=0)</span><br><span class="line">DF_bn = M - 1</span><br><span class="line">DF_wn = N - M</span><br><span class="line">SS_bn /= DF_bn</span><br><span class="line">SS_wn /= DF_wn</span><br><span class="line">F = SS_bn/SS_wn</span><br><span class="line">p_vals = np.ones(F.shape[0])</span><br><span class="line">ind = np.nonzero(M == 2)[0]</span><br><span class="line">if ind.shape[0] &gt; 0:</span><br><span class="line">p_vals[ind] = scipy.stats.f.sf(F[ind], 1, N - 2)</span><br><span class="line">ind = np.nonzero(M == 3)[0]</span><br><span class="line">if ind.shape[0] &gt; 0:</span><br><span class="line">p_vals[ind] = scipy.stats.f.sf(F[ind], 2, N - 3)</span><br><span class="line">return F, p_vals</span><br></pre></td></tr></table></figure></p><p><strong>注意X和y分别是什么</strong><br>我们需要输入进 fast_anova_2bit(X, y)的X是处理过的SNPs中前4754个样本的，y是trait1、trait2、trait3<br>因为需要分别预测三个性状，我们需要针对三个性状分别挑选特征</p><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">geno_conv_train = geno_conv[:,:<span class="number">4754</span>]</span><br><span class="line">geno_conv_test = geno_conv[:,<span class="number">4754</span>:]</span><br><span class="line"><span class="built_in">print</span> geno_conv_train.<span class="built_in">shape</span></span><br><span class="line"><span class="built_in">print</span> geno_conv_test.<span class="built_in">shape</span></span><br></pre></td></tr></table></figure><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#分别计算三种性状下<span class="number">5000</span>个SNPs做完ANOVA的p-value</span><br><span class="line"><span class="built_in">F,</span>pval_1 = fast_anov<span class="built_in">a_2bit</span>(geno_conv_train.T,trait1)</span><br><span class="line"><span class="built_in">F,</span>pval_2 = fast_anov<span class="built_in">a_2bit</span>(geno_conv_train.T,trait2)</span><br><span class="line"><span class="built_in">F,</span>pval_3 = fast_anov<span class="built_in">a_2bit</span>(geno_conv_train.T,trait3)</span><br><span class="line">pval_1.shape</span><br></pre></td></tr></table></figure><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">1</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">3</span>))</span><br><span class="line">ax[<span class="number">0</span>].hist(pval_1,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title('<span class="number">5000</span> SNPs p-value for trait1 distribution')</span><br><span class="line">ax[<span class="number">1</span>].hist(pval_2,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title('<span class="number">5000</span> SNPs p-value for trait2 distribution')</span><br><span class="line">ax[<span class="number">2</span>].hist(pval_3,bins = <span class="number">50</span>)</span><br><span class="line">ax[<span class="number">2</span>].set_title('<span class="number">5000</span> SNPs p-value for trait3 distribution')</span><br></pre></td></tr></table></figure><p><img src="http://i1.bvimg.com/640680/b8b10e4aac94c22f.png" alt="Markdown"><br>可以设定一个阈值，比如留下p-value前百分之四十的SNPs,根据index选取留下的SNPs<br><figure class="highlight cos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">threshold1 = np.percentile(pval_1,<span class="number">40</span>)</span><br><span class="line">threshold2 = np.percentile(pval_2,<span class="number">40</span>)</span><br><span class="line">threshold3 = np.percentile(pval_3,<span class="number">40</span>)</span><br><span class="line"><span class="keyword">print</span> 'threshold1: <span class="built_in">%f</span>' <span class="built_in">%threshold</span>1</span><br><span class="line"><span class="keyword">print</span> 'threshold2: <span class="built_in">%f</span>' <span class="built_in">%threshold</span>2</span><br><span class="line"><span class="keyword">print</span> 'threshold3: <span class="built_in">%f</span>' <span class="built_in">%threshold</span>3</span><br></pre></td></tr></table></figure></p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#返回符合条件的p-value的坐标，即可找到需要留下的SNPs的位置，注意每个SNPs占据两行</span></span><br><span class="line"><span class="attr">anova_index_1</span> = np.where(pval_1&lt;threshold1)[<span class="number">0</span>]</span><br><span class="line"><span class="attr">anova_index_1</span> = np.sort(np.concatenate((anova_index_1,anova_index_1 +<span class="number">1</span>)))</span><br><span class="line"><span class="attr">anova_index_2</span> = np.where(pval_2&lt;threshold2)[<span class="number">0</span>]</span><br><span class="line"><span class="attr">anova_index_2</span> = np.sort(np.concatenate((anova_index_2,anova_index_2 +<span class="number">1</span>)))</span><br><span class="line"><span class="attr">anova_index_3</span> = np.where(pval_3&lt;threshold3)[<span class="number">0</span>]</span><br><span class="line"><span class="attr">anova_index_3</span> = np.sort(np.concatenate((anova_index_3,anova_index_3 +<span class="number">1</span>)))</span><br></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#根据p-value选取保留的SNPs，注意这一步要在所有的6210个样本上做</span></span><br><span class="line"><span class="attr">feature1_anova</span> = np.take(geno_conv,anova_index_1,axis=<span class="number">0</span>)</span><br><span class="line"><span class="attr">feature2_anova</span> = np.take(geno_conv,anova_index_2,axis=<span class="number">0</span>)</span><br><span class="line"><span class="attr">feature3_anova</span> = np.take(geno_conv,anova_index_3,axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h4 id="3-2-Random-projection"><a href="#3-2-Random-projection" class="headerlink" title="3.2 Random projection"></a>3.2 Random projection</h4><p>Random projection 不依赖于性状，仅仅在原SNPs数据进行降维 <br><br>Random projection可以使用scikit-learn下的sklearn.random_projection模块计算 <br><br>包括generate，transform和normalize等步骤 <br><br>这里演示从5000个feature（10000行）降维</p><h5 id="3-2-1-generate"><a href="#3-2-1-generate" class="headerlink" title="3.2.1 generate"></a>3.2.1 generate</h5><p>产生一个稀疏矩阵</p><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#<span class="number">10000</span>为操作前的feature个数：<span class="number">2</span>*<span class="number">5000</span></span><br><span class="line">X = np.zeros((<span class="number">2</span>, <span class="number">10000</span>))</span><br><span class="line">#确定降维后的个数，这里定为<span class="number">1000</span>，使用sklearn random_projection 模块下的 SparseRandomProjection 函数</span><br><span class="line">proj = SparseRandomProjection(<span class="number">1000</span>)</span><br><span class="line">proj.fit(X)</span><br><span class="line">print proj.components_.shape</span><br></pre></td></tr></table></figure><h5 id="3-2-2-transform"><a href="#3-2-2-transform" class="headerlink" title="3.2.2 transform"></a>3.2.2 transform</h5><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">X</span>= geno_conv.T</span><br><span class="line"><span class="attr">X_</span> = proj.transform(X)</span><br></pre></td></tr></table></figure><h5 id="3-2-3-normalize"><a href="#3-2-3-normalize" class="headerlink" title="3.2.3 normalize"></a>3.2.3 normalize</h5><p>对每个feature进行normalize，避免出现过大的值<br><figure class="highlight capnproto"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">normalized_feeature = StandardScaler().fit_transform(X_).T</span><br></pre></td></tr></table></figure></p><p>最终大小为1000*6210，结果在feature_selection/randomproj_5000</p><h3 id="4-回归模型"><a href="#4-回归模型" class="headerlink" title="4. 回归模型"></a>4. 回归模型</h3><p>这部分通过几个常用的机器学习模型对上一部处理过的feature进行拟合和预测<br>这里使用sklearn和xgboost提供的模块，这些模块具有很好的封装，使用风格统一，使用时可以查看其官方文档<br><br>这里不介绍具体的机器学习模型的算法原理，可以参考周志华老师的《机器学习》等书进行学习。</p><h4 id="4-1-机器学习模型"><a href="#4-1-机器学习模型" class="headerlink" title="4.1 机器学习模型"></a>4.1 机器学习模型</h4><p>接下来会使用一些常用的可以用于回归的机器学习模型，可以选择其中的一种或几种对feature_selection/文件夹下的三种数据进行回归和预测。下面我们将几个模型列出，并且选择其中的一种作为示例，其他的模型可同理调用。 <br></p><h4 id="4-2-评价指标"><a href="#4-2-评价指标" class="headerlink" title="4.2 评价指标"></a>4.2 评价指标</h4><p>我们使用<script type="math/tex">r^2,pcc</script>作为衡量预测结果的指标</p><p>$r^2 = 1-\frac{SS<em>{res}}{SS</em>{tot}}$</p><p>$pcc = \frac{cov(X,Y)}{\sigma_X \sigma_Y} = \frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y} $</p><p>我们可以绘制结果的heatmap图，散点图等进行可视化。</p><h4 id="4-3-交叉验证"><a href="#4-3-交叉验证" class="headerlink" title="4.3 交叉验证"></a>4.3 交叉验证</h4><p>交叉验证(Cross validation)可以帮助调参，寻找机器学习模型中的超参数 <br><br>一般可以使用10折或者5折交叉验证，注意在最终预测时，使用调参后的模型在整个训练集上训练，这时不再交叉验证 <br><br>因为交叉验证需要额外增加计算时间，因此这里只在整个训练集上训练一次，不再展示交叉验证的过程。</p><p><strong>如果深究的话，本问题还有其特殊性，可以设计特殊的交叉验证方式</strong><br>不同的样本具有关联性CV，有的样本可能来自同一亲本，而且训练集和测试集的划分并不是随机的<br>因此在真正解决这个问题的时候，需要考虑不同的抽样方式下的调参与训练，我们可以使用下图所示的几种抽样方式<br><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="function"><span class="keyword">method</span> <span class="title">in</span> <span class="params">(<span class="string">'random'</span>, <span class="string">'by_female'</span>, <span class="string">'by_male'</span>, <span class="string">'cross'</span>)</span>:</span></span><br><span class="line"><span class="keyword">with</span> h5py.File(<span class="string">'data/cv_index.%s'</span>%<span class="function"><span class="keyword">method</span>, '<span class="title">r</span>') <span class="title">as</span> <span class="title">f</span>:</span></span><br><span class="line">index_train = f[<span class="string">'0/train'</span>][:]</span><br><span class="line">index_test = f[<span class="string">'0/test'</span>][:]</span><br><span class="line">fig, ax = subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line">sampling_table = np.zeros(np.prod(parent_table.shape))</span><br><span class="line">sampling_table[index_train] = <span class="number">1</span></span><br><span class="line">sampling_table = np.take(sampling_table, parent_table)</span><br><span class="line">ax[<span class="number">0</span>].matshow(sampling_table, cmap=cm.Greys)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Training samples (%s)'</span>%<span class="function"><span class="keyword">method</span>)</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">sampling_table</span> = <span class="title">np</span>.<span class="title">zeros</span><span class="params">(np.prod(parent_table.shape)</span>)</span></span><br><span class="line"><span class="function"><span class="title">sampling_table</span>[<span class="title">index_test</span>] = 1</span></span><br><span class="line"><span class="function"><span class="title">sampling_table</span> = <span class="title">np</span>.<span class="title">take</span><span class="params">(sampling_table, parent_table)</span></span></span><br><span class="line"><span class="function"><span class="title">ax</span>[1].<span class="title">matshow</span><span class="params">(sampling_table, cmap=cm.Greys)</span></span></span><br><span class="line"><span class="function"><span class="title">ax</span>[1].<span class="title">set_title</span><span class="params">(<span class="string">'Test samples (%s)'</span>%<span class="keyword">method</span>)</span></span></span><br><span class="line"><span class="function"><span class="title">plt</span>.<span class="title">tight_layout</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure></p><p><img src="http://i1.bvimg.com/640680/53ed95bc3fc879c9.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/3a9fec1a694dc533.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/f9198785ddd4e809.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/18e028db8839992e.png" alt="Markdown"></p><h4 id="4-4-准备数据"><a href="#4-4-准备数据" class="headerlink" title="4.4 准备数据"></a>4.4 准备数据</h4><p>sklearn的机器学习模型一般需要提供X和y以供模型训练，然后提供新的X，模型就可以预测新的y <br><br>通过前面的工作，我们获得了三种不同的X(ANOVA、random projection(5000/whole))，我们还需要将X和y划分为训练集和测试集 <br><br>注意我们需要分别对三个性状进行预测，因此ANOVA的X是三种 <br><br><strong>评价模型的时候要注意，y_true的部分值缺失</strong></p><h5 id="4-4-1-准备y"><a href="#4-4-1-准备y" class="headerlink" title="4.4.1 准备y"></a>4.4.1 准备y</h5><p>先处理y，y 的train和test是统一的，不受方法影响<br><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">#y 的train和test的统一的，不受方法影响</span></span><br><span class="line">pheno<span class="emphasis">_whole = pd.read_</span>csv('data/emaize<span class="emphasis">_pheno_</span>whole',delimiter=',')</span><br><span class="line">wholepheno = &#123;&#125;</span><br><span class="line">for trait in ['trait1','trait2','trait3']:</span><br><span class="line">wholepheno[trait] = np.array(pheno_whole[trait])</span><br><span class="line">y_train = &#123;&#125;</span><br><span class="line">y_test = &#123;&#125;</span><br><span class="line">for trait in ['trait1','trait2','trait3']:</span><br><span class="line">y_train[<span class="string">trait</span>] = wholepheno[<span class="string">trait</span>][<span class="symbol">:4754</span>]</span><br><span class="line">y_test[<span class="string">trait</span>] = wholepheno[<span class="string">trait</span>][<span class="symbol">4754:</span>]</span><br></pre></td></tr></table></figure></p><h5 id="4-4-2-准备X"><a href="#4-4-2-准备X" class="headerlink" title="4.4.2 准备X"></a>4.4.2 准备X</h5><p>再处理X，使用ANOVA时X要区分不同性状，Random projection由于是与性状无关的降维方法，三种性状下的feature都一样 <br><br>因为机器学习模型要求一般数据形式为sample*feature，因此需要对结果转置<br><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def prepare_data(method):</span><br><span class="line">if method == 'randomproj_5000':</span><br><span class="line">with h5py.File('feature<span class="emphasis">_selection/randomproj_</span>5000') as f:</span><br><span class="line">X_train = f[<span class="string">'data'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test = f[<span class="string">'data'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">if method == 'randomproj_whole':</span><br><span class="line">with h5py.File('feature<span class="emphasis">_selection/randomproj_</span>whole') as f:</span><br><span class="line">X_train = f[<span class="string">'X'</span>][<span class="symbol">:</span>][<span class="string">:4754,:</span>]</span><br><span class="line">X_test = f[<span class="string">'X'</span>][<span class="symbol">:</span>][<span class="string">4754:,:</span>]</span><br><span class="line">if method == 'anova':</span><br><span class="line">X_train = &#123;&#125;</span><br><span class="line">X_test = &#123;&#125;</span><br><span class="line">with h5py.File('feature_selection/anova') as f:</span><br><span class="line">X_train[<span class="string">'trait1'</span>] = f[<span class="string">'feature1'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test[<span class="string">'trait1'</span>] = f[<span class="string">'feature1'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">X_train[<span class="string">'trait2'</span>] = f[<span class="string">'feature2'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test[<span class="string">'trait2'</span>] = f[<span class="string">'feature2'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">X_train[<span class="string">'trait3'</span>] = f[<span class="string">'feature3'</span>][<span class="symbol">:</span>][<span class="string">:,:4754</span>].T</span><br><span class="line">X_test[<span class="string">'trait3'</span>] = f[<span class="string">'feature3'</span>][<span class="symbol">:</span>][<span class="string">:,4754:</span>].T</span><br><span class="line">return X<span class="emphasis">_train,X_</span>test</span><br></pre></td></tr></table></figure></p><p>选择三种方法之一作为X,注意ANOVA方法返回的X需要指明性状</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#查看anova方法的X_train X_test</span><br><span class="line">X_train, X_test = prepare_data(<span class="string">'anova'</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'anova method X_train shape: %s'</span> %(X_train[<span class="string">'trait1'</span>].shape,)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'anova method X_test shape: %s'</span> %(X_test[<span class="string">'trait1'</span>].shape,)</span><br></pre></td></tr></table></figure><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#查看<span class="built_in">random</span> projection方法的X_train X_test</span><br><span class="line">X_train, X_test = prepare_data('randomproj_5000')</span><br><span class="line"><span class="built_in">print</span> '<span class="built_in">random</span> projection <span class="built_in">method</span> X_train shape: <span class="built_in">%s</span>' <span class="symbol">%</span>(X_train.shape,)</span><br><span class="line"><span class="built_in">print</span> '<span class="built_in">random</span> projection <span class="built_in">method</span> X_test shape: <span class="built_in">%s</span>' <span class="symbol">%</span>(X_test.shape,)</span><br></pre></td></tr></table></figure><h4 id="4-5-选择需要的机器学习模型"><a href="#4-5-选择需要的机器学习模型" class="headerlink" title="4.5 选择需要的机器学习模型"></a>4.5 选择需要的机器学习模型</h4><p>接下来会提供多种机器学习模型，并且讲解其使用方法，可以选择自己喜欢的模型进行回归，也可以用sklearn或其他package提供的模型<br>模型包括：</p><ul><li>lr: Linear regression</li><li>ridge: Ridge regression</li><li>kr: Kernel Ridge regression</li><li>rfr: Random Forest regression</li><li>xgbr: XGBoost regression</li><li>knr: K-nearest neigbour regression</li><li>gpr: Gaussian Process regression<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def Model(model):</span><br><span class="line"><span class="keyword">if</span> <span class="attr">model=='lr':</span></span><br><span class="line"><span class="attr">reg</span> = LinearRegression()</span><br><span class="line"><span class="comment">#elif model=='xgbr':</span></span><br><span class="line"><span class="comment"># reg = XGBRegressor()</span></span><br><span class="line">elif <span class="attr">model=='ridge':</span></span><br><span class="line"><span class="attr">reg</span> = Ridge()</span><br><span class="line">elif <span class="attr">model=='kr':</span></span><br><span class="line"><span class="attr">reg</span> = KernelRidge(<span class="attr">alpha</span> = <span class="number">10000</span>, <span class="attr">kernel</span> = 'polynomial',<span class="attr">degree</span> = <span class="number">3</span>)</span><br><span class="line">elif <span class="attr">model=='knr':</span></span><br><span class="line"><span class="attr">reg</span> = neighbors.KNeighborsRegressor(<span class="attr">n_neighbors=4,</span> <span class="attr">algorithm='brute')</span></span><br><span class="line">elif <span class="attr">model=='rfr':</span></span><br><span class="line"><span class="attr">reg</span> = RandomForestRegressor(<span class="attr">n_estimators=10,</span> <span class="attr">criterion='mse',</span> <span class="attr">max_depth=12,</span> <span class="attr">n_jobs=5)</span></span><br><span class="line">elif <span class="attr">model=='gpr':</span></span><br><span class="line"><span class="attr">kernel</span> = <span class="number">1.0</span> * DotProduct(<span class="attr">sigma_0=1.0)**4</span></span><br><span class="line"><span class="attr">reg</span> = GaussianProcessRegressor(<span class="attr">kernel</span> = kernel, <span class="attr">optimizer=None)</span></span><br><span class="line">return reg</span><br></pre></td></tr></table></figure></li></ul><p>接下来可以使用三种特征（X）中的一种以及七种方法中的一种进行训练和预测 <br><br>这里我们以randomproj_5000作为特征，用Ridge作为回归模型演示 <br><br>如果用anova得到的feature，需要注意不同性状的feature不一样 <br></p><h5 id="某个机器学习模型的使用方法如下：reg-fit-X-y-用于拟合，reg-predict-X-用于预测。更多用法可以参考sklearn官方文档"><a href="#某个机器学习模型的使用方法如下：reg-fit-X-y-用于拟合，reg-predict-X-用于预测。更多用法可以参考sklearn官方文档" class="headerlink" title="某个机器学习模型的使用方法如下：reg.fit(X,y)用于拟合，reg.predict(X)用于预测。更多用法可以参考sklearn官方文档"></a>某个机器学习模型的使用方法如下：reg.fit(X,y)用于拟合，reg.predict(X)用于预测。更多用法可以参考sklearn官方文档</h5><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test = prepare_data(<span class="string">'randomproj_whole'</span>)</span><br><span class="line">reg = Model(<span class="string">'gpr'</span>)</span><br><span class="line">y_predict = &#123;&#125;</span><br><span class="line">y_predict_train = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> <span class="class"><span class="keyword">trait</span> <span class="title">in</span> <span class="title">tqdm</span></span>([<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>]):</span><br><span class="line">reg.fit(X_train,y_train[<span class="class"><span class="keyword">trait</span>])</span></span><br><span class="line">y_predict[<span class="class"><span class="keyword">trait</span>] = <span class="title">reg</span>.<span class="title">predict</span></span>(X_test)</span><br><span class="line">y_predict_train[<span class="class"><span class="keyword">trait</span>] = <span class="title">reg</span>.<span class="title">predict</span></span>(X_train)</span><br><span class="line"></span><br><span class="line">X_test.shape</span><br></pre></td></tr></table></figure><p>计算预测结果与真实值的<script type="math/tex">r^2,pcc</script><br><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">test_nonan = np.where(np.isnan(np.array(pheno_whole[<span class="string">'trait1'</span>])[<span class="number">4754</span>:]) ==<span class="number">0</span>)</span><br><span class="line">pcc_train = &#123;&#125;</span><br><span class="line">pcc_test = &#123;&#125;</span><br><span class="line">r2_train = &#123;&#125;</span><br><span class="line">r2_test = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> <span class="class"><span class="keyword">trait</span> <span class="title">in</span> ['<span class="title">trait1</span>',<span class="type">'trait2'</span>,<span class="type">'trait3']:</span></span></span><br><span class="line">pcc_test[<span class="class"><span class="keyword">trait</span>] = <span class="title">pearsonr</span></span>(y_predict[<span class="class"><span class="keyword">trait</span>][<span class="title">test_nonan</span>],<span class="type">np.array</span></span>(pheno_whole[<span class="class"><span class="keyword">trait</span>])[4754:<span class="type">][test_nonan])</span></span></span><br><span class="line">pcc_train[<span class="class"><span class="keyword">trait</span>] = <span class="title">pearsonr</span></span>(y_predict_train[<span class="class"><span class="keyword">trait</span>],<span class="type">y_train[trait])</span></span></span><br><span class="line">r2_test[<span class="class"><span class="keyword">trait</span>] = <span class="title">r2_score</span></span>(y_predict[<span class="class"><span class="keyword">trait</span>][<span class="title">test_nonan</span>],<span class="type">np.array</span></span>(pheno_whole[<span class="class"><span class="keyword">trait</span>])[4754:<span class="type">][test_nonan])</span></span></span><br><span class="line">r2_train[<span class="class"><span class="keyword">trait</span>] = <span class="title">r2_score</span></span>(y_predict_train[<span class="class"><span class="keyword">trait</span>],<span class="type">y_train[trait])</span></span></span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcc_test</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pcc_train</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_test</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r2_train</span><br></pre></td></tr></table></figure><p>可以看到预测结果并不是很好，在测试集上的pcc只有0.5左右。后续的分析可以发现，这是因为样本之间具有相关性导致的<br><br>具体的原因分析比较复杂，简单来说，因为这组测试集与训练集的样本的亲本之间亲缘关系较远，模型难以从SNPs得到的feature推断出亲本信息，导致预测结果较差。</p><p>绘制heatmap图观察预测结果 <br><br>GPR具有很强的拟合能力，总可以在训练集上得到接近1的PCC<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">2</span>,<span class="number">3</span>, figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line">for i in range(<span class="number">3</span>):</span><br><span class="line">traits = [<span class="string">'trait1'</span>,<span class="string">'trait2'</span>,<span class="string">'trait3'</span>]</span><br><span class="line">ax[<span class="number">0</span>,i].scatter(y_predict[traits[i]][test_nonan],np.array(pheno_whole[traits[i]])[<span class="number">4754</span>:][test_nonan])</span><br><span class="line">ax[<span class="number">0</span>,i].set_title(<span class="string">'%s test set predict &amp; true value plot'</span> <span class="comment">%traits[i])</span></span><br><span class="line">line1 = [(<span class="number">-4</span>, <span class="number">-4</span>), (<span class="number">4</span>, <span class="number">4</span>)]</span><br><span class="line">(line1_xs, line1_ys) = zip(*line1)</span><br><span class="line">ax[<span class="number">0</span>,i].add_line(<span class="symbol">Line2D</span>(line1_xs, line1_ys, linewidth=<span class="number">1</span>, color=<span class="string">'red'</span>))</span><br><span class="line">ax[<span class="number">0</span>,i].set_xlim(left=<span class="number">-4</span>, right=<span class="number">4</span>)</span><br><span class="line">ax[<span class="number">0</span>,i].set_ylim(bottom=<span class="number">-4</span>, top=<span class="number">4</span>)</span><br><span class="line">ax[<span class="number">1</span>,i].scatter(y_predict_train[traits[i]],y_train[traits[i]])</span><br><span class="line">ax[<span class="number">1</span>,i].set_title(<span class="string">'%s train set predict &amp; true value plot'</span> <span class="comment">%traits[i])</span></span><br><span class="line">ax[<span class="number">1</span>,i].add_line(<span class="symbol">Line2D</span>(line1_xs, line1_ys, linewidth=<span class="number">1</span>, color=<span class="string">'red'</span>))</span><br><span class="line">ax[<span class="number">1</span>,i].set_xlim(left=<span class="number">-4</span>, right=<span class="number">4</span>)</span><br><span class="line">ax[<span class="number">1</span>,i].set_ylim(bottom=<span class="number">-4</span>, top=<span class="number">4</span>)</span><br></pre></td></tr></table></figure></p><p><img src="http://i1.bvimg.com/640680/dc071479d62b84c7.png" alt="Markdown"></p><p>绘制完整真实值与预测值的heatmap图 <br><br>从图中我们可以清晰地看出一个基本的模型的问题： <br><br>模型强烈地依赖已有信息进行预测，当未知样本的父本与已知训练集的亲缘关系较远时，模型只能依赖母本（横坐标）进行预测 <br><br>导致预测的heatmap图有明显的与母本相关的特征，而实际上子代的性状更容易被父本主导 <br></p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">wholepre = np.concatenate((y_predict[<span class="string">'trait1'</span>],y_predict[<span class="string">'trait2'</span>],y_predict[<span class="string">'trait3'</span>])).reshape(<span class="number">3</span>,<span class="number">-1</span>)</span><br><span class="line">predictions = pd.DataFrame(wholepre.T)</span><br><span class="line">predictions.columns = [<span class="string">'trait1'</span>, <span class="string">'trait2'</span>, <span class="string">'trait3'</span>]</span><br><span class="line">predictions = predictions.set_index(np.arange(<span class="number">4754</span>,<span class="number">6210</span>))</span><br><span class="line">def normalize_phenotype(x, range_pheno=<span class="number">4.0</span>):</span><br><span class="line"><span class="keyword">return</span> (np.clip(x, -range_pheno, range_pheno) + range_pheno)/<span class="number">2.0</span>/range_pheno</span><br><span class="line"><span class="keyword">for</span> <span class="class"><span class="keyword">trait</span> <span class="title">in</span> <span class="title">traits</span>:<span class="type"></span></span></span><br><span class="line">fig, ax = subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line">ax[<span class="number">0</span>].matshow(np.take(np.ravel(normalize_phenotype(pheno_whole[<span class="class"><span class="keyword">trait</span>].<span class="title">values</span>)), <span class="type">parent_table)</span>, <span class="type">cmap=cm.RdBu_r)</span></span></span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">'Phenotypes of whole true data (%s)'</span>%<span class="class"><span class="keyword">trait</span>)</span></span><br><span class="line"></span><br><span class="line">trait_pred = np.full(phenotypes.shape[<span class="number">0</span>], np.nan)</span><br><span class="line">trait_pred[predictions.index.tolist()] = normalize_phenotype(predictions[<span class="class"><span class="keyword">trait</span>].<span class="title">values</span>)</span></span><br><span class="line">ax[<span class="number">1</span>].matshow(np.take(trait_pred, parent_table), cmap=cm.RdBu)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">'Prediction on test data (%s 1)'</span>%traits)</span><br></pre></td></tr></table></figure><p><img src="http://i1.bvimg.com/640680/b514a9c8b7cc7943.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/bbe789a8598188da.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/19a5441ffb4534eb.png" alt="Markdown"></p><h3 id="后续分析"><a href="#后续分析" class="headerlink" title="后续分析"></a>后续分析</h3><h4 id="不同样本具有不同的预测难度"><a href="#不同样本具有不同的预测难度" class="headerlink" title="不同样本具有不同的预测难度"></a>不同样本具有不同的预测难度</h4><p>普通的机器学习模型在测试集上表现结果不好，但是通过多次的十字交叉抽样模拟，可以发现不同样本的预测难度不同，在大多数样本上，不需要专门设计的机器学习模型就足够表现很好</p><h4 id="样本之间具有关联性"><a href="#样本之间具有关联性" class="headerlink" title="样本之间具有关联性"></a>样本之间具有关联性</h4><p>不服从一些基本的假设，比如线性模型下，残差并不是独立的，需要考虑问题的特殊性进行额外的设计。<br><br>由于存储空间和计算时间的限制，无法展示其他有效的方法，有兴趣的同学可以查找育种领域的其他模型进行尝试。</p><h4 id="复杂的机器学习模型并不一定有效"><a href="#复杂的机器学习模型并不一定有效" class="headerlink" title="复杂的机器学习模型并不一定有效"></a>复杂的机器学习模型并不一定有效</h4><p>育种领域目前最好的模型依然是线性模型，通过特殊的设计，可以考虑到亲缘关系、显著相关的SNP(causal)以及随机效应部分<br>而寻找合适的feature是预测结果好坏的决定性因素，至今没有非常好的方法。</p><p>我们通过模拟特殊的十字交叉抽样方式发现，虽然测试集的样本不好预测，但是大多数的样本使用简单的机器学习方法就可以在大多数样本上取得较好的结果 <br><br>由于计算资源限制，下面直接展示模拟结果</p><p>我们使用一种特殊的十字交叉抽样，在训练集上抽样1000次，用来测试基本的机器学习模型结果 <br><br>我们使用了2bit coding编码的SNPs,通过random projection降维至80000 <br><br>然后使用Gaussian Process Regression作为回归模型 <br><br><img src="http://i1.bvimg.com/640680/839f4f607631b772.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/4c1eb79af4bbb5fb.png" alt="Markdown"><br>可以看到一千次抽样的测试结果，大多数测试的PCC都比较高</p><p><img src="http://i1.bvimg.com/640680/bea286d0f130d044.png" alt="Markdown"><br>按照样本查看每个样本多次抽样的平均PCC，注意这里是有bias没有消除的<br><img src="http://i1.bvimg.com/640680/17df0a3dcaa71ada.png" alt="Markdown"></p><p>这里绘制了每个样本的平均PCC heatmap图像,可以发现大多数的样本是很好预测的，样本性状基本由父本性状主导(纵坐标为父本),但是少数亲缘关系较远的父本（图中蓝色线）就很难预测。<br><img src="http://i1.bvimg.com/640680/50adb2cb87536a3d.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/48ee63cf0c78d296.png" alt="Markdown"><br><img src="http://i1.bvimg.com/640680/d3bb77a76c162d53.png" alt="Markdown"></p><p>不同父本的性状有显著差别，而子代的性状由于设计原因，主要由父本控制。<br><br>我们可以通过绘图查看不同父本的性状的变化<br><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">male_index = np.ndarray([<span class="number">6210</span>,]).astype(<span class="string">'int'</span>)</span><br><span class="line">for i in range(<span class="number">6210</span>):</span><br><span class="line">male_index[i] = int(np.array(phenotypes[<span class="string">'pedigree'</span>])[i].split(<span class="string">'_'</span>)[<span class="number">2</span>][<span class="number">1</span>:])</span><br><span class="line">male_trait1 = np.concatenate((male_index.reshape(<span class="number">1</span>,<span class="number">-1</span>),np.array(pheno_whole[<span class="string">'trait1'</span>]).reshape(<span class="number">1</span>,<span class="number">-1</span>))).<span class="symbol">T</span></span><br><span class="line">male_trait1_bysort = male_trait1[male_trait1[:,<span class="number">0</span>].argsort()]</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line">ax.plot(male_trait1_bysort[:,<span class="number">1</span>])</span><br><span class="line">ax.set_title(<span class="string">'different males have varied values'</span>)</span><br></pre></td></tr></table></figure></p><p><img src="http://i1.bvimg.com/640680/818f1d13de885240.png" alt="Markdown"><br>以上内容简要地介绍了eMaize问题使用的一些基本的常用的机器学习方法，包括数据预处理、特征选择、降维、回归以及分析。本教程还顺便展示了一些python常用的工具包的使用，读者有时间可以慢慢体会其中的具体操作，因为jupyter notebook的可视化与交互性很强，读者可以方便地查看中间步骤的数据情况，更好地理解代码所进行的操作。<br><br>由于实际工作的步骤、数据量、变量等问题，还需要慎重考虑计算时间、任务管理等工作 <br><br>想要预测较难预测的样本仅仅靠常规的机器学习方法并不够用，将机器学习应用于生物学问题时，不能简单套用模型，还需要根据问题进行针对性的设计，才有可能取得更好的结果。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是为实验室写的，借由eMaize问题帮助大家简单了解机器学习基本方法和基础代码的教程。也可以在&lt;a href=&quot;https://lulab.gitbooks.io/bioinfo/content/5%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%95%B4%E5%90%88----%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/51.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;看到&lt;/p&gt;
&lt;p&gt;由于jupyter notebook的强大的展示功能，本教程还用jupyter notebook组织且运行，可以获得更好的学习效果，代码在&lt;a href=&quot;https://github.com/james20141606/somethingmore/blob/master/bioinfo.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;,欢迎取用。&lt;a href=&quot;http://localhost:4000/2018/04/12/setup/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;在这里&lt;/a&gt;我简单介绍了如何配置jupyter，在&lt;a href=&quot;https://james20141606.github.io/2018/04/10/Deep-Learning-Practice/&quot;&gt;Deep Learning tutorial&lt;/a&gt;中我也强烈推荐了jupyter，并且介绍了很多基于jupyter的资源，强烈建议尝试一下。&lt;br&gt;
    
    </summary>
    
      <category term="techniques" scheme="http://james20141606.github.io/categories/techniques/"/>
    
      <category term="machine learning" scheme="http://james20141606.github.io/categories/techniques/machine-learning/"/>
    
    
      <category term="codes" scheme="http://james20141606.github.io/tags/codes/"/>
    
      <category term="statistics" scheme="http://james20141606.github.io/tags/statistics/"/>
    
      <category term="machine learning" scheme="http://james20141606.github.io/tags/machine-learning/"/>
    
      <category term="techniques" scheme="http://james20141606.github.io/tags/techniques/"/>
    
      <category term="bioinformatics" scheme="http://james20141606.github.io/tags/bioinformatics/"/>
    
  </entry>
  
  <entry>
    <title>陈炳林回忆录 序言</title>
    <link href="http://james20141606.github.io/2018/04/11/auto0/"/>
    <id>http://james20141606.github.io/2018/04/11/auto0/</id>
    <published>2018-04-11T02:10:01.000Z</published>
    <updated>2018-04-12T15:22:53.537Z</updated>
    
    <content type="html"><![CDATA[<p>本文章同时被整理成一本小书，放置在我的gitbook账户下，点击<a href="https://legacy.gitbook.com/book/james20141606/grandpa-autobiography/details" target="_blank" rel="noopener">这里</a>可以阅读。</p><h1 id="Preface-前言"><a href="#Preface-前言" class="headerlink" title="Preface 前言"></a>Preface 前言</h1><p>这份不长不短的回忆录源自于清华大学的毛中特课程的一份作业，在一年以前就打算选择冯务中老师的课，原因就是打听了各个老师的任务，对这项任务非常感兴趣，无奈没有抢到课，但是却开始了帮助爷爷奶奶整理这份回忆录的过程。平时每个周末都会和爷爷奶奶视频聊天一两个小时，自从有了这个想法，就会专门和爷爷奶奶聊过去的故事，顺带鼓励他们动笔写一些。爷爷年轻时是县委组织部的笔杆子，虽然已经七十多岁了，听到我的鼓励也有些心动，多年未提笔，写起来却是收不住，听奶奶说爷爷经常凌晨四五点起来就开始写，边写边流泪，回忆幼年时的艰辛与不易。这份回忆录，讲到了爷爷中年时期即止，爷爷说，年轻的生活更加刻骨铭心，令人难忘，后来生活好转，一切顺利如意，倒也没什么可写了。<br><a id="more"></a></p><p>这份回忆录以爷爷为主要视角叙述，补充了很多和奶奶讨论之后获得的细节，家里过去非常的穷，留下的资料几乎为零，曾经爷爷的哥哥大爷试图整理一份家谱出来，也被爷爷的爸爸在大爷去世后烧毁，因此我们也觉得能够再整理出一些过去的故事非常有意义。这里面的一些故事朴实又动人，在我整理的过程中充满了感慨和感动，让我体会到祖辈们的艰苦和不屈的精神。有的故事还带来了意想不到的惊喜，比如爷爷专门回忆了他年轻时结识的一个好朋友周聚照，已经几十年联系不上了，我整理完爷爷的回忆录，对这位朋友印象深刻，因此自告奋勇帮爷爷联系，在几个可能的地点的百度贴吧发布帖子，真的找到了这位老人的家人。爷爷和奶奶非常激动，第二天就坐车前去看望，周聚照老人已经不在了，但是他的后代生活的很好，孙辈们都获得了很好的教育，考入了很好的大学，改变了自己的命运，真的很令人感慨。另一个故事，爷爷没有亲手写下来，但是还是忍不住告诉了我，就是回忆录的最后一个故事，关于正义的故事，这个发生于爷爷的父亲身上的真实的故事深深的震撼了我，让我对那个混乱的年代有了更深的体会。<br>最后还整理了一个简单的按照年份的时间表，还用一个专门的软件macfamilytree制作了一个这三四代人的家谱树，希望未来的家谱树可以越来越大，开枝散叶，生生不息。</p><h1 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title="目录   Table of Contents"></a>目录   Table of Contents</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><a href="https://james20141606.github.io/2018/04/11/auto0/">前言</a></h2><h2 id="Chapter-Ⅰ-我的童年"><a href="#Chapter-Ⅰ-我的童年" class="headerlink" title="Chapter Ⅰ 我的童年"></a><a href="https://james20141606.github.io/2018/04/11/auto1/">Chapter Ⅰ 我的童年</a></h2><h2 id="Chapter-Ⅱ-初中生活"><a href="#Chapter-Ⅱ-初中生活" class="headerlink" title="Chapter Ⅱ 初中生活"></a><a href="https://james20141606.github.io/2018/04/11/auto2/">Chapter Ⅱ 初中生活</a></h2><h2 id="Chapter-Ⅲ-难忘的一九五八"><a href="#Chapter-Ⅲ-难忘的一九五八" class="headerlink" title="Chapter Ⅲ 难忘的一九五八"></a><a href="https://james20141606.github.io/2018/04/11/auto3/">Chapter Ⅲ 难忘的一九五八</a></h2><h2 id="Chapter-Ⅳ-新的篇章"><a href="#Chapter-Ⅳ-新的篇章" class="headerlink" title="Chapter Ⅳ 新的篇章"></a><a href="https://james20141606.github.io/2018/04/11/auto4/">Chapter Ⅳ 新的篇章</a></h2><h2 id="Chapter-Ⅴ-休学的日子"><a href="#Chapter-Ⅴ-休学的日子" class="headerlink" title="Chapter Ⅴ 休学的日子"></a><a href="https://james20141606.github.io/2018/04/11/auto5/">Chapter Ⅴ 休学的日子</a></h2><h2 id="Chapter-Ⅵ-婚后的生活"><a href="#Chapter-Ⅵ-婚后的生活" class="headerlink" title="Chapter Ⅵ 婚后的生活"></a><a href="https://james20141606.github.io/2018/04/11/auto6/">Chapter Ⅵ 婚后的生活</a></h2><h2 id="Chapter-Ⅶ-喜上加喜-喜中有忧"><a href="#Chapter-Ⅶ-喜上加喜-喜中有忧" class="headerlink" title="Chapter Ⅶ 喜上加喜 喜中有忧"></a><a href="https://james20141606.github.io/2018/04/11/auto7/">Chapter Ⅶ 喜上加喜 喜中有忧</a></h2><h2 id="Chapter-Ⅷ-工作-崭新的篇章"><a href="#Chapter-Ⅷ-工作-崭新的篇章" class="headerlink" title="Chapter Ⅷ 工作 崭新的篇章"></a><a href="https://james20141606.github.io/2018/04/11/auto8/">Chapter Ⅷ 工作 崭新的篇章</a></h2><h2 id="Essays-短文数篇"><a href="#Essays-短文数篇" class="headerlink" title="Essays    短文数篇"></a><a href="https://james20141606.github.io/2018/04/11/auto9/">Essays    短文数篇</a></h2><h3 id="忆祖母"><a href="#忆祖母" class="headerlink" title="忆祖母"></a>忆祖母</h3><h3 id="忆母亲"><a href="#忆母亲" class="headerlink" title="忆母亲"></a>忆母亲</h3><h3 id="四伯家生活写照"><a href="#四伯家生活写照" class="headerlink" title="四伯家生活写照"></a>四伯家生活写照</h3><h3 id="八岁孩子学走路"><a href="#八岁孩子学走路" class="headerlink" title="八岁孩子学走路"></a>八岁孩子学走路</h3><h3 id="我的第一双棉鞋"><a href="#我的第一双棉鞋" class="headerlink" title="我的第一双棉鞋"></a>我的第一双棉鞋</h3><h3 id="大伯和父亲给祖母惹祸"><a href="#大伯和父亲给祖母惹祸" class="headerlink" title="大伯和父亲给祖母惹祸"></a>大伯和父亲给祖母惹祸</h3><h3 id="真实故事三则"><a href="#真实故事三则" class="headerlink" title="真实故事三则"></a>真实故事三则</h3><h3 id="我的朋友周聚照"><a href="#我的朋友周聚照" class="headerlink" title="我的朋友周聚照"></a>我的朋友周聚照</h3><h3 id="人生机遇只有一次"><a href="#人生机遇只有一次" class="headerlink" title="人生机遇只有一次"></a>人生机遇只有一次</h3><h3 id="过个革命化春节"><a href="#过个革命化春节" class="headerlink" title="过个革命化春节"></a>过个革命化春节</h3><h3 id="石人传说二则"><a href="#石人传说二则" class="headerlink" title="石人传说二则"></a>石人传说二则</h3><h3 id="Poems-诗歌九则"><a href="#Poems-诗歌九则" class="headerlink" title="Poems 诗歌九则"></a><a href="https://james20141606.github.io/2018/04/11/auto10/">Poems 诗歌九则</a></h3><h4 id="玩秋千"><a href="#玩秋千" class="headerlink" title="玩秋千"></a>玩秋千</h4><h4 id="石人山景"><a href="#石人山景" class="headerlink" title="石人山景"></a>石人山景</h4><h4 id="恋家"><a href="#恋家" class="headerlink" title="恋家"></a>恋家</h4><h4 id="四伯"><a href="#四伯" class="headerlink" title="四伯"></a>四伯</h4><h4 id="无题"><a href="#无题" class="headerlink" title="无题"></a>无题</h4><h4 id="思往昔看今朝"><a href="#思往昔看今朝" class="headerlink" title="思往昔看今朝"></a>思往昔看今朝</h4><h4 id="石人山下荡秋千"><a href="#石人山下荡秋千" class="headerlink" title="石人山下荡秋千"></a>石人山下荡秋千</h4><h4 id="咏春"><a href="#咏春" class="headerlink" title="咏春"></a>咏春</h4><h4 id="大竹园变堰潭"><a href="#大竹园变堰潭" class="headerlink" title="大竹园变堰潭"></a>大竹园变堰潭</h4><h2 id="Story-of-Justice-一个关于正义的故事"><a href="#Story-of-Justice-一个关于正义的故事" class="headerlink" title="Story of Justice    一个关于正义的故事"></a><a href="https://james20141606.github.io/2018/04/11/auto11/">Story of Justice    一个关于正义的故事</a></h2><h2 id="Chronology年表"><a href="#Chronology年表" class="headerlink" title="Chronology年表"></a><a href="https://james20141606.github.io/2018/04/11/auto12/">Chronology年表</a></h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文章同时被整理成一本小书，放置在我的gitbook账户下，点击&lt;a href=&quot;https://legacy.gitbook.com/book/james20141606/grandpa-autobiography/details&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;可以阅读。&lt;/p&gt;
&lt;h1 id=&quot;Preface-前言&quot;&gt;&lt;a href=&quot;#Preface-前言&quot; class=&quot;headerlink&quot; title=&quot;Preface 前言&quot;&gt;&lt;/a&gt;Preface 前言&lt;/h1&gt;&lt;p&gt;这份不长不短的回忆录源自于清华大学的毛中特课程的一份作业，在一年以前就打算选择冯务中老师的课，原因就是打听了各个老师的任务，对这项任务非常感兴趣，无奈没有抢到课，但是却开始了帮助爷爷奶奶整理这份回忆录的过程。平时每个周末都会和爷爷奶奶视频聊天一两个小时，自从有了这个想法，就会专门和爷爷奶奶聊过去的故事，顺带鼓励他们动笔写一些。爷爷年轻时是县委组织部的笔杆子，虽然已经七十多岁了，听到我的鼓励也有些心动，多年未提笔，写起来却是收不住，听奶奶说爷爷经常凌晨四五点起来就开始写，边写边流泪，回忆幼年时的艰辛与不易。这份回忆录，讲到了爷爷中年时期即止，爷爷说，年轻的生活更加刻骨铭心，令人难忘，后来生活好转，一切顺利如意，倒也没什么可写了。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅰ  我的童年</title>
    <link href="http://james20141606.github.io/2018/04/11/auto1/"/>
    <id>http://james20141606.github.io/2018/04/11/auto1/</id>
    <published>2018-04-11T02:10:00.000Z</published>
    <updated>2018-04-12T07:56:57.045Z</updated>
    
    <content type="html"><![CDATA[<p>我出生在石桥街西夹后布袋街外祖母家那个巷子里，是一九四零年(民国二十九年)生，赶上三十年年成那年。我出生后家里有四口人，大哥已经两岁。在集镇上住，家里没地没房，不做生意，生存十分困难。后来经人介绍，父亲用卖菜的筐一头一个孩子，挑着我们去白河东沙山给地主彭山种地。地主给了草房两间，几亩薄地，生活勉强过得去。日本侵华后战乱频起，又逢灾年（指1942年七月到1943年春天的那场大灾荒，河南受灾总人数达1200万人，约三百万人死亡），祖母不愿骨肉分离，我们一家四口只好又两手空空搬到祖母借住地薛庄去（魏庄西边西边的那个庄）。<br><a id="more"></a><br>1941年春天母亲得了一场大病（奶花疮），那时我才不足一周岁，正值三十年年成，没饭吃也没奶喝，眼看着就要饿死。父亲只得将家里的一床被子和一条床单带上，徒步到老河口换点吃的。当他第三天凌晨回到沙山家里时，我和母亲两人已经两天没有吃东西了。父亲忙生火做面麸汤面水救命，我竟一口气喝了三大碗，肚子撑得得鼓鼓的，父亲说当时我肚子上的青筋都能看到，我还想再喝一些，母亲坚决不要我再喝，说否则会把人撑死，还是母亲心细。这两升麸面可是救了我的命啊。</p><p>再一次搬回薛庄后，祖母，大伯，爹妈，大哥和我六口人没吃没喝，据说那时候能够食用的榆树皮都被剥光了，树枝、豆科的角皮都吃，人吃了以后拉不出来就用竹签剜，母亲说我当时就用的这个办法，吃饭已艰难至此，总不能全家一起饿死吧，为了减轻压力，祖母带着自己平时少言寡语，木讷死板的大儿子，也就是我的大伯远走他乡要饭去。为了大家的生存，大伯也只能跟着祖母要饭去了。母亲说，为了不让我饿死，她只好把我的大哥也送到外公家，留下我自己一个孩子。好心的黄奶（她有一个终身未娶的儿子留在身边）每顿煮菜汤的时候剩下的饭跟都会让我喝，两家人的饭跟救活了我，黄奶也是我的救命恩人！</p><p>奶奶领大伯远走他乡本身就够难了，大伯一个大男人实在是委屈，进村后他就站在树下或者墙根处，不愿进院子里。可是这样怎么能讨得来饭呢。于是每顿都是祖母先讨来饭让大伯吃，吃的差不多了再去要几口饭自己吃，如果要不到，两个人就只能饿肚子。她要饭不是为了大儿子，不是为了她自己，她带走大儿子，留下我们，是为了留下家族的火种。饿死大伯只饿死一个，饿死我们一家人，不知道陈家还能不能延续下去。祖母说：“人留子孙，草留根”，当时的我们，真可谓是离离原上草，一岁一枯荣；野火烧不尽，春风吹又生了。</p><p>灾荒终于过去，祖母和大伯回家了，大伯没有饿死，祖母没有饿死，我也没有饿死，大家都没有饿死，陈氏家族总算有一线希望了。祖母很伟大，大伯的牺牲值得铭记，我还是大伯的过继儿，大伯的恩情我不会忘记。</p><p>解放前，薛庄有个大地主叫做郭老八，大名并不记得了。他每日都搬一个大圈椅，坐在槐树下纳凉，经常自言自语道：我儿强似我，要钱做什么；我儿不如我，要钱干什么？此人精明算计，在土改前他竟然大肆低价变卖土地、房屋，挥霍家产，到了土改时家产变卖一空，竟然成了贫农，我们才知道原来是人家外边有人，提前知道了形势，想躲过一劫。我的祖母、长辈因长期地无一分、椽无一根，困苦惯了，深受压榨剥削，为了有两亩地，竟然在土改的前一年全家人节衣缩食，纺花织布，买下了两亩薄地。结果第二年就土改了，你说傻不傻，没有知识和文化，真是命苦啊！因我们家里太穷，土改时定为雇农，因此将地主李氏南家最好的三间大瓦房分给我们，后来因为此处没有庭院，所以将瓦房推倒，在现在的老家旧居所用这些砖瓦盖了新房。当时还分得一张核桃木雕花木床，两把圈椅，木床不幸遗失，两把圈椅送去了寺庙中。</p><p>一九四八年，八周岁的我的得了天花，发高烧，没有吃的也没有药医，后来竟然下不了床，不会走路了，于是大伯经常用长腰带绑着我带我重学走路，这次大难不死，没有落下什么大毛病，只是让我的体质变得特别差，这也是我一生体质不好的原因。</p><p>我八岁到十岁的几年主要跟随奶奶去石人沟四伯家生活，他那里吃饱饭没有什么大问题，那几年我终身难忘，有苦有乐，有悲有喜。一九五零年的春天，我开始在尹店小学读书，三年后转学到皇路店完小上学。那时候的学校不布置作业，家里又没有一个识字的人，学的怎么样谁又知道呢？</p><p>抽空拾柴捡粪是我那时候最喜欢干的主业，当时土改给我家分了几亩地，我做梦都想买来一头牛耕地，攒粪让庄稼长得好，能够有吃有喝站到人前，这就是我当时的梦想了！父亲答应了我，买了一头全身黑色的小母牛娃，条件是我不能因此耽误了上学，这头小牛完全由我负责，我当然无比爽快地答应。每日上学和放学路上，我都不走大路，一定要从田间地埂走，割青草喂我心爱的小牛，我爱我的小牛就像现代人爱自己的宝马车一样，这牛是我的希望呀。夏季牛拴在外边，我就把床铺到它的附近，生怕有人晚上偷走它，我上学、养牛两不耽误，把小牛照顾得很好。两年之后，它产下了一头小牛犊，这可把我高兴坏了，生牛肚那晚，我一夜未眠，我想：梦想要实现了，我家现在有两头牛了啊！</p><p>既上学又养牛已经够忙活了，后来小我四岁的弟弟炳义也开始在皇路店上小学了，刚吃过饭去上学还好，他有劲就自己走，等放学回家肚子饿了，他就坐在地上耍赖，非要我背他回去，作为哥哥我就只能背着他走一段路，这可耽误了我割草了啊。</p><p>那时候家里穷，没有任何防寒、避雨的工具，夏季还好办，到了冬天，一下雪可就惨了，我只能把鞋子脱下夹在腋下（只有一双鞋，不能弄湿），脚总是会冻得钻心地痛。</p><p>小学离家有两公里地，下雪的时候就干脆不回家吃午饭了，等晚上路上结冰时再穿鞋回家，当然也是因为中午回家也没什么好吃的，不回去还能少一趟冻脚之苦。我从小喜爱咸饭，若是做了咸面条，妈绝对会给留一大碗。有时候母亲也会托人中午捎来一点红薯面馍，啃一口一个白印。吃红薯太多伤胃，我也因此落下了终身的胃病。</p><p>一九五六年小学毕业后我成功考入石桥镇上的初级中学，当时小升初率不高，所以我真是很幸运。我小学时的班主任张文彬老师亲自步行来家里送录取通知书。全家都高兴极了，家里有中学生啦，就像中了状元似的。父亲一定要留张老师吃午饭，老师答应了，那顿饭也就算是谢师宴了吧！后来我也和张老师成了好朋友，忘年之交了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我出生在石桥街西夹后布袋街外祖母家那个巷子里，是一九四零年(民国二十九年)生，赶上三十年年成那年。我出生后家里有四口人，大哥已经两岁。在集镇上住，家里没地没房，不做生意，生存十分困难。后来经人介绍，父亲用卖菜的筐一头一个孩子，挑着我们去白河东沙山给地主彭山种地。地主给了草房两间，几亩薄地，生活勉强过得去。日本侵华后战乱频起，又逢灾年（指1942年七月到1943年春天的那场大灾荒，河南受灾总人数达1200万人，约三百万人死亡），祖母不愿骨肉分离，我们一家四口只好又两手空空搬到祖母借住地薛庄去（魏庄西边西边的那个庄）。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅱ  初中生活</title>
    <link href="http://james20141606.github.io/2018/04/11/auto2/"/>
    <id>http://james20141606.github.io/2018/04/11/auto2/</id>
    <published>2018-04-11T02:09:59.000Z</published>
    <updated>2018-04-12T07:57:06.487Z</updated>
    
    <content type="html"><![CDATA[<p>入学后我被分到了56丁班，和我后来的妻子是同班同学，她从小学就学习刻苦，成绩优秀，是初中部的学习部长，那时我们是纯洁的同学关系，很少有接触，几乎没有怎么说过话。<br><a id="more"></a></p><p>上初中时正值全国性反右的高潮，一九五六年在庐山会议上本来要纠左，彭德怀上了万言书，反而被毛泽东定性为反党集团，全国轰轰烈烈的反右运动开始了。学校教师有将近一半被划为右派，初中生虽然不划右派，但是对个别学生的言论也进行批判，令其退学。比如薛庄村学生王慧敏受运动刚开始时大鸣大放的影响（即向党提意见），她草书“向毛主席开一炮”，甲班学生柏长松在教工厕所门口写了“屎不一样”，抨击教师和学生生活水平不同，学生生活水平不好。这两人被查出来之后，被全校批判，勒令退学，开除学籍，丧失了继续学习的权利。教职工、学生都被这样的政治空气笼罩着，多数老师被划为右派，可我的班主任贾之广是反右运动中的左派，一副盛气凌人的气度，在丁班大搞紧张气氛，把我和几个要好的同学打成所谓的“小集团”。中央有彭、黄、张、周反革命集团，而我们这小集团是什么性质？我们这些十几岁的娃娃根本不懂，班主任这样做为了什么，我们也不懂。他组织全班同学揭发我们，每晚组织班干部揭发批判，揭什么呀，批什么呀！</p><p>小集团成员是不得随意离校的，离校要遵循请假制度，我们这些人（曹成才、翟清合、王明跃、王松林、雷清茂等人），一举一动都会被人监视着。我当时没钱在大伙就餐，只能立小灶，这小灶可不是现在改善生活的那种，我每周都得回家里挑做饭要烧的柴火，玉米糁和红薯等，可是找班主任请假，他不批准，这可让人怎么生活呀！他越是这样，我们这些好友靠的越紧，凑空就在一起互相诉苦，心情也是越来越差，气氛越来越紧张。</p><p>请不下来假，不回家拿吃的可如何上学？一次周六下午我写好了请假条让贾批准，天色已晚，学生们已经离校了，因为紧张我忘记敲门，直接推门进去了，这时我亲眼看见一个年轻的女教师正仰面躺在他的床上，二人正低声私语。这实在是够尴尬了，可我没有退出来，拿着请假条死缠着要回家，这举动自然是激怒了他，他要我出去，我想着反正他没有把我关起来，也没说不准我回家，我就摸黑偷偷溜回家了。到家后我把当时的情况讲给了父亲，他怒火中烧，说要找贾评理，。我当时不懂，不但给父亲说了此事，也对小集团的成员们讲了贾的所作所为，大家都极其不满，消息估计也传开了，让贾也知道了。父亲出于愤怒竟然也去学校找贾，因此师生间矛盾再次升级，我的对手可是年近四十的人，在国民党电台任过台长，还是反右左派，斗争经验丰富，我就像一个不会反抗的犯人一样，被牢牢地控制住了。</p><p>由于我精神压力巨大，不久就得了一种怪病：正走路时眼前一黑，头一晕，腿发软，就向前摔去，摔得鼻青脸肿。不用班主任勒令我回家，我自己也只得休学了！</p><p>贾的恶作剧并没有结束，他极其会戏弄人，命令小集团的成员用学校拉垃圾的车子拉我回家，路上这群无知的青年竟然还兴高采烈，欢声笑语，驾着垃圾车飞跑，好像我刚从恐怖的监狱里逃出来一样高兴。不管怎样，我休学回家了，当时我并不知道，学生会学习部长王若平也因小学的时候和小集团成员曹成才同班同学（年龄比她大两岁，是小集团首领），被威逼要揭发小集团，她哪知道揭发批斗什么，当然什么都说不出来。后来可恶的贾芝庞组织其他干部把矛头全对准她，向她施压，批判她，她没有经受得住，精神也不正常了，在我休学之前她就已经休学啦，被人送回家养病。结婚后我们两个谈及此事，真觉得不可思议，上帝究竟是如何安排的，让我们两个经历这九九八十一难啊。</p><p>紧接着河南又刮起了一阵反潘、杨、王风，直指潘复生，杨珏，王庭栋。纠左开始了，这才把贾芝庞给揭露了出来，将他绳之以法，判了三年刑。</p><p>被判小集团期间我心情极差，休学回家治疗了一个多月，是尹店中医李连奇给治的，每天一副中药，药引是童便。病治好后该返校了，但是大哥突然罹患脑膜炎病逝，年仅二十岁。当时他已订好婚，五八年底就该结婚了，大哥的猝然离世对家人的打击太大了，父亲因此变得精神不太正常，不思茶饭。在身体极度虚弱的情况下，大队硬是派他去云阳铁牛庙水库做工，在水库父亲也累得病倒了。</p><p>我的病刚好，大哥离世，父亲在水库也病倒了，一九五百年真是灾难性的一年，是黑色的一九五八。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;入学后我被分到了56丁班，和我后来的妻子是同班同学，她从小学就学习刻苦，成绩优秀，是初中部的学习部长，那时我们是纯洁的同学关系，很少有接触，几乎没有怎么说过话。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅲ  难忘的一九五八</title>
    <link href="http://james20141606.github.io/2018/04/11/auto3/"/>
    <id>http://james20141606.github.io/2018/04/11/auto3/</id>
    <published>2018-04-11T02:09:57.000Z</published>
    <updated>2018-04-12T07:57:23.193Z</updated>
    
    <content type="html"><![CDATA[<p>父亲病倒后水库指挥部通知家人，去云阳水库接回父亲。家里只有我可以担当此仁，此时我已经十八岁，刚刚成年。接到通知的时候我害怕极了，父亲可千万不能出事啊。我恨不得自己能赶快长出一双翅膀飞过去接他回家。<br><a id="more"></a><br>第二天一大早，我拉着架子车就上路了，开始时我是跑着拉车，走过鸭河之后就心有余而力不足了，上坡路是绝对跑不动了，但是心里着急，还是一刻不停地走着，一天只喝了几次水，没有进食任何东西，经过一天的奔波，晚上才到云阳，因为是头一次去，走的晕头转向，肚子一天没有吃东西却也不觉饿，只是口渴难耐，说不出话。经过打听之后得知还有十公里路，没有正路可走，步行沿着河边走倒是可以快一点，但是车子放哪里呢？没有车子第二天如何拉父亲呢？可是我太急于见到父亲确定他没事，人受挫折武艺高，我找了一家修车铺，放掉车胎气，自述架子车放了炮，得补胎，我把架棚靠人家店外，下盘搬进屋子里，说好了明天来拉车付款。我顾不得吃晚饭，就按照人家指的路线摸黑去水库。天黑路生，河里不时发出响声，好像是鱼儿拍打水面，没有出过远门，没有一个人走过夜路的我，自然情绪紧张，稍有风吹草动就会东张西望。我越紧张，就越觉得背后有什么东西在跟着我，我吓得头发梢支棱着，然而再怕也不能停下，我只能一直往前行，大概在晚上十一点左右终于看到了灯光，那是水库指挥部所在地了。</p><p>指挥部工作人员刚吃过夜宵，我向负责人说明情况后，他叫炊事员把剩下的一大碗甜面片给我吃，还给我拿了几根蒜薹，饭已经凉了，可我终于有了极大的饿意，吃的狼吞虎咽、风卷残云，几分钟就吃完了，噎得直打嗝。他让我找个空铺睡下休息，并通知工地，让父亲第二天一早过来。我哪里睡得着啊，只盼着早点见到父亲，父亲接到指挥部通知说儿子在指挥部等他，已经卧床的他竟然起身一个人摇摇晃晃地往指挥部走。次日拂晓我和父亲终得相见，我们像久别重逢一般抱头痛哭，父亲安慰我说，见到你我的病就轻得多啦。我的泪水不光是因为见到了父亲，酸甜苦辣咸五味俱全，这几年我都体验了一遍啊，心中的苦楚一起涌上心头：小集团、生病、休学、兄长病殁、父亲精神失常、小弟炳都得转头虱病。正所谓男儿有泪不轻弹，只是未到伤心处。</p><p>太阳冉冉升起来啦，我和父亲一起，扶着他向云阳走去，在停架子车的店铺说明情况后取出架子车，走进旁边的一家食堂。他说：“今天我们父子俩吃炝锅面，再买一斤油条，加进去美美气气吃一顿。”父子见面，他的病好了一些，我折腾了一天一夜，但是心里轻松得多了，我只觉得自己腿酸乏力，因为自己也才病愈，又一口气跑了那么远。吃完饭，我强打精神，他坐车我拉车，往回家的路走，边走边聊。父亲见我也是强打精神，他说上坡时我下来，下坡时我再坐车，走一阵咱俩换换，我拉车你坐车。听父亲这么说，我不怕了，父亲还能活！当天夜里我们顺利到家了。别了，黑色一九五八！！</p><p>当父亲处理完这些事情后，就带着我复学，他先领我见了四中当时的校团委书记和宝兴，请他多关照我，和宝兴家在皇路店沽沱村，不知道父亲是怎么认识他的。复学前后还在学校经历了勤工俭学、大炼钢铁、白河淘铁砂（炼钢用）等运动，我的求学路可谓一波三折啊，孙辈们是难以想象的！</p><p>勤工俭学：五人一辆独轮木质手推车（当时称之为小车），去南召三岔口买柴，因为没有大路走，只能从全是乱石的河滩里推着走，我们披星戴月，买柴卖柴，赚了多少钱已经记不清啦。</p><p>炼钢铁：就在学校西南角空地处放一个炼铁炉，大风箱得六七个人同时拉才能拉动，炉子里放的是铁锅、铁盆、生铁之类的铁制品，各种废铁堆在一起烧，至于能烧出多少铁根本没有人管它，这样荒唐的事当时正在神州大地的每个角落发生，在大炼钢铁的过程中，南阳县四中的全体学生也都停课了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;父亲病倒后水库指挥部通知家人，去云阳水库接回父亲。家里只有我可以担当此仁，此时我已经十八岁，刚刚成年。接到通知的时候我害怕极了，父亲可千万不能出事啊。我恨不得自己能赶快长出一双翅膀飞过去接他回家。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅳ  新的篇章</title>
    <link href="http://james20141606.github.io/2018/04/11/auto4/"/>
    <id>http://james20141606.github.io/2018/04/11/auto4/</id>
    <published>2018-04-11T02:09:55.000Z</published>
    <updated>2018-04-12T08:11:41.163Z</updated>
    
    <content type="html"><![CDATA[<p>我在一九五九年夏季初中毕业，学校要求毕业生要主要报考高中、师范。高中是绝对上不起的，当教师是臭老九，经过反复的斟酌，我选择了当时自己觉得最受人崇拜的专业：农机化专业，这可是毛主席提出的四化之一，就这样我顺利录取到了郑州农机化专科学校（1960年，郑州农业机械化专科学校并入河南农学院（现河南农业大学），组建河南农学院农业机械化分院），我仿佛已经能够想象出自己开着铁牛奔驰在祖国广阔原野上的场景了。<br><a id="more"></a><br>那年全校有毕业班四个，录取农机化专业的一共有四个人，甲班的王文武，丙班的丁立志，以及丁班的我和王若平。九月份就要开学啦，我们的学校在省城郑州，郑州在哪里，路有多远，要坐汽车和火车才能到达，这些对于没出过远门的我（在石桥上学期间只到过南阳城区一次，参观李花庄铁牛耕地，面粉厂的大型面粉加工设备）来说，真是无比新鲜，更何况就要长期离开父母，相隔好几百里呢。去郑州要结伴，毕竟人多智谋广啊，我觉得约上同班同学，又录取同校的王若平是首选，我估计她也会首选我结伴同行。经过打听得知，郑州农机化专科学校和郑州计划经济学校在同一条路上（农业路），距离很近，为此又约上录取该校的赵玉珍，闫学珍结伴。</p><p>行动路线、时间、人员集合地点等确定后，我们头一天先各自步行至南阳，晚上住在闫学珍的亲戚家（地址在老一中东，现在的市第八小学附近）。第二天一大早我们乘坐南阳开往许昌的代客车（也就是货车上加一个帆布篷，车厢上固定有大连椅），到达许昌汽车站已经是下午了，经过购票排队，在火车站排队候车，终于坐上了一辆从三门峡至许昌的火车，我们于次日凌晨抵达省城火车站。经过打听得知去北郊（那时农业路附近是郑州的郊区）那趟公交车是烧木炭的车，夜里无法发车，于是我们决定坐三轮车去学校。其实当时学校在火车站设有接待站，有车接我们，可是我们奔波两天，初到省城，火车站又乱，竟然没有注意到。</p><p>从偏僻的农村到南阳首府，到许昌，到河南的省会，全国交通大动脉，漫长的路程，全新的景象，我心中的那份心情可想而知，生活，全新的生活就要开始了！</p><p>入校之后学校首先对我们进行了专业教育，介绍学校环境：大礼堂、小礼堂、校医院、图书馆、教学大楼、大体育场等，学校有高水平的篮球队，棒球队和排球队，学校的业余剧团，还能去校外演出的剧团。每周末学校都会放电影，有各种球队比赛等娱乐活动。学校有大型实习工厂，车钳电焊，车床设备齐全，所加工的游标卡尺，缸盖修理等工艺具有很先进的水平，可以当做商品售卖，有订单，能赚钱。大小汽车数量，实习用各型号链式和轮式拖拉机齐全。学校还有菜地百亩，黄河滩可耕地几百亩，每年收成很多小麦，伙食是八人一盒菜，而且吃饭不限量，管理生活的副校长在大礼堂讲话时宣布，要把大家都养成大胖子。</p><p>学校不收书本费、生活费，每人每月12.5元，除了医疗费1.5元外全是生活费。生活、学习、环境全都令人满意，四中时期的阴影全都抛到脑后了，那里的生活是崭新的，前途是无量的，只等毕业分配工作，当干部，拿工资，养家糊口了。</p><p>然而好景不长，一九六零年的秋季，左倾思潮翻涌，阶级斗争、政治运动席卷全国，粮食生产急剧下降，人民群众的生活水平降到了最低水平线（1960-1962年发生了著名的三年自然灾害，河南等粮食产地受灾尤为严重）。省城告急了，就要断炊了，刚开始学校提出“低标准，瓜菜代”，用东北运来的大豆面加上黄河滩的蒲草做窝窝头吃，稠一点的大米饭用秤称。再往后，火车运到郑州的粮食竟然来不及开进粮店，大专院校的车就已经开到火车站拿着粮本开始接货了，学校再也坚持不下去了，郑州也坚持不下去了，唯一的方法是减少城市人口，减少不种地只吃饭的人的数量，于是在六一年，人口集中的大专院校全部停办，以减轻省城压力，农村是广阔的天地，我只能重新回到广阔的农村了，我重新回到了阔别两年的家。</p><p>虽然能见到久别的父母，可是回家的心情一点都不愉快。我心事重重，学校宣布放长假，有多长？还能回校吗？连粮户关系（指粮食与户口关系，当时有农业与非农业两种户口）都又非转农了，还有机会农转非吗？看来只能做一辈子的农民啦。你放假，我放假，结伴回老家。又是经历同样的交通路线，经过一天一夜的折腾才到南阳，那时又是凌晨，我和同学王若平背着行囊，低头不语，步行走在回家的路上。天亮才走到蒲山殷庄她的家，该歇歇脚了。她慈祥的妈妈为我俩做了一顿削过皮的红薯白面疙瘩，接待诚恳热情，她哪里知道接待的人竟是她未来的女婿呀！那可是三年自然灾害期间，这顿饭我终生难忘，饿了甜似蜜，不饿蜜不甜啊，削过皮的白面面疙瘩，又香又甜不塞牙，怎么能轻易忘记呢，这是我在若平家吃的第一顿饭。</p><p>结伴同行去郑，结伴同行回家，感谢您招待的这顿饭，感谢我的老同学，再见吧老同学，再见！不送啦！我又迈步向家的方向走去，可我像霜打了一样，无精打采，徒步走回魏庄的家里。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我在一九五九年夏季初中毕业，学校要求毕业生要主要报考高中、师范。高中是绝对上不起的，当教师是臭老九，经过反复的斟酌，我选择了当时自己觉得最受人崇拜的专业：农机化专业，这可是毛主席提出的四化之一，就这样我顺利录取到了郑州农机化专科学校（1960年，郑州农业机械化专科学校并入河南农学院（现河南农业大学），组建河南农学院农业机械化分院），我仿佛已经能够想象出自己开着铁牛奔驰在祖国广阔原野上的场景了。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅴ 休学的日子</title>
    <link href="http://james20141606.github.io/2018/04/11/auto5/"/>
    <id>http://james20141606.github.io/2018/04/11/auto5/</id>
    <published>2018-04-11T02:09:53.000Z</published>
    <updated>2018-04-12T08:11:53.357Z</updated>
    
    <content type="html"><![CDATA[<p>回乡后的我很快就适应了农村的生活，我是地道的农民的儿子，但是我心里还是惦记着上学时的生活，惦记着我的老同学，他们现在生活的怎么样，他/她们在干什么呢？老家尹店每年农历四月初八的庙会规模大，总是有两台戏，约老同学来赶庙会、叙叙旧应该是不错的选择！于是同班同学王若平和赵玉珍应约前往，逛完庙会又去了我的家里，父母热情地接待了她们，也让她们感动不已。<br><a id="more"></a><br>同样的命运，同样的环境，同样的人生遭遇，五年的同窗同学生活，我和王若平见面有太多想说的，有太多的共同语言，我们倾诉着各自的遭遇、生活中的喜怒哀乐，缘分就是这么奇妙，所谓日久生情，时间久了，我们的关系从普通的同学关系，变得不太一样了，内心仿佛多了些什么？</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;回乡后的我很快就适应了农村的生活，我是地道的农民的儿子，但是我心里还是惦记着上学时的生活，惦记着我的老同学，他们现在生活的怎么样，他/她们在干什么呢？老家尹店每年农历四月初八的庙会规模大，总是有两台戏，约老同学来赶庙会、叙叙旧应该是不错的选择！于是同班同学王若平和赵玉珍应约前往，逛完庙会又去了我的家里，父母热情地接待了她们，也让她们感动不已。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
  <entry>
    <title>回忆录 CHAPTER Ⅵ  婚后的生活</title>
    <link href="http://james20141606.github.io/2018/04/11/auto6/"/>
    <id>http://james20141606.github.io/2018/04/11/auto6/</id>
    <published>2018-04-11T02:09:51.000Z</published>
    <updated>2018-04-12T08:11:58.734Z</updated>
    
    <content type="html"><![CDATA[<p>燕尾山拾柴历险记</p><p>经过双方父母见面，我们这两个老同学确立了夫妻关系，于一九六二年农历七月十一日喜结良缘，开始了又一段崭新的生活。我不仅是一名失学的学生，农村的农民，还是一名丈夫，而且很快，就要成为父亲了。</p><p>一九六二年的农历闰四月，家里连一点可以吃的东西都没有了。已经怀了身孕的妻子只能靠着白水煮红薯干充饥，想吃点别的什么食物都是奢望。老家每年四月八号的庙会总会有亲朋好友和同学们来家里，断炊了还拿什么招待呢？我决定跟随邻居，去燕尾山拾柴变卖来赚些钱买点粮食。<br><a id="more"></a><br>为什么偏要去燕尾山呢，因为那座山较险峻，海拔高，很少有人涉足，所以山上容易弄到枯枝烧柴。我们出发的时候只带了能吃七天的玉米糁，脚穿妻子给我做的新布鞋。南召人说：南召到路上，七十二道脚不干。前四月山区还有些冷，河水依然冰冷，一会脱鞋淌水，一会儿穿上走山路。上山的时候要拉着荆藤向上爬，下来可就难多了，所谓上山容易下山难之说，这时才体会的格外清楚。夜晚露宿在山岔里，盖那床又脏又薄的褥子。四月的山区，夜间比平地还要冷上好几度，晚上睡觉是怎么也暖不热的。</p><p>玉米糁吃光了，拾到的柴还不够一车，没东西吃了，我和邻居李连有大叔只能饿肚子。李大叔不知道怎么想到办法，从山区的支部书记老婆那里弄来了免费的玉米糁，不过是发了霉的，像蚂蚱牙似的，不管怎么样，吃的问题总算是解决了。</p><p>支部书记夫人四十多岁，穿着扎花鞋，还用红头绳扎着头发，有着山里人特有的气质。我们一日三餐都吃着她提供的发霉了的玉米糁，饿了甜似蜜，填饱肚子第一，我们也不挑。不知道那位支书夫人是不是出于可怜之心，第二天又给我们送来了发粘的芥菜丝让我们陪着饭吃，李连有大叔竟然感动得跪地磕头致谢，场面令我也感到震撼，我也从内心深处感谢这位女菩萨的施舍。</p><p>终于拾够了一整车的柴，我们满载而归，上山坡时你推我拉，互相帮助，饿了找背风处生火做饭，天黑人困了找山坡背风处睡觉。遮风避雨的小宿舍几分钟就可以搭建好，我们也没有功夫像现在的野营爱好者那样花那么多力气。用拉车的人常备的支杆将车把支牢固，取下小铺盖，裹上被子于车下即可酣然入睡好解乏。不失眠，超过席梦思，赛过金銮殿。</p><p>这趟北山拾柴历经十天，竟卖了六斤肉（瘦了六斤），脸瘦了一大圈，出发时穿的那双新布鞋也已经破了，脚跟露在外边了。全家人在家吃着清水煮红薯片等着我，而我上山拾柴那几天，想吃红薯片汤都难啊，当时的生活就是艰难至此。</p><p>苦味是五味之首，有苦才有甜，这是最质朴却深刻的人生哲理。卖掉一半柴火用来购粮食，另一半留下烧锅，顺利地度过了难关。这年五月初一，我的长子陈华军出生了，你说我的心里该有多甜啊，这样的苦难过后的甜，真是世上最甜的滋味了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;燕尾山拾柴历险记&lt;/p&gt;
&lt;p&gt;经过双方父母见面，我们这两个老同学确立了夫妻关系，于一九六二年农历七月十一日喜结良缘，开始了又一段崭新的生活。我不仅是一名失学的学生，农村的农民，还是一名丈夫，而且很快，就要成为父亲了。&lt;/p&gt;
&lt;p&gt;一九六二年的农历闰四月，家里连一点可以吃的东西都没有了。已经怀了身孕的妻子只能靠着白水煮红薯干充饥，想吃点别的什么食物都是奢望。老家每年四月八号的庙会总会有亲朋好友和同学们来家里，断炊了还拿什么招待呢？我决定跟随邻居，去燕尾山拾柴变卖来赚些钱买点粮食。&lt;br&gt;
    
    </summary>
    
      <category term="爷爷回忆录" scheme="http://james20141606.github.io/categories/%E7%88%B7%E7%88%B7%E5%9B%9E%E5%BF%86%E5%BD%95/"/>
    
    
      <category term="life" scheme="http://james20141606.github.io/tags/life/"/>
    
      <category term="autobiograpy" scheme="http://james20141606.github.io/tags/autobiograpy/"/>
    
  </entry>
  
</feed>
